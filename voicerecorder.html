<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Recorder & Transcriber (MP3)</title>
    <script src="https://cdn.tailwindcss.com?plugins=forms"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://unpkg.com/@ffmpeg/ffmpeg@0.11.0/dist/ffmpeg.min.js"></script>

    <style>
        /* Styles (pulse, scrollbar, layout, disabled, lucide, ffmpegLog) remain the same */
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
        .recording-pulse { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        .history-list::-webkit-scrollbar { width: 8px; }
        .history-list::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb { background: #888; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb:hover { background: #555; }
        html, body { height: 100%; margin: 0; font-family: sans-serif; }
        .main-container { display: flex; flex-direction: column; min-height: 100vh; }
        .content-grow { flex-grow: 1; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        [data-lucide] { width: 1em; height: 1em; display: inline-block; vertical-align: middle; }
        #ffmpegLog { font-family: monospace; font-size: 0.75rem; max-height: 100px; overflow-y: auto; background-color: #f5f5f5; border: 1px solid #e0e0e0; padding: 5px; margin-top: 10px; white-space: pre-wrap; word-break: break-all; }
        
        /* Dark mode styles */
        :root {
            color-scheme: light dark;
        }
        
        body.dark-mode {
            background-color: #1a1a1a;
            color: #e0e0e0;
        }
        
        body.dark-mode .bg-white {
            background-color: #2d2d2d;
        }
        
        body.dark-mode .text-gray-800 {
            color: #e0e0e0;
        }
        
        body.dark-mode .text-gray-600 {
            color: #b0b0b0;
        }
        
        body.dark-mode .text-gray-500 {
            color: #a0a0a0;
        }
        
        body.dark-mode .bg-gray-50 {
            background-color: #333333;
        }
        
        body.dark-mode .border-gray-200 {
            border-color: #444444;
        }
        
        body.dark-mode #ffmpegLog {
            background-color: #222222;
            border-color: #444444;
            color: #e0e0e0;
        }
        
        body.dark-mode .bg-gray-100 {
            background-color: #1a1a1a;
        }
        
        /* Toggle switch styles */
        .toggle-switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 24px;
        }
        
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .toggle-slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 24px;
        }
        
        .toggle-slider:before {
            position: absolute;
            content: "";
            height: 16px;
            width: 16px;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        
        input:checked + .toggle-slider {
            background-color: #2196F3;
        }
        
        input:checked + .toggle-slider:before {
            transform: translateX(26px);
        }
    </style>
</head>
<body class="bg-gray-100">
    <div class="main-container container mx-auto p-4 md:p-8 max-w-4xl">

        <header class="mb-8 text-center relative">
            <h1 class="text-3xl font-bold text-gray-800">Voice Recorder & Transcriber (MP3)</h1>
            <p class="text-gray-600">Record audio, convert to MP3 (VBR ~q1), save locally, and transcribe using Gemini.</p>
            <button id="settingsButton" class="absolute top-0 right-0 p-2 text-gray-600 hover:text-gray-800 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                <i data-lucide="settings" style="width: 24px; height: 24px;"></i>
            </button>
        </header>

        <section id="settingsSection" class="mb-6 p-4 bg-white dark:bg-gray-800 rounded-lg shadow hidden">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-xl font-semibold text-gray-700 dark:text-gray-300">Settings</h2>
                <button id="closeSettings" class="p-1 text-gray-600 dark:text-gray-400 hover:text-gray-800 dark:hover:text-gray-200 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                    <i data-lucide="x" style="width: 20px; height: 20px;"></i>
                </button>
            </div>
            
            <div id="transcriptionApiSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Transcription API:</h3>
                
                <!-- Gemini API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Google Gemini</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="geminiToggle" checked>
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="geminiSettings" class="mt-2">
                        <label for="apiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="apiKey" name="apiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your API key">
                            <a href="https://aistudio.google.com/app/apikey" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        <p class="text-xs text-gray-500 dark:text-gray-400 mt-2">Your API key is stored only in your browser's local storage.</p>
                    </div>
                </div>
                
                <!-- OpenAI API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">OpenAI</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="openaiToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="openaiSettings" class="mt-2 hidden">
                        <label for="openaiApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="openaiApiKey" name="openaiApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your OpenAI API key">
                            <a href="https://platform.openai.com/api-keys" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        
                        <div class="mt-3">
                            <label for="openaiModel" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Model:</label>
                            <select id="openaiModel" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="whisper-1">Whisper</option>
                                <option value="gpt-4o-audio-preview">GPT-4o Audio Preview</option>
                                <option value="gpt-4o-mini-audio-preview">GPT-4o Mini Audio Preview</option>
                            </select>
                        </div>
                        
                        <div class="mt-3">
                            <label for="openaiLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="openaiLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
                
                <!-- Groq API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Groq</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="groqToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="groqSettings" class="mt-2 hidden">
                        <label for="groqApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="groqApiKey" name="groqApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your Groq API key">
                            <a href="https://console.groq.com/keys" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        
                        <div class="mt-3">
                            <label for="groqModel" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Model:</label>
                            <select id="groqModel" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="whisper-large-v3-turbo">Whisper Large V3 Turbo</option>
                                <option value="distil-whisper-large-v3-en">Distil Whisper Large V3 (English)</option>
                                <option value="whisper-large-v3">Whisper Large V3</option>
                            </select>
                        </div>
                        
                        <div class="mt-3">
                            <label for="groqLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="groqLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
                
                <!-- Assembly AI API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Assembly AI</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="assemblyToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="assemblySettings" class="mt-2 hidden">
                        <label for="assemblyApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="assemblyApiKey" name="assemblyApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your Assembly AI API key">
                            <a href="https://www.assemblyai.com/dashboard/api-keys" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        
                        <div class="mt-3">
                            <div class="flex items-center space-x-2">
                                <label class="text-sm font-medium text-gray-700 dark:text-gray-300">EU Server:</label>
                                <label class="toggle-switch">
                                    <input type="checkbox" id="assemblyEuToggle">
                                    <span class="toggle-slider"></span>
                                </label>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Toggle to use EU server for transcription</p>
                        </div>
                        
                        <div class="mt-3">
                            <label for="assemblyLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="assemblyLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en_us">English (US)</option>
                                <option value="en_uk">English (UK)</option>
                                <option value="en_au">English (Australia)</option>
                                <option value="fr_fr">French</option>
                                <option value="de_de">German</option>
                                <option value="it_it">Italian</option>
                                <option value="es_es">Spanish</option>
                                <option value="pt_pt">Portuguese</option>
                                <option value="nl_nl">Dutch</option>
                                <option value="ja_jp">Japanese</option>
                                <option value="ko_kr">Korean</option>
                                <option value="zh_cn">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
            </div>

            <div id="ffmpegSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">FFmpeg Status:</h3>
                <div class="flex items-center justify-between mb-2">
                    <p id="ffmpegStatus" class="text-sm text-gray-600 dark:text-gray-400">Loading FFmpeg...</p>
                    <div class="flex items-center space-x-2">
                        <label class="text-xs text-gray-500 dark:text-gray-400">Enable FFmpeg</label>
                        <label class="toggle-switch">
                            <input type="checkbox" id="ffmpegToggle" checked>
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                </div>
                <div id="ffmpegLog" class="hidden text-left mt-2"></div>
            </div>
            
            <div id="recordingSettingsSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Recording Settings:</h3>
                <div class="mt-3">
                    <label for="recordingLimit" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Recording Length Limit (seconds):</label>
                    <input type="number" id="recordingLimit" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Auto (based on API)">
                    <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Leave empty for automatic limits (FFmpeg: 600s, Gemini: 570s, OpenAI: 140s)</p>
                </div>
            </div>
            
            <div id="themeSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Theme:</h3>
                <div class="flex items-center space-x-2">
                    <label class="text-sm text-gray-600 dark:text-gray-400">Dark Mode:</label>
                    <div class="flex items-center space-x-2">
                        <label class="text-xs text-gray-500 dark:text-gray-400">System</label>
                        <label class="toggle-switch">
                            <input type="checkbox" id="darkModeToggle">
                            <span class="toggle-slider"></span>
                        </label>
                        <label class="text-xs text-gray-500 dark:text-gray-400">Dark</label>
                    </div>
                </div>
            </div>
        </section>

        <section class="mb-6 p-6 bg-white dark:bg-gray-800 rounded-lg shadow text-center">
            <h2 class="text-xl font-semibold mb-4 text-gray-700 dark:text-gray-300">Record Audio</h2>
            <div class="relative" id="recordButtonContainer">
                <button id="recordButton" class="p-4 bg-red-600 text-white rounded-full hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-red-500 transition duration-150 ease-in-out disabled:bg-gray-400" disabled> 
                    <i id="micIconPlaceholder" data-lucide="mic" style="width: 32px; height: 32px;"></i>
                </button>
                <div id="dropZoneOverlay" class="absolute inset-0 flex items-center justify-center rounded-full bg-blue-500 bg-opacity-80 text-white hidden">
                    <i data-lucide="upload" style="width: 32px; height: 32px;"></i>
                </div>
            </div>
            <p id="statusMessage" class="mt-3 text-gray-600 h-5">Loading FFmpeg...</p>
            <p id="uploadMessage" class="mt-1 text-sm text-gray-500">Drag & drop an audio file here to upload</p>
            <div id="ffmpegLog" class="hidden text-left"></div>
        </section>

        <section id="transcriptionSection" class="mb-6 p-4 bg-white rounded-lg shadow hidden">
             <h2 class="text-xl font-semibold mb-2 text-gray-700">Transcription</h2>
             <div class="relative">
                <textarea id="transcriptionOutput" rows="4" class="w-full p-2 border border-gray-300 rounded-md bg-gray-50 resize-none" readonly placeholder="Transcription will appear here..."></textarea>
                <button id="copyButton" title="Copy to Clipboard" class="absolute top-2 right-2 p-1 bg-gray-200 text-gray-600 rounded hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500 opacity-50 cursor-not-allowed" disabled>
                    <i data-lucide="copy" style="width: 18px; height: 18px;"></i>
                </button>
             </div>
        </section>

        <section class="content-grow p-4 bg-white dark:bg-gray-800 rounded-lg shadow flex flex-col">
            <h2 class="text-xl font-semibold mb-4 text-gray-700 dark:text-gray-300 flex-shrink-0">Recording History</h2>
            <div id="historyList" class="history-list flex-grow overflow-y-auto space-y-3 pr-2">
                <p id="noHistoryMessage" class="text-gray-500">No recordings yet.</p>
            </div>
        </section>

        <footer class="mt-8 text-center text-sm text-gray-500">
            <p>App by Gemini. Uses browser storage and requires Gemini API Key for transcription.</p>
        </footer>

    </div> <script>
        // --- DOM Elements (Unchanged) ---
        const apiKeyInput = document.getElementById('apiKey');
        const saveApiKeyButton = document.getElementById('saveApiKey');
        const recordButton = document.getElementById('recordButton');
        const recordButtonContainer = document.getElementById('recordButtonContainer');
        const dropZoneOverlay = document.getElementById('dropZoneOverlay');
        const uploadMessage = document.getElementById('uploadMessage');
        const statusMessage = document.getElementById('statusMessage');
        const transcriptionSection = document.getElementById('transcriptionSection');
        const transcriptionOutput = document.getElementById('transcriptionOutput');
        const copyButton = document.getElementById('copyButton');
        const historyList = document.getElementById('historyList');
        const noHistoryMessage = document.getElementById('noHistoryMessage');
        const ffmpegLog = document.getElementById('ffmpegLog');
        const settingsButton = document.getElementById('settingsButton');
        const settingsSection = document.getElementById('settingsSection');
        const closeSettings = document.getElementById('closeSettings');
        const ffmpegStatus = document.getElementById('ffmpegStatus');
        const geminiToggle = document.getElementById('geminiToggle');
        const geminiSettings = document.getElementById('geminiSettings');
        const openaiToggle = document.getElementById('openaiToggle');
        const openaiSettings = document.getElementById('openaiSettings');
        const openaiApiKeyInput = document.getElementById('openaiApiKey');
        const saveOpenaiApiKeyButton = document.getElementById('saveOpenaiApiKey');
        const openaiModelSelect = document.getElementById('openaiModel');
        const openaiLanguageSelect = document.getElementById('openaiLanguage');
        const groqToggle = document.getElementById('groqToggle');
        const groqSettings = document.getElementById('groqSettings');
        const groqApiKeyInput = document.getElementById('groqApiKey');
        const saveGroqApiKeyButton = document.getElementById('saveGroqApiKey');
        const groqModelSelect = document.getElementById('groqModel');
        const groqLanguageSelect = document.getElementById('groqLanguage');
        const assemblyToggle = document.getElementById('assemblyToggle');
        const assemblySettings = document.getElementById('assemblySettings');
        const assemblyApiKeyInput = document.getElementById('assemblyApiKey');
        const assemblyEuToggle = document.getElementById('assemblyEuToggle');
        const assemblyLanguageSelect = document.getElementById('assemblyLanguage');
        const recordingLimitInput = document.getElementById('recordingLimit');

        // --- State Variables (Unchanged) ---
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let currentApiKey = localStorage.getItem('geminiApiKey') || '';
        let currentOpenaiApiKey = localStorage.getItem('openaiApiKey') || '';
        let currentGroqApiKey = localStorage.getItem('groqApiKey') || '';
        let currentAssemblyApiKey = localStorage.getItem('assemblyApiKey') || '';
        let openaiModel = localStorage.getItem('openaiModel') || 'whisper-1';
        let openaiLanguage = localStorage.getItem('openaiLanguage') || 'auto';
        let groqModel = localStorage.getItem('groqModel') || 'whisper-large-v3-turbo';
        let groqLanguage = localStorage.getItem('groqLanguage') || 'auto';
        let assemblyLanguage = localStorage.getItem('assemblyLanguage') || 'auto';
        let assemblyEuServer = localStorage.getItem('assemblyEuServer') === 'true';
        let db;
        let ffmpeg;
        let ffmpegLoaded = false;
        let currentlyPlayingAudio = null;
        let currentlyPlayingButton = null;
        let tokenUsage = { input: 0, output: 0 }; // Track token usage
        let darkMode = localStorage.getItem('darkMode') || 'system'; // Dark mode preference
        let settingsVisible = false; // Track settings visibility
        let ffmpegEnabled = localStorage.getItem('ffmpegEnabled') !== 'false'; // FFmpeg enabled by default
        let geminiEnabled = localStorage.getItem('geminiEnabled') !== 'false'; // Gemini enabled by default
        let openaiEnabled = localStorage.getItem('openaiEnabled') === 'true'; // OpenAI disabled by default
        let groqEnabled = localStorage.getItem('groqEnabled') === 'true'; // Groq disabled by default
        let assemblyEnabled = localStorage.getItem('assemblyEnabled') === 'true'; // Assembly disabled by default
        let recordingLimit = localStorage.getItem('recordingLimit') || ''; // Recording length limit
        let recordingTimer = null; // Timer for recording length limit
        let isDraggingFile = false; // Track if file is being dragged over

        // --- Constants ---
        const DB_NAME = 'VoiceRecorderDB_MP3';
        const DB_VERSION = 1;
        const STORE_NAME = 'recordings_mp3';
        const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=';
        const OPENAI_API_URL = 'https://api.openai.com/v1/audio/transcriptions';
        const OPENAI_CHAT_API_URL = 'https://api.openai.com/v1/chat/completions';
        const GROQ_API_URL = 'https://api.groq.com/openai/v1/audio/transcriptions';
        const ASSEMBLY_API_URL_US = 'https://api.assemblyai.com/v2/transcript';
        const ASSEMBLY_API_URL_EU = 'https://api.eu.assemblyai.com/v2/transcript';
        const TARGET_MIME_TYPE = 'audio/mpeg';
        const TARGET_FORMAT = 'mp3';
        const TARGET_QUALITY = '1';
        const TARGET_CHANNELS = 1;
        
        // Local proxy URLs for API requests
        const OPENAI_PROXY_URL = '/api/openai';

        // File size limits for different APIs
        const FILE_SIZE_LIMITS = {
            gemini: 50 * 1024 * 1024, // 50MB
            openai: 25 * 1024 * 1024, // 25MB
            groq: 25 * 1024 * 1024,   // 25MB
            assembly: 200 * 1024 * 1024 // 200MB
        };

        // --- FFmpeg Initialization ---
        async function loadFFmpeg() {
            if (!ffmpegEnabled) {
                ffmpegStatus.textContent = 'FFmpeg disabled. Audio will not be converted to MP3.';
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = 'Recording enabled (no MP3 conversion)';
                return;
            }
            
            ffmpegStatus.textContent = 'Loading FFmpeg (approx. 30MB)...';
            recordButton.disabled = true;
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = 'Initializing FFmpeg library...\n';

            try {
                if (typeof FFmpeg === 'undefined' || typeof FFmpeg.createFFmpeg === 'undefined') {
                     throw new Error("FFmpeg library script not loaded correctly.");
                }
                const { createFFmpeg } = FFmpeg;

                const corePath = 'https://unpkg.com/@ffmpeg/core@0.11.0/dist/ffmpeg-core.js';
                ffmpegLog.textContent += `Attempting to load core from: ${corePath}\n (This avoids SharedArrayBuffer issues but is slower)\n`;

                ffmpeg = createFFmpeg({
                    log: true,
                    logger: ({ type, message }) => {
                        console.log(`FFmpeg log [${type}]: ${message}`);
                        if(ffmpegLog.textContent.length > 5000) ffmpegLog.textContent = '';
                        ffmpegLog.textContent += message + '\n';
                        ffmpegLog.scrollTop = ffmpegLog.scrollHeight;
                    },
                    progress: ({ ratio }) => {
                         console.log(`FFmpeg progress: ${(ratio * 100).toFixed(2)}%`);
                         if (ratio > 0 && ratio < 1) {
                            ffmpegStatus.textContent = `Loading FFmpeg... ${(ratio * 100).toFixed(0)}%`;
                         }
                    },
                    corePath: corePath,
                });

                ffmpegLog.textContent += 'Loading FFmpeg core...\n';
                await ffmpeg.load();
                ffmpegLog.textContent += 'FFmpeg core loaded successfully.\n';
                ffmpegLoaded = true;
                ffmpegStatus.textContent = 'FFmpeg loaded successfully';
                setStatus('Ready to record.');
                recordButton.disabled = false;

            } catch (error) {
                console.error("Error loading FFmpeg:", error);
                if (error instanceof ReferenceError && error.message.includes("SharedArrayBuffer")) {
                     ffmpegStatus.textContent = 'FFmpeg failed: SharedArrayBuffer missing. Need server COOP/COEP headers.';
                     ffmpegLog.textContent += `ERROR: SharedArrayBuffer not defined. This usually means the server is not sending the required COOP and COEP headers. See console and explanation above the code.\n`;
                } else {
                    ffmpegStatus.textContent = 'Failed to load FFmpeg. Conversion unavailable.';
                    ffmpegLog.textContent += `Error loading FFmpeg: ${error}\n`;
                }
                ffmpegLoaded = false;
                recordButton.disabled = true;
                recordButton.title = 'FFmpeg failed to load, recording disabled.';
            }
        }


        // --- IndexedDB Initialization (Unchanged) ---
        function initDB() {
            return new Promise((resolve, reject) => {
                const request = indexedDB.open(DB_NAME, DB_VERSION);
                request.onerror = (event) => { console.error("IndexedDB error:", event.target.error); setStatus('Error initializing local database.', true); reject(event.target.error); };
                request.onsuccess = (event) => { db = event.target.result; console.log("Database initialized successfully:", DB_NAME); resolve(db); };
                request.onupgradeneeded = (event) => {
                    db = event.target.result;
                    if (!db.objectStoreNames.contains(STORE_NAME)) {
                        const objectStore = db.createObjectStore(STORE_NAME, { keyPath: 'id', autoIncrement: true });
                        objectStore.createIndex('timestamp', 'timestamp', { unique: false });
                        console.log("Object store created:", STORE_NAME);
                    }
                };
            });
        }

        // --- IndexedDB Operations ---
        function addRecordingToDB(blob, mimeType) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite');
                const store = transaction.objectStore(STORE_NAME);
                const recording = { audioBlob: blob, mimeType: mimeType, timestamp: new Date(), transcription: null };
                const request = store.add(recording);
                request.onsuccess = (event) => resolve(event.target.result);
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function getRecordingsFromDB() {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.getAll();
                request.onsuccess = (event) => resolve(event.target.result.sort((a, b) => b.timestamp - a.timestamp));
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function getRecordingByIdFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.get(id);
                request.onsuccess = (event) => resolve(event.target.result);
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function updateTranscriptionInDB(id, transcription) {
            return new Promise(async (resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                try {
                    const recording = await getRecordingByIdFromDB(id);
                    if (!recording) return reject(`Recording ${id} not found.`);
                    recording.transcription = transcription;
                    const transaction = db.transaction([STORE_NAME], 'readwrite');
                    const store = transaction.objectStore(STORE_NAME);
                    const request = store.put(recording);
                    request.onsuccess = () => resolve();
                    request.onerror = (event) => reject(event.target.error);
                } catch (error) {
                    reject(error);
                }
            });
        }

        function deleteRecordingFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.delete(id);
                request.onsuccess = () => resolve();
                request.onerror = (event) => reject(event.target.error);
            });
        }

        // --- UI Update Functions (Unchanged) ---
        function setStatus(message, isError = false) { statusMessage.textContent = message; statusMessage.className = `mt-3 h-5 ${isError ? 'text-red-600' : 'text-gray-600'}`; }
        function updateRecordButtonState() {
            const micIconElement = recordButton.querySelector('[data-lucide="mic"]');
            if (isRecording) {
                recordButton.classList.remove('bg-red-600', 'hover:bg-red-700');
                recordButton.classList.add('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                if (micIconElement) micIconElement.classList.add('animate-pulse');
                setStatus('Recording...');
                recordButton.disabled = false; // Ensure button is enabled during recording
            } else {
                if (!statusMessage.textContent.includes('FFmpeg') && !statusMessage.textContent.includes('Converting')) {
                    setStatus('Click the mic to record');
                }
                recordButton.classList.remove('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                recordButton.classList.add('bg-red-600', 'hover:bg-red-700');
                if (micIconElement) micIconElement.classList.remove('animate-pulse');
                
                // Only disable the button if both conditions are true:
                // 1. FFmpeg is enabled in settings
                // 2. FFmpeg is not loaded yet
                if (ffmpegEnabled && !ffmpegLoaded) {
                    recordButton.disabled = true;
                    recordButton.title = 'FFmpeg is loading...';
                } else {
                    recordButton.disabled = false;
                    if (!ffmpegEnabled) {
                        recordButton.title = 'Recording enabled (no MP3 conversion)';
                    } else {
                        recordButton.title = 'Record audio and convert to MP3';
                    }
                }
            }
        }
        function displayTranscription(text) {
            transcriptionOutput.value = text || "No transcription available.";
            transcriptionSection.classList.remove('hidden');
            
            if (text && text !== "API Key needed." && !text.startsWith("Error:")) {
                copyButton.disabled = false;
                copyButton.classList.remove('opacity-50', 'cursor-not-allowed');
                copyButton.classList.add('opacity-100', 'cursor-pointer');
                
                // Automatically copy to clipboard
                navigator.clipboard.writeText(text).then(() => {
                    setStatus('Transcription copied to clipboard!');
                    const copyIcon = copyButton.querySelector('[data-lucide="copy"]');
                    const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`;
                    const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`;
                    copyButton.innerHTML = checkIconHTML;
                    lucide.createIcons();
                    setTimeout(() => {
                        copyButton.innerHTML = originalIconHTML;
                        lucide.createIcons();
                    }, 1500);
                }).catch(err => {
                    console.error('Auto-copy failed: ', err);
                    setStatus('Auto-copy failed.', true);
                });
            } else {
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }
        async function renderHistory() {
             try {
                const recordings = await getRecordingsFromDB(); 
                historyList.innerHTML = '';
                
                if (recordings.length === 0) { 
                    noHistoryMessage.classList.remove('hidden'); 
                    historyList.appendChild(noHistoryMessage); 
                } else {
                    noHistoryMessage.classList.add('hidden');
                    
                    // Sort recordings by timestamp (newest first)
                    recordings.sort((a, b) => b.timestamp - a.timestamp);
                    
                    // Limit to 10 entries
                    const limitedRecordings = recordings.slice(0, 10);
                    
                    // If we have more than 10 recordings, delete the oldest ones
                    if (recordings.length > 10) {
                        const recordingsToDelete = recordings.slice(10);
                        for (const rec of recordingsToDelete) {
                            try {
                                await deleteRecordingFromDB(rec.id);
                                console.log(`Auto-deleted old recording ${rec.id}`);
                            } catch (error) {
                                console.error(`Error auto-deleting recording ${rec.id}:`, error);
                            }
                        }
                    }
                    
                    limitedRecordings.forEach(rec => {
                        const div = document.createElement('div'); 
                        div.className = 'p-3 bg-gray-50 border border-gray-200 rounded-md flex items-center justify-between space-x-3';
                        
                        const infoDiv = document.createElement('div'); 
                        infoDiv.className = 'flex-grow min-w-0';
                        
                        const time = document.createElement('p'); 
                        time.className = 'text-sm font-medium text-gray-800 dark:text-gray-300 truncate'; 
                        // Get the actual format from the MIME type
                        let format = 'MP3';
                        if (rec.mimeType) {
                            if (rec.mimeType.includes('webm')) {
                                format = 'WEBM';
                            } else if (rec.mimeType.includes('ogg')) {
                                format = 'OGG';
                            } else if (rec.mimeType.includes('wav')) {
                                format = 'WAV';
                            }
                        }
                        time.textContent = `Recorded ${format}: ${rec.timestamp.toLocaleString()}`; 
                        time.title = `${format} Recorded: ${rec.timestamp.toLocaleString()}`;
                        
                        // Add file size and duration info
                        const fileInfo = document.createElement('p');
                        fileInfo.className = 'text-xs text-gray-500';
                        
                        // Calculate file size
                        const fileSizeMB = (rec.audioBlob.size / (1024 * 1024)).toFixed(2);
                        
                        // Create audio element to get duration
                        const audio = new Audio(URL.createObjectURL(rec.audioBlob));
                        audio.onloadedmetadata = () => {
                            const duration = audio.duration;
                            const minutes = Math.floor(duration / 60);
                            const seconds = Math.floor(duration % 60);
                            const durationStr = `${minutes}:${seconds.toString().padStart(2, '0')}`;
                            
                            // Add token usage if available
                            const tokenInfo = rec.tokenUsage ? 
                                ` | Tokens: ${rec.tokenUsage.input || 0} in, ${rec.tokenUsage.output || 0} out` : 
                                '';
                                
                            fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: ${durationStr}${tokenInfo}`;
                            URL.revokeObjectURL(audio.src);
                        };
                        
                        const transcriptionPreview = document.createElement('p'); 
                        transcriptionPreview.className = 'text-xs text-gray-500 italic truncate'; 
                        transcriptionPreview.textContent = rec.transcription ? `"${rec.transcription.substring(0, 60)}..."` : 'Not transcribed yet'; 
                        if(rec.transcription) transcriptionPreview.title = rec.transcription;
                        
                        // Append elements in the correct order
                        infoDiv.appendChild(time);
                        infoDiv.appendChild(fileInfo);
                        infoDiv.appendChild(transcriptionPreview);
                        
                        const controlsDiv = document.createElement('div'); 
                        controlsDiv.className = 'flex-shrink-0 flex items-center space-x-2';
                        
                        const playButton = document.createElement('button');
                        playButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        playButton.className = 'p-1.5 bg-green-100 text-green-700 rounded hover:bg-green-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-green-500';
                        playButton.title = 'Play MP3 Audio';
                        playButton.onclick = () => playAudio(rec.audioBlob, playButton);

                        const downloadButton = document.createElement('button');
                        downloadButton.innerHTML = `<i data-lucide="download" style="width: 18px; height: 18px;"></i>`;
                        downloadButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        downloadButton.title = 'Download MP3';
                        downloadButton.onclick = () => {
                            const url = URL.createObjectURL(rec.audioBlob);
                            const a = document.createElement('a');
                            a.href = url;
                            // Get the correct file extension based on MIME type
                            let extension = 'mp3';
                            if (rec.mimeType) {
                                if (rec.mimeType.includes('webm')) {
                                    extension = 'webm';
                                } else if (rec.mimeType.includes('ogg')) {
                                    extension = 'ogg';
                                } else if (rec.mimeType.includes('wav')) {
                                    extension = 'wav';
                                }
                            }
                            a.download = `recording_${rec.id}_${rec.timestamp.toISOString().slice(0,19).replace(/[:]/g, '-')}.${extension}`;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        };

                        const transcribeButton = document.createElement('button');
                        transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                        transcribeButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        transcribeButton.title = 'Transcribe Audio';
                        transcribeButton.onclick = (e) => {
                            if (rec.transcription) {
                                displayTranscription(rec.transcription);
                                return;
                            }
                            transcribeButton.disabled = true;
                            transcribeButton.innerHTML = '...';
                            transcribeAudio(rec.id, rec.audioBlob, rec.mimeType).finally(() => {
                                transcribeButton.disabled = false;
                                transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                                lucide.createIcons();
                            });
                        };
                        
                        // Update disabled state logic
                        if (rec.transcription) {
                            // If there's a transcription, button is always enabled
                            transcribeButton.disabled = false;
                            transcribeButton.title = 'View Transcription';
                        } else if (!ffmpegLoaded && !assemblyEnabled) {
                            // If FFmpeg isn't loaded and we're not using Assembly AI, disable the button
                            transcribeButton.disabled = true;
                            transcribeButton.title = 'FFmpeg not loaded';
                        } else if ((!geminiEnabled || !currentApiKey) && 
                                 (!openaiEnabled || !currentOpenaiApiKey) && 
                                 (!groqEnabled || !currentGroqApiKey) && 
                                 (!assemblyEnabled || !currentAssemblyApiKey)) {
                            // If no API is enabled with a key, disable the button
                            transcribeButton.disabled = true;
                            transcribeButton.title = 'No API enabled or API Key required';
                        } else {
                            // Otherwise, enable the button for transcription
                            transcribeButton.disabled = false;
                            transcribeButton.title = 'Transcribe Audio';
                        }

                        const deleteButton = document.createElement('button');
                        deleteButton.innerHTML = `<i data-lucide="trash-2" style="width: 18px; height: 18px;"></i>`;
                        deleteButton.className = 'p-1.5 bg-red-100 text-red-700 rounded hover:bg-red-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-red-500';
                        deleteButton.title = 'Delete Recording';
                        deleteButton.onclick = () => deleteRecording(rec.id);

                        controlsDiv.appendChild(playButton);
                        controlsDiv.appendChild(downloadButton);
                        controlsDiv.appendChild(transcribeButton);
                        controlsDiv.appendChild(deleteButton);
                        
                        div.appendChild(infoDiv);
                        div.appendChild(controlsDiv);
                        historyList.appendChild(div);
                    });
                    
                    lucide.createIcons();
                }
            } catch (error) { 
                console.error("Error rendering history:", error); 
                setStatus('Could not load history.', true); 
                noHistoryMessage.classList.remove('hidden'); 
                historyList.appendChild(noHistoryMessage); 
            }
        }

        // --- Audio Handling ---
        async function startRecording() {
            if (!ffmpegEnabled && !ffmpegLoaded) {
                setStatus('FFmpeg disabled. Recording without MP3 conversion.');
            }
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log("Mic access granted.");
                const options = { mimeType: 'audio/webm;codecs=opus' };
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/ogg;codecs=opus';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/webm';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = '';
                console.log("Recording with MIME type:", options.mimeType || "Browser Default");
                mediaRecorder = new MediaRecorder(stream, options);
                audioChunks = [];
                mediaRecorder.ondataavailable = event => { if (event.data.size > 0) audioChunks.push(event.data); };
                mediaRecorder.onstop = async () => {
                    const originalBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });
                    const originalMimeType = mediaRecorder.mimeType || 'audio/webm';
                    console.log("Recording stopped. Original Blob:", originalBlob);
                    console.log("Original MIME type:", originalMimeType);
                    stream.getTracks().forEach(track => track.stop());
                    
                    if (ffmpegEnabled && ffmpegLoaded) {
                        await convertAudioAndSave(originalBlob, originalMimeType); // Convert and save
                    } else {
                        // Save without conversion
                        setStatus('Saving recording...');
                        const newId = await addRecordingToDB(originalBlob, originalMimeType);
                        setStatus(`Recording saved (ID: ${newId}).`);
                        await renderHistory();
                        
                        // Attempt automatic transcription if API key is available
                        if ((geminiEnabled && currentApiKey) || (openaiEnabled && currentOpenaiApiKey) || (groqEnabled && currentGroqApiKey)) {
                            setStatus(`Starting automatic transcription for recording ${newId}...`);
                            await transcribeAudio(newId, originalBlob, originalMimeType);
                        } else {
                            setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                            displayTranscription("API Key needed for transcription.");
                        }
                    }
                    
                    updateRecordButtonState(); // Update button state after saving
                };
                mediaRecorder.onerror = (event) => {
                    console.error("MediaRecorder error:", event.error);
                    setStatus(`Recording error: ${event.error?.name || 'Unknown'}`, true);
                    isRecording = false;
                    updateRecordButtonState();
                    stream.getTracks().forEach(track => track.stop());
                };
                mediaRecorder.start();
                isRecording = true;
                updateRecordButtonState();
                
                // Set up recording length limit timer
                if (recordingLimit) {
                    const limitSeconds = parseInt(recordingLimit);
                    if (!isNaN(limitSeconds) && limitSeconds > 0) {
                        recordingTimer = setTimeout(() => {
                            if (isRecording) {
                                stopRecording();
                            }
                        }, limitSeconds * 1000);
                    }
                } else {
                    // Default to 600 seconds (10 minutes) for all recording types
                    recordingTimer = setTimeout(() => {
                        if (isRecording) {
                            stopRecording();
                        }
                    }, 600 * 1000);
                }
            } catch (err) {
                console.error("Mic error:", err);
                console.error("Details:", JSON.stringify(err));
                console.error("Name:", err?.name);
                console.error("Message:", err?.message);
                let msg = 'Error starting recording.';
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') msg = 'Mic access denied.';
                else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') msg = 'No mic found.';
                else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') msg = 'Mic in use.';
                else if (err.message) msg = `Error: ${err.message}`;
                else msg = 'Unknown mic error.';
                setStatus(msg, true);
                isRecording = false;
                updateRecordButtonState();
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                try {
                    // Clear the recording timer
                    if (recordingTimer) {
                        clearTimeout(recordingTimer);
                        recordingTimer = null;
                    }
                    
                    mediaRecorder.stop();
                    isRecording = false;
                    setStatus('Processing recording...');
                    updateRecordButtonState();
                } catch (error) {
                    console.error("Error stopping recorder:", error);
                    setStatus('Error stopping recording.', true);
                    isRecording = false;
                    updateRecordButtonState();
                    if (mediaRecorder?.stream) {
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    }
                }
            }
        }

        // --- FFmpeg Conversion Function ---
        async function convertAudioAndSave(originalBlob, originalMimeType) {
            if (!ffmpegLoaded || !ffmpeg) {
                setStatus('FFmpeg not ready. Cannot convert/save.', true);
                updateRecordButtonState();
                return;
            }
            setStatus('Converting audio to MP3...');
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = `Starting conversion of ${originalMimeType}...\n`;
            // Don't disable the button here, let updateRecordButtonState handle it
            updateRecordButtonState();

            try {
                const arrayBuffer = await originalBlob.arrayBuffer();
                const inputData = new Uint8Array(arrayBuffer);
                const inputFilename = `input.${originalMimeType.split('/')[1]?.split(';')[0] || 'bin'}`;
                const outputFilename = `output.${TARGET_FORMAT}`;

                ffmpegLog.textContent += `Writing input file (${inputFilename})...\n`;
                await ffmpeg.FS('writeFile', inputFilename, inputData);
                ffmpegLog.textContent += `Input file written.\n`;

                const ffmpegCommand = [
                    '-i', inputFilename,
                    '-ac', `${TARGET_CHANNELS}`,
                    '-q:a', TARGET_QUALITY,
                    outputFilename
                ];

                ffmpegLog.textContent += `Running FFmpeg: ffmpeg ${ffmpegCommand.join(' ')}\n`;
                await ffmpeg.run(...ffmpegCommand);
                ffmpegLog.textContent += `FFmpeg execution finished.\n`;

                ffmpegLog.textContent += `Reading output file (${outputFilename})...\n`;
                const outputData = ffmpeg.FS('readFile', outputFilename);
                ffmpegLog.textContent += `Output file read (${outputData.length} bytes).\n`;

                const mp3Blob = new Blob([outputData.buffer], { type: TARGET_MIME_TYPE });
                console.log("Conversion successful. MP3 Blob created:", mp3Blob);

                try {
                    await ffmpeg.FS('unlink', inputFilename);
                    await ffmpeg.FS('unlink', outputFilename);
                    ffmpegLog.textContent += `Cleaned up virtual files.\n`;
                } catch (cleanupError) {
                    console.warn("FFmpeg cleanup warning:", cleanupError);
                    ffmpegLog.textContent += `Cleanup warning: ${cleanupError.message}\n`;
                }

                setStatus('Saving converted MP3...');
                const newId = await addRecordingToDB(mp3Blob, TARGET_MIME_TYPE);
                setStatus(`MP3 recording saved (ID: ${newId}).`);
                await renderHistory();

                // Attempt automatic transcription if API key is available
                if (currentApiKey) {
                    setStatus(`Starting automatic transcription for recording ${newId}...`);
                    await transcribeAudio(newId, mp3Blob, TARGET_MIME_TYPE);
                } else {
                    setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                    displayTranscription("API Key needed for transcription.");
                }

            } catch (error) {
                console.error("FFmpeg conversion failed:", error);
                setStatus(`Error during MP3 conversion: ${error.message || error}`, true);
                ffmpegLog.textContent += `ERROR: ${error.message || error}\n`;
            } finally {
                updateRecordButtonState();
            }
        }

        function playAudio(blob, button) {
            try {
                // If there's already an audio playing, stop it
                if (currentlyPlayingAudio) {
                    currentlyPlayingAudio.pause();
                    currentlyPlayingAudio.currentTime = 0;
                    if (currentlyPlayingButton) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                    }
                }

                // If clicking the same button that's currently playing, just stop
                if (currentlyPlayingButton === button) {
                    currentlyPlayingAudio = null;
                    currentlyPlayingButton = null;
                    return;
                }

                // Create and play new audio
                const audioUrl = URL.createObjectURL(blob);
                const audio = new Audio(audioUrl);
                
                audio.onerror = (e) => {
                    console.error("Audio play error:", e);
                    setStatus('Error playing audio.', true);
                    URL.revokeObjectURL(audioUrl);
                };
                
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    if (currentlyPlayingButton === button) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                        currentlyPlayingAudio = null;
                        currentlyPlayingButton = null;
                    }
                };

                audio.play();
                currentlyPlayingAudio = audio;
                currentlyPlayingButton = button;
                button.innerHTML = `<i data-lucide="pause" style="width: 18px; height: 18px;"></i>`;
                lucide.createIcons();
            } catch (error) {
                console.error("Audio object error:", error);
                setStatus('Could not play audio.', true);
            }
        }

        // --- Transcription (Updated to support multiple APIs) ---
        async function transcribeAudio(id, audioBlob, mimeType) {
            // Check if any API is enabled and has a key
            if (!geminiEnabled && !openaiEnabled && !groqEnabled && !assemblyEnabled) {
                setStatus('No transcription API enabled.', true);
                displayTranscription("No transcription API enabled. Please enable an API in settings.");
                return;
            }
            
            if (geminiEnabled && !currentApiKey) {
                setStatus('Gemini API Key needed.', true);
                displayTranscription("Gemini API Key needed for transcription.");
                return;
            }
            
            if (openaiEnabled && !currentOpenaiApiKey) {
                setStatus('OpenAI API Key needed.', true);
                displayTranscription("OpenAI API Key needed for transcription.");
                return;
            }
            
            if (groqEnabled && !currentGroqApiKey) {
                setStatus('Groq API Key needed.', true);
                displayTranscription("Groq API Key needed for transcription.");
                return;
            }
            
            if (assemblyEnabled && !currentAssemblyApiKey) {
                setStatus('Assembly AI API Key needed.', true);
                displayTranscription("Assembly AI API Key needed for transcription.");
                return;
            }
            
            if (!audioBlob) {
                setStatus('Invalid audio.', true);
                return;
            }
            
            setStatus(`Transcribing recording ${id}...`);
            displayTranscription("Transcribing...");
            transcriptionSection.classList.remove('hidden');
            copyButton.disabled = true;
            copyButton.classList.add('opacity-50', 'cursor-not-allowed');
            copyButton.classList.remove('opacity-100', 'cursor-pointer');

            try {
                let transcriptionText = "Transcription not found.";
                let recordingTokenUsage = { input: 0, output: 0 };
                
                // Try Gemini first if enabled
                if (geminiEnabled && currentApiKey) {
                    try {
                        const base64Audio = await blobToBase64(audioBlob);
                        const requestBody = { contents: [{ parts: [ { text: "Please transcribe the following audio recording:" }, { inline_data: { mime_type: mimeType, data: base64Audio } } ]}] };
                        const response = await fetch(GEMINI_API_URL + currentApiKey, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(requestBody) });
                        const data = await response.json();
                        
                        if (!response.ok) {
                            console.error("Gemini API Error:", data);
                            throw new Error(data?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        // Update token usage
                        if (data.usage) {
                            recordingTokenUsage.input = data.usage.promptTokenCount || 0;
                            recordingTokenUsage.output = data.usage.candidatesTokenCount || 0;
                            
                            // Update global token usage
                            tokenUsage.input += recordingTokenUsage.input;
                            tokenUsage.output += recordingTokenUsage.output;
                            localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                        }
                        
                        if (data.candidates?.[0]?.content?.parts?.[0]?.text) {
                            transcriptionText = data.candidates[0].content.parts[0].text;
                        } else if (data.candidates?.[0]?.finishReason === "SAFETY") {
                            transcriptionText = "Blocked: safety.";
                        } else {
                            console.warn("Unexpected Gemini API response:", data);
                            const textPart = data.candidates?.[0]?.content?.parts?.find(p => p.text);
                            if (textPart) transcriptionText = textPart.text;
                        }
                        
                        console.log("Gemini transcription OK:", transcriptionText);
                    } catch (error) {
                        console.error("Gemini transcription failed:", error);
                        // If Gemini fails and other APIs are enabled, try them
                        if ((openaiEnabled && currentOpenaiApiKey) || (groqEnabled && currentGroqApiKey)) {
                            throw new Error("Gemini failed, trying other APIs...");
                        } else {
                            throw error;
                        }
                    }
                }
                
                // Try OpenAI if Gemini is not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && openaiEnabled && currentOpenaiApiKey) {
                    try {
                        // Check if the selected model is a GPT-4o audio model
                        const isGPT4oAudioModel = openaiModel.includes('gpt-4o') && openaiModel.includes('audio');
                        
                        if (isGPT4oAudioModel) {
                            // Use chat completions API for GPT-4o audio models
                            const base64Audio = await blobToBase64(audioBlob);
                            
                            console.log("Sending audio to GPT-4o API, base64 length:", base64Audio.length);
                            
                            // Create request body for chat completions API
                            const requestBody = {
                                model: openaiModel,
                                messages: [
                                    {
                                        role: "user",
                                        content: [
                                            {
                                                type: "text",
                                                text: "Please transcribe this audio file accurately."
                                            },
                                            {
                                                type: "audio_url",
                                                audio_url: {
                                                    url: `data:${audioBlob.type};base64,${base64Audio}`
                                                }
                                            }
                                        ]
                                    }
                                ],
                                temperature: 0 // Lower temperature for more accurate transcription
                            };
                            
                            // Make the API request through our local proxy
                            const response = await fetch(`${OPENAI_PROXY_URL}/v1/chat/completions`, {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                    'Authorization': `Bearer ${currentOpenaiApiKey}`
                                },
                                body: JSON.stringify(requestBody)
                            });
                            
                            if (!response.ok) {
                                const errorData = await response.json();
                                console.error("OpenAI API Error:", errorData);
                                throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                            }
                            
                            const data = await response.json();
                            
                            // Extract the transcript from the chat response
                            if (data.choices && data.choices.length > 0 && data.choices[0].message?.content) {
                                transcriptionText = data.choices[0].message.content;
                            } else {
                                console.warn("Unexpected OpenAI Chat API response:", data);
                                transcriptionText = "Unexpected response format from OpenAI.";
                            }
                            
                            console.log("OpenAI GPT-4o transcription OK:", transcriptionText);
                            
                            // Update token usage from the response
                            if (data.usage) {
                                recordingTokenUsage.input = data.usage.prompt_tokens || 0;
                                recordingTokenUsage.output = data.usage.completion_tokens || 0;
                                
                                // Update global token usage
                                tokenUsage.input += recordingTokenUsage.input;
                                tokenUsage.output += recordingTokenUsage.output;
                                localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                            }
                        } else {
                            // Use transcription API for standard Whisper models
                            const formData = new FormData();
                            formData.append('file', audioBlob, 'audio.mp3');
                            formData.append('model', openaiModel);
                            
                            // Only add language if not auto
                            if (openaiLanguage !== 'auto') {
                                formData.append('language', openaiLanguage);
                            }
                            
                            const response = await fetch(`${OPENAI_PROXY_URL}/v1/audio/transcriptions`, {
                                method: 'POST',
                                headers: {
                                    'Authorization': `Bearer ${currentOpenaiApiKey}`
                                },
                                body: formData
                            });
                            
                            if (!response.ok) {
                                const errorData = await response.json();
                                console.error("OpenAI API Error:", errorData);
                                throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                            }
                            
                            const data = await response.json();
                            transcriptionText = data.text || "Transcription not found.";
                            console.log("OpenAI Whisper transcription OK:", transcriptionText);
                            
                            // OpenAI doesn't provide token usage in the same way, so we'll estimate
                            // Rough estimate: 1 token per 4 characters
                            const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                            recordingTokenUsage.input = 0; // We don't know the input tokens
                            recordingTokenUsage.output = estimatedTokens;
                            
                            // Update global token usage
                            tokenUsage.output += estimatedTokens;
                            localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                        }
                    } catch (error) {
                        console.error("OpenAI transcription failed:", error);
                        // If OpenAI fails and Groq is enabled, try Groq
                        if (groqEnabled && currentGroqApiKey) {
                            throw new Error("OpenAI failed, trying Groq...");
                        } else {
                            throw error;
                        }
                    }
                }
                
                // Try Groq if other APIs are not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && (!openaiEnabled || !currentOpenaiApiKey) && groqEnabled && currentGroqApiKey) {
                    try {
                        const formData = new FormData();
                        formData.append('file', audioBlob, 'audio.mp3');
                        formData.append('model', groqModel);
                        formData.append('temperature', '0');
                        formData.append('response_format', 'text');
                        
                        // Only add language if not auto
                        if (groqLanguage !== 'auto') {
                            formData.append('language', groqLanguage);
                        }
                        
                        const response = await fetch(GROQ_API_URL, {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${currentGroqApiKey}`
                            },
                            body: formData
                        });
                        
                        if (!response.ok) {
                            const errorData = await response.json();
                            console.error("Groq API Error:", errorData);
                            throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        // Groq returns plain text, not JSON
                        transcriptionText = await response.text();
                        console.log("Groq transcription OK:", transcriptionText);
                        
                        // Groq doesn't provide token usage in the same way, so we'll estimate
                        // Rough estimate: 1 token per 4 characters
                        const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                        recordingTokenUsage.input = 0; // We don't know the input tokens
                        recordingTokenUsage.output = estimatedTokens;
                        
                        // Update global token usage
                        tokenUsage.output += estimatedTokens;
                        localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                    } catch (error) {
                        console.error("Groq transcription failed:", error);
                        throw error;
                    }
                }
                
                // Try Assembly AI if other APIs are not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && 
                    (!openaiEnabled || !currentOpenaiApiKey) && 
                    (!groqEnabled || !currentGroqApiKey) && 
                    assemblyEnabled && currentAssemblyApiKey) {
                    try {
                        // Determine which API URL to use based on the EU/US setting
                        const apiUrl = assemblyEuServer ? ASSEMBLY_API_URL_EU : ASSEMBLY_API_URL_US;
                        
                        setStatus('Uploading audio to Assembly AI...');
                        
                        // Step 1: Convert blob to base64
                        const base64Audio = await blobToBase64(audioBlob);
                        
                        // Step 2: Upload the audio file
                        const uploadResponse = await fetch(`${apiUrl}/upload`, {
                            method: 'POST',
                            headers: {
                                'Authorization': currentAssemblyApiKey,
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify({
                                file_data: base64Audio
                            })
                        });
                        
                        if (!uploadResponse.ok) {
                            const errorData = await uploadResponse.json();
                            console.error("Assembly AI Upload Error:", errorData);
                            throw new Error(errorData?.error || `HTTP ${uploadResponse.status}`);
                        }
                        
                        const uploadData = await uploadResponse.json();
                        const audioUrl = uploadData.upload_url;
                        
                        if (!audioUrl) {
                            throw new Error("Failed to get upload URL from Assembly AI");
                        }
                        
                        setStatus('Starting transcription with Assembly AI...');
                        
                        // Step 3: Create the transcription request
                        const transcriptionRequest = {
                            audio_url: audioUrl,
                            language_code: assemblyLanguage !== 'auto' ? assemblyLanguage : undefined
                        };
                        
                        // Step 4: Submit the transcription request
                        const transcriptionResponse = await fetch(apiUrl, {
                            method: 'POST',
                            headers: {
                                'Authorization': currentAssemblyApiKey,
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify(transcriptionRequest)
                        });
                        
                        if (!transcriptionResponse.ok) {
                            const errorData = await transcriptionResponse.json();
                            console.error("Assembly AI Transcription Error:", errorData);
                            throw new Error(errorData?.error || `HTTP ${transcriptionResponse.status}`);
                        }
                        
                        const transcriptionData = await transcriptionResponse.json();
                        const transcriptionId = transcriptionData.id;
                        
                        if (!transcriptionId) {
                            throw new Error("Failed to get transcription ID from Assembly AI");
                        }
                        
                        setStatus('Waiting for Assembly AI transcription to complete...');
                        
                        // Step 5: Poll for transcription completion
                        let completed = false;
                        let attempts = 0;
                        const maxAttempts = 60; // 5 minutes max (5s intervals)
                        
                        while (!completed && attempts < maxAttempts) {
                            await new Promise(resolve => setTimeout(resolve, 5000)); // Wait 5 seconds
                            
                            const pollResponse = await fetch(`${apiUrl}/${transcriptionId}`, {
                                method: 'GET',
                                headers: {
                                    'Authorization': currentAssemblyApiKey
                                }
                            });
                            
                            if (!pollResponse.ok) {
                                const errorData = await pollResponse.json();
                                console.error("Assembly AI Poll Error:", errorData);
                                throw new Error(errorData?.error || `HTTP ${pollResponse.status}`);
                            }
                            
                            const pollData = await pollResponse.json();
                            
                            if (pollData.status === 'completed') {
                                completed = true;
                                transcriptionText = pollData.text || "Transcription not found.";
                                console.log("Assembly AI transcription completed:", transcriptionText);
                            } else if (pollData.status === 'error') {
                                throw new Error(`Assembly AI error: ${pollData.error || 'Unknown error'}`);
                            }
                            
                            attempts++;
                            setStatus(`Waiting for transcription... (${attempts * 5}s)`);
                        }
                        
                        if (!completed) {
                            throw new Error("Transcription timed out after 5 minutes");
                        }
                        
                    } catch (error) {
                        console.error("Assembly AI transcription failed:", error);
                        throw error;
                    }
                }
                
                setStatus(`Transcription complete (ID: ${id}).`);
                displayTranscription(transcriptionText);
                
                // Update recording with transcription and token usage
                const recording = await getRecordingByIdFromDB(id);
                if (recording) {
                    recording.transcription = transcriptionText;
                    recording.tokenUsage = recordingTokenUsage;
                    
                    // Update in database
                    const transaction = db.transaction([STORE_NAME], 'readwrite');
                    const store = transaction.objectStore(STORE_NAME);
                    await new Promise((resolve, reject) => {
                        const request = store.put(recording);
                        request.onsuccess = () => resolve();
                        request.onerror = (event) => reject(event.target.error);
                    });
                }
                
                await renderHistory();
            } catch (error) {
                console.error("Transcription failed:", error);
                setStatus(`Transcription error: ${error.message}`, true);
                displayTranscription(`Error: ${error.message}`);
                transcriptionSection.classList.remove('hidden');
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }

        // --- Utility Functions ---
        function formatDuration(seconds) {
            const min = Math.floor(seconds / 60);
            const sec = Math.floor(seconds % 60);
            return `${min}:${sec.toString().padStart(2, '0')}`;
        }
        
        async function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    // Remove the "data:audio/mpeg;base64," prefix from the data URL
                    const base64data = reader.result.split(',')[1];
                    resolve(base64data);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        // History Actions (Unchanged)
        async function deleteRecording(id) { if (confirm(`Delete recording ${id}?`)) { try { await deleteRecordingFromDB(id); setStatus(`Recording ${id} deleted.`); await renderHistory(); } catch (error) { setStatus('Error deleting.', true); console.error("Delete error:", error); } } }

        // Event Listeners
        recordButton.addEventListener('click', () => {
            if (isRecording) {
                stopRecording();
            } else {
                transcriptionOutput.value = '';
                transcriptionSection.classList.add('hidden');
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
                startRecording();
            }
        });
        
        // Auto-save API keys on input change
        apiKeyInput.addEventListener('input', () => {
            currentApiKey = apiKeyInput.value.trim();
            if (currentApiKey) {
                localStorage.setItem('geminiApiKey', currentApiKey);
                setStatus('Gemini API Key saved.');
            } else {
                localStorage.removeItem('geminiApiKey');
                setStatus('Gemini API Key removed.', true);
            }
        });
        
        openaiApiKeyInput.addEventListener('input', () => {
            currentOpenaiApiKey = openaiApiKeyInput.value.trim();
            if (currentOpenaiApiKey) {
                localStorage.setItem('openaiApiKey', currentOpenaiApiKey);
                setStatus('OpenAI API Key saved.');
            } else {
                localStorage.removeItem('openaiApiKey');
                setStatus('OpenAI API Key removed.', true);
            }
        });
        
        groqApiKeyInput.addEventListener('input', () => {
            currentGroqApiKey = groqApiKeyInput.value.trim();
            if (currentGroqApiKey) {
                localStorage.setItem('groqApiKey', currentGroqApiKey);
                setStatus('Groq API Key saved.');
            } else {
                localStorage.removeItem('groqApiKey');
                setStatus('Groq API Key removed.', true);
            }
        });
        
        // Recording limit input
        recordingLimitInput.addEventListener('input', () => {
            recordingLimit = recordingLimitInput.value.trim();
            if (recordingLimit) {
                localStorage.setItem('recordingLimit', recordingLimit);
                setStatus('Recording limit updated.');
            } else {
                localStorage.removeItem('recordingLimit');
                setStatus('Recording limit reset to auto.');
            }
        });
        
        copyButton.addEventListener('click', () => {
            if (transcriptionOutput.value && !copyButton.disabled) {
                navigator.clipboard.writeText(transcriptionOutput.value).then(() => {
                    setStatus('Copied!');
                    const copyIcon = copyButton.querySelector('[data-lucide="copy"]');
                    const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`;
                    const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`;
                    copyButton.innerHTML = checkIconHTML;
                    lucide.createIcons();
                    setTimeout(() => {
                        copyButton.innerHTML = originalIconHTML;
                        lucide.createIcons();
                    }, 1500);
                }).catch(err => {
                    console.error('Copy failed: ', err);
                    setStatus('Copy failed.', true);
                });
            }
        });
        
        // Settings panel controls
        settingsButton.addEventListener('click', () => {
            settingsVisible = !settingsVisible;
            if (settingsVisible) {
                settingsSection.classList.remove('hidden');
            } else {
                settingsSection.classList.add('hidden');
            }
            lucide.createIcons();
        });
        
        closeSettings.addEventListener('click', () => {
            settingsVisible = false;
            settingsSection.classList.add('hidden');
            lucide.createIcons();
        });
        
        // Dark mode toggle
        const darkModeToggle = document.getElementById('darkModeToggle');
        darkModeToggle.addEventListener('change', () => {
            darkMode = darkModeToggle.checked ? 'dark' : 'system';
            localStorage.setItem('darkMode', darkMode);
            applyTheme();
        });
        
        // FFmpeg toggle
        const ffmpegToggle = document.getElementById('ffmpegToggle');
        ffmpegToggle.addEventListener('change', async () => {
            ffmpegEnabled = ffmpegToggle.checked;
            localStorage.setItem('ffmpegEnabled', ffmpegEnabled);
            
            if (ffmpegEnabled) {
                await loadFFmpeg();
            } else {
                ffmpegStatus.textContent = 'FFmpeg disabled. Audio will not be converted to MP3.';
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = 'Recording enabled (no MP3 conversion)';
                setStatus('Ready to record (no MP3 conversion).');
                updateRecordButtonState();
            }
        });
        
        // API toggles - only one can be active at a time
        geminiToggle.addEventListener('change', () => {
            if (geminiToggle.checked) {
                // Disable other APIs
                openaiToggle.checked = false;
                groqToggle.checked = false;
                assemblyToggle.checked = false;
                openaiEnabled = false;
                groqEnabled = false;
                assemblyEnabled = false;
                openaiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
                assemblySettings.classList.add('hidden');
            }
            
            geminiEnabled = geminiToggle.checked;
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            
            if (geminiEnabled) {
                geminiSettings.classList.remove('hidden');
            } else {
                geminiSettings.classList.add('hidden');
            }
        });
        
        openaiToggle.addEventListener('change', () => {
            if (openaiToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                groqToggle.checked = false;
                assemblyToggle.checked = false;
                geminiEnabled = false;
                groqEnabled = false;
                assemblyEnabled = false;
                geminiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
                assemblySettings.classList.add('hidden');
            }
            
            openaiEnabled = openaiToggle.checked;
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            
            if (openaiEnabled) {
                openaiSettings.classList.remove('hidden');
            } else {
                openaiSettings.classList.add('hidden');
            }
        });
        
        groqToggle.addEventListener('change', () => {
            if (groqToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                openaiToggle.checked = false;
                assemblyToggle.checked = false;
                geminiEnabled = false;
                openaiEnabled = false;
                assemblyEnabled = false;
                geminiSettings.classList.add('hidden');
                openaiSettings.classList.add('hidden');
                assemblySettings.classList.add('hidden');
            }
            
            groqEnabled = groqToggle.checked;
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            
            if (groqEnabled) {
                groqSettings.classList.remove('hidden');
            } else {
                groqSettings.classList.add('hidden');
            }
        });
        
        // OpenAI model change
        openaiModelSelect.addEventListener('change', () => {
            openaiModel = openaiModelSelect.value;
            localStorage.setItem('openaiModel', openaiModel);
        });
        
        // OpenAI language change
        openaiLanguageSelect.addEventListener('change', () => {
            openaiLanguage = openaiLanguageSelect.value;
            localStorage.setItem('openaiLanguage', openaiLanguage);
        });
        
        // Groq model change
        groqModelSelect.addEventListener('change', () => {
            groqModel = groqModelSelect.value;
            localStorage.setItem('groqModel', groqModel);
        });
        
        // Groq language change
        groqLanguageSelect.addEventListener('change', () => {
            groqLanguage = groqLanguageSelect.value;
            localStorage.setItem('groqLanguage', groqLanguage);
        });

        // Assembly AI toggle
        assemblyToggle.addEventListener('change', () => {
            if (assemblyToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                openaiToggle.checked = false;
                groqToggle.checked = false;
                geminiEnabled = false;
                openaiEnabled = false;
                groqEnabled = false;
                geminiSettings.classList.add('hidden');
                openaiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
            }
            
            assemblyEnabled = assemblyToggle.checked;
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            
            if (assemblyEnabled) {
                assemblySettings.classList.remove('hidden');
                // Check if API key is available
                if (!currentAssemblyApiKey) {
                    setStatus('Assembly AI API Key needed.', true);
                    displayTranscription("Assembly AI API Key needed for transcription.");
                } else {
                    setStatus('Assembly AI ready for transcription.');
                }
            } else {
                assemblySettings.classList.add('hidden');
            }
            
            // Update transcription button states
            renderHistory();
        });
        
        // Assembly API key input
        assemblyApiKeyInput.addEventListener('input', () => {
            currentAssemblyApiKey = assemblyApiKeyInput.value.trim();
            if (currentAssemblyApiKey) {
                localStorage.setItem('assemblyApiKey', currentAssemblyApiKey);
                setStatus('Assembly AI API Key saved.');
            } else {
                localStorage.removeItem('assemblyApiKey');
                setStatus('Assembly AI API Key removed.', true);
            }
        });
        
        // Assembly EU server toggle
        assemblyEuToggle.addEventListener('change', () => {
            assemblyEuServer = assemblyEuToggle.checked;
            localStorage.setItem('assemblyEuServer', assemblyEuServer);
            setStatus(`Assembly AI server set to ${assemblyEuServer ? 'EU' : 'US'}.`);
        });
        
        // Assembly language change
        assemblyLanguageSelect.addEventListener('change', () => {
            assemblyLanguage = assemblyLanguageSelect.value;
            localStorage.setItem('assemblyLanguage', assemblyLanguage);
        });

        // Initialization
        async function initializeApp() {
            lucide.createIcons();
            apiKeyInput.value = currentApiKey;
            openaiApiKeyInput.value = currentOpenaiApiKey;
            groqApiKeyInput.value = currentGroqApiKey;
            assemblyApiKeyInput.value = currentAssemblyApiKey;
            openaiModelSelect.value = openaiModel;
            openaiLanguageSelect.value = openaiLanguage;
            groqModelSelect.value = groqModel;
            groqLanguageSelect.value = groqLanguage;
            assemblyLanguageSelect.value = assemblyLanguage;
            assemblyEuToggle.checked = assemblyEuServer;
            recordingLimitInput.value = recordingLimit;
            
            // Set dark mode toggle state
            darkModeToggle.checked = darkMode === 'dark';
            applyTheme();
            
            // Set FFmpeg toggle state
            ffmpegToggle.checked = ffmpegEnabled;
            
            // Set API toggles
            geminiToggle.checked = geminiEnabled;
            openaiToggle.checked = openaiEnabled;
            groqToggle.checked = groqEnabled;
            assemblyToggle.checked = assemblyEnabled;
            
            // Show/hide API settings based on toggles
            if (geminiEnabled) {
                geminiSettings.classList.remove('hidden');
            } else {
                geminiSettings.classList.add('hidden');
            }
            if (openaiEnabled) {
                openaiSettings.classList.remove('hidden');
            } else {
                openaiSettings.classList.add('hidden');
            }
            if (groqEnabled) {
                groqSettings.classList.remove('hidden');
            } else {
                groqSettings.classList.add('hidden');
            }
            if (assemblyEnabled) {
                assemblySettings.classList.remove('hidden');
                // Check if API key is available
                if (!currentAssemblyApiKey) {
                    setStatus('Assembly AI API Key needed.', true);
                    displayTranscription("Assembly AI API Key needed for transcription.");
                } else {
                    setStatus('Assembly AI ready for transcription.');
                }
            } else {
                assemblySettings.classList.add('hidden');
            }
            
            // Show settings if no API key or if FFmpeg needs attention
            if ((geminiEnabled && !currentApiKey) || 
                (openaiEnabled && !currentOpenaiApiKey) || 
                (groqEnabled && !currentGroqApiKey) || 
                (assemblyEnabled && !currentAssemblyApiKey)) {
                settingsSection.classList.remove('hidden');
                settingsVisible = true;
            }
            
            // Set up drag and drop for file upload
            setupDragAndDrop();
            
            // Set initial status based on FFmpeg toggle state
            if (ffmpegEnabled) {
                await loadFFmpeg(); // Load FFmpeg if enabled
            } else {
                // FFmpeg is disabled, enable recording without conversion
                ffmpegStatus.textContent = 'FFmpeg disabled. Audio will not be converted to MP3.';
                ffmpegLoaded = false;
                setStatus('Ready to record (no MP3 conversion).');
                recordButton.disabled = false;
                recordButton.title = 'Recording enabled (no MP3 conversion)';
            }
            
            try {
                await initDB();
                await renderHistory();
            } catch (error) {
                setStatus('DB init failed.', true);
            }
            
            // Update the record button state after initialization
            updateRecordButtonState();
            
            // Check if any API is enabled and has a key
            const hasValidApiKey = (geminiEnabled && currentApiKey) || 
                                 (openaiEnabled && currentOpenaiApiKey) || 
                                 (groqEnabled && currentGroqApiKey) || 
                                 (assemblyEnabled && currentAssemblyApiKey);
            
            if (!hasValidApiKey) {
                setStatus('API Key needed for transcription.', true);
                displayTranscription("API Key needed for transcription.");
            } else if (assemblyEnabled && currentAssemblyApiKey) {
                setStatus('Assembly AI ready for transcription.');
            }
            
            // Mic support checks - these will disable the button if mic isn't available
            if (!navigator.mediaDevices?.getUserMedia) {
                setStatus('getUserMedia not supported.', true);
                recordButton.disabled = true;
                recordButton.title = 'Not supported';
            } else if (!window.MediaRecorder) {
                setStatus('MediaRecorder not supported.', true);
                recordButton.disabled = true;
                recordButton.title = 'Not supported';
            } else {
                try {
                    const ps = await navigator.permissions.query({ name: 'microphone' });
                    console.log('Mic perm state:', ps.state);
                    if (ps.state === 'denied') setStatus('Mic denied.', true);
                    ps.onchange = () => {
                        console.log('Mic perm changed:', ps.state);
                        if (ps.state === 'denied') setStatus('Mic denied.', true);
                        else if (statusMessage.textContent.includes('denied')) setStatus('Mic granted.', false);
                    };
                } catch (e) {
                    console.warn("Perm query failed:", e);
                }
            }
        }
        document.addEventListener('DOMContentLoaded', initializeApp);

        // Update token display
        function updateTokenDisplay() {
            const savedUsage = localStorage.getItem('tokenUsage');
            if (savedUsage) {
                tokenUsage = JSON.parse(savedUsage);
            }
            document.getElementById('inputTokens').textContent = tokenUsage.input.toLocaleString();
            document.getElementById('outputTokens').textContent = tokenUsage.output.toLocaleString();
        }
        
        // Apply theme based on system preference or user choice
        function applyTheme() {
            if (darkMode === 'dark') {
                document.body.classList.add('dark-mode');
            } else if (darkMode === 'system') {
                if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                    document.body.classList.add('dark-mode');
                } else {
                    document.body.classList.remove('dark-mode');
                }
            } else {
                document.body.classList.remove('dark-mode');
            }
        }
        
        // Listen for system theme changes
        if (window.matchMedia) {
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {
                if (darkMode === 'system') {
                    if (e.matches) {
                        document.body.classList.add('dark-mode');
                    } else {
                        document.body.classList.remove('dark-mode');
                    }
                }
            });
        }

        // --- File Upload with Drag and Drop ---
        function setupDragAndDrop() {
            const dropZone = recordButtonContainer;
            
            // Prevent default drag behaviors
            ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
                dropZone.addEventListener(eventName, preventDefaults, false);
                document.body.addEventListener(eventName, preventDefaults, false);
            });
            
            // Highlight drop zone when item is dragged over it
            ['dragenter', 'dragover'].forEach(eventName => {
                dropZone.addEventListener(eventName, highlight, false);
            });
            
            ['dragleave', 'drop'].forEach(eventName => {
                dropZone.addEventListener(eventName, unhighlight, false);
            });
            
            // Handle dropped files
            dropZone.addEventListener('drop', handleDrop, false);
            
            function preventDefaults(e) {
                e.preventDefault();
                e.stopPropagation();
            }
            
            function highlight() {
                isDraggingFile = true;
                dropZoneOverlay.classList.remove('hidden');
            }
            
            function unhighlight() {
                isDraggingFile = false;
                dropZoneOverlay.classList.add('hidden');
            }
            
            async function handleDrop(e) {
                const dt = e.dataTransfer;
                const files = dt.files;
                
                if (files.length === 0) {
                    setStatus('No file detected.', true);
                    return;
                }
                
                if (files.length > 1) {
                    setStatus('Please drop only one file.', true);
                    return;
                }
                
                const file = files[0];
                
                // Check if it's an audio file
                if (!file.type.startsWith('audio/')) {
                    setStatus('Please upload an audio file.', true);
                    return;
                }
                
                // Check file size based on selected API
                const selectedAPI = getSelectedAPI();
                const maxSize = FILE_SIZE_LIMITS[selectedAPI];
                
                if (file.size > maxSize) {
                    setStatus(`File too large for ${selectedAPI}. Max: ${formatFileSize(maxSize)}.`, true);
                    return;
                }
                
                setStatus('Processing uploaded file...');
                
                try {
                    // Add the file directly to the database without conversion
                    const newId = await addRecordingToDB(file, file.type);
                    setStatus(`File uploaded (ID: ${newId}).`);
                    await renderHistory();
                    
                    // Attempt automatic transcription if API key is available
                    if ((geminiEnabled && currentApiKey) || 
                        (openaiEnabled && currentOpenaiApiKey) || 
                        (groqEnabled && currentGroqApiKey) || 
                        (assemblyEnabled && currentAssemblyApiKey)) {
                        setStatus(`Starting automatic transcription for file ${newId}...`);
                        await transcribeAudio(newId, file, file.type);
                    } else {
                        setStatus('File uploaded. Add an API key to enable transcription.', true);
                        displayTranscription("API Key needed for transcription.");
                    }
                } catch (error) {
                    console.error("Error processing uploaded file:", error);
                    setStatus(`Error processing file: ${error.message}`, true);
                }
            }
        }
        
        function getSelectedAPI() {
            if (geminiEnabled) return 'gemini';
            if (openaiEnabled) return 'openai';
            if (groqEnabled) return 'groq';
            if (assemblyEnabled) return 'assembly';
            return 'gemini'; // Default
        }
        
        function formatFileSize(bytes) {
            if (bytes < 1024) return bytes + ' B';
            if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
            return (bytes / (1024 * 1024)).toFixed(1) + ' MB';
        }

    </script>
</body>
</html>
