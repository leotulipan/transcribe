<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Recorder & Transcriber (MP3)</title>
    <script src="https://cdn.tailwindcss.com?plugins=forms"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://unpkg.com/@ffmpeg/ffmpeg@0.11.0/dist/ffmpeg.min.js"></script>

    <style>
        /* Styles (pulse, scrollbar, layout, disabled, lucide, ffmpegLog) remain the same */
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
        .recording-pulse { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        .history-list::-webkit-scrollbar { width: 8px; }
        .history-list::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb { background: #888; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb:hover { background: #555; }
        html, body { height: 100%; margin: 0; font-family: sans-serif; }
        .main-container { display: flex; flex-direction: column; min-height: 100vh; }
        .content-grow { flex-grow: 1; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        [data-lucide] { width: 1em; height: 1em; display: inline-block; vertical-align: middle; }
        #ffmpegLog { font-family: monospace; font-size: 0.75rem; max-height: 100px; overflow-y: auto; background-color: #f5f5f5; border: 1px solid #e0e0e0; padding: 5px; margin-top: 10px; white-space: pre-wrap; word-break: break-all; }
    </style>
</head>
<body class="bg-gray-100">
    <div class="main-container container mx-auto p-4 md:p-8 max-w-4xl">

        <header class="mb-8 text-center relative">
            <h1 class="text-3xl font-bold text-gray-800">Voice Recorder & Transcriber (MP3)</h1>
            <p class="text-gray-600">Record audio, convert to MP3 (VBR ~q1), save locally, and transcribe using Gemini.</p>
            <button id="settingsButton" class="absolute top-0 right-0 p-2 text-gray-600 hover:text-gray-800 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                <i data-lucide="settings" style="width: 24px; height: 24px;"></i>
            </button>
        </header>

        <section id="settingsSection" class="mb-6 p-4 bg-white rounded-lg shadow hidden">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-xl font-semibold text-gray-700">Settings</h2>
                <button id="closeSettings" class="p-1 text-gray-600 hover:text-gray-800 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                    <i data-lucide="x" style="width: 20px; height: 20px;"></i>
                </button>
            </div>
            
            <div id="apiKeySection" class="mb-4">
                <label for="apiKey" class="block text-sm font-medium text-gray-700 mb-1">Gemini API Key:</label>
                <div class="flex items-center space-x-2">
                    <input type="password" id="apiKey" name="apiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your API key">
                    <button id="saveApiKey" class="px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">Save</button>
                </div>
                <p class="text-xs text-gray-500 mt-2">Your API key is stored only in your browser's local storage and is required for transcription.</p>
            </div>

            <div id="ffmpegSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 mb-2">FFmpeg Status:</h3>
                <p id="ffmpegStatus" class="text-sm text-gray-600">Loading FFmpeg...</p>
                <div id="ffmpegLog" class="hidden text-left mt-2"></div>
            </div>

            <div id="tokenUsageSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 mb-2">Token Usage:</h3>
                <p class="text-xs text-gray-600">
                    Input Tokens: <span id="inputTokens">0</span><br>
                    Output Tokens: <span id="outputTokens">0</span>
                </p>
            </div>
        </section>

        <section class="mb-6 p-6 bg-white rounded-lg shadow text-center">
            <h2 class="text-xl font-semibold mb-4 text-gray-700">Record Audio</h2>
            <button id="recordButton" class="p-4 bg-red-600 text-white rounded-full hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-red-500 transition duration-150 ease-in-out disabled:bg-gray-400" disabled> <i id="micIconPlaceholder" data-lucide="mic" style="width: 32px; height: 32px;"></i>
            </button>
            <p id="statusMessage" class="mt-3 text-gray-600 h-5">Loading FFmpeg...</p> <div id="ffmpegLog" class="hidden text-left"></div>
        </section>

        <section id="transcriptionSection" class="mb-6 p-4 bg-white rounded-lg shadow hidden">
             <h2 class="text-xl font-semibold mb-2 text-gray-700">Transcription</h2>
             <div class="relative">
                <textarea id="transcriptionOutput" rows="4" class="w-full p-2 border border-gray-300 rounded-md bg-gray-50 resize-none" readonly placeholder="Transcription will appear here..."></textarea>
                <button id="copyButton" title="Copy to Clipboard" class="absolute top-2 right-2 p-1 bg-gray-200 text-gray-600 rounded hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500 opacity-50 cursor-not-allowed" disabled>
                    <i data-lucide="copy" style="width: 18px; height: 18px;"></i>
                </button>
             </div>
        </section>

        <section class="content-grow p-4 bg-white rounded-lg shadow flex flex-col">
            <h2 class="text-xl font-semibold mb-4 text-gray-700 flex-shrink-0">Recording History (MP3)</h2>
            <div id="historyList" class="history-list flex-grow overflow-y-auto space-y-3 pr-2">
                <p id="noHistoryMessage" class="text-gray-500">No recordings yet.</p>
            </div>
        </section>

        <footer class="mt-8 text-center text-sm text-gray-500">
            <p>App by Gemini. Uses browser storage and requires Gemini API Key for transcription.</p>
        </footer>

    </div> <script>
        // --- DOM Elements (Unchanged) ---
        const apiKeyInput = document.getElementById('apiKey');
        const saveApiKeyButton = document.getElementById('saveApiKey');
        const recordButton = document.getElementById('recordButton');
        const statusMessage = document.getElementById('statusMessage');
        const transcriptionSection = document.getElementById('transcriptionSection');
        const transcriptionOutput = document.getElementById('transcriptionOutput');
        const copyButton = document.getElementById('copyButton');
        const historyList = document.getElementById('historyList');
        const noHistoryMessage = document.getElementById('noHistoryMessage');
        const ffmpegLog = document.getElementById('ffmpegLog');
        const settingsButton = document.getElementById('settingsButton');
        const settingsSection = document.getElementById('settingsSection');
        const closeSettings = document.getElementById('closeSettings');
        const ffmpegStatus = document.getElementById('ffmpegStatus');

        // --- State Variables (Unchanged) ---
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let currentApiKey = localStorage.getItem('geminiApiKey') || '';
        let db;
        let ffmpeg;
        let ffmpegLoaded = false;
        let currentlyPlayingAudio = null;
        let currentlyPlayingButton = null;
        let tokenUsage = { input: 0, output: 0 }; // Track token usage

        // --- Constants ---
        const DB_NAME = 'VoiceRecorderDB_MP3';
        const DB_VERSION = 1;
        const STORE_NAME = 'recordings_mp3';
        const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=';
        const TARGET_MIME_TYPE = 'audio/mpeg';
        const TARGET_FORMAT = 'mp3';
        // const TARGET_BITRATE = '256k'; // Replaced by quality setting
        const TARGET_QUALITY = '1'; // VBR quality setting (-q:a 1)
        const TARGET_CHANNELS = 1;

        // --- FFmpeg Initialization ---
        async function loadFFmpeg() {
            ffmpegStatus.textContent = 'Loading FFmpeg (approx. 30MB)...';
            recordButton.disabled = true;
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = 'Initializing FFmpeg library...\n';

            try {
                if (typeof FFmpeg === 'undefined' || typeof FFmpeg.createFFmpeg === 'undefined') {
                     throw new Error("FFmpeg library script not loaded correctly.");
                }
                const { createFFmpeg } = FFmpeg;

                const corePath = 'https://unpkg.com/@ffmpeg/core@0.11.0/dist/ffmpeg-core.js';
                ffmpegLog.textContent += `Attempting to load core from: ${corePath}\n (This avoids SharedArrayBuffer issues but is slower)\n`;

                ffmpeg = createFFmpeg({
                    log: true,
                    logger: ({ type, message }) => {
                        console.log(`FFmpeg log [${type}]: ${message}`);
                        if(ffmpegLog.textContent.length > 5000) ffmpegLog.textContent = '';
                        ffmpegLog.textContent += message + '\n';
                        ffmpegLog.scrollTop = ffmpegLog.scrollHeight;
                    },
                    progress: ({ ratio }) => {
                         console.log(`FFmpeg progress: ${(ratio * 100).toFixed(2)}%`);
                         if (ratio > 0 && ratio < 1) {
                            ffmpegStatus.textContent = `Loading FFmpeg... ${(ratio * 100).toFixed(0)}%`;
                         }
                    },
                    corePath: corePath,
                });

                ffmpegLog.textContent += 'Loading FFmpeg core...\n';
                await ffmpeg.load();
                ffmpegLog.textContent += 'FFmpeg core loaded successfully.\n';
                ffmpegLoaded = true;
                ffmpegStatus.textContent = 'FFmpeg loaded successfully';
                setStatus('Ready to record.');
                recordButton.disabled = false;

            } catch (error) {
                console.error("Error loading FFmpeg:", error);
                if (error instanceof ReferenceError && error.message.includes("SharedArrayBuffer")) {
                     ffmpegStatus.textContent = 'FFmpeg failed: SharedArrayBuffer missing. Need server COOP/COEP headers.';
                     ffmpegLog.textContent += `ERROR: SharedArrayBuffer not defined. This usually means the server is not sending the required COOP and COEP headers. See console and explanation above the code.\n`;
                } else {
                    ffmpegStatus.textContent = 'Failed to load FFmpeg. Conversion unavailable.';
                    ffmpegLog.textContent += `Error loading FFmpeg: ${error}\n`;
                }
                ffmpegLoaded = false;
                recordButton.disabled = true;
                recordButton.title = 'FFmpeg failed to load, recording disabled.';
            }
        }


        // --- IndexedDB Initialization (Unchanged) ---
        function initDB() {
            return new Promise((resolve, reject) => {
                const request = indexedDB.open(DB_NAME, DB_VERSION);
                request.onerror = (event) => { console.error("IndexedDB error:", event.target.error); setStatus('Error initializing local database.', true); reject(event.target.error); };
                request.onsuccess = (event) => { db = event.target.result; console.log("Database initialized successfully:", DB_NAME); resolve(db); };
                request.onupgradeneeded = (event) => {
                    db = event.target.result;
                    if (!db.objectStoreNames.contains(STORE_NAME)) {
                        const objectStore = db.createObjectStore(STORE_NAME, { keyPath: 'id', autoIncrement: true });
                        objectStore.createIndex('timestamp', 'timestamp', { unique: false });
                        console.log("Object store created:", STORE_NAME);
                    }
                };
            });
        }

        // --- IndexedDB Operations (Unchanged) ---
        function addRecordingToDB(blob, mimeType) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite'); const store = transaction.objectStore(STORE_NAME);
                const recording = { audioBlob: blob, mimeType: mimeType, timestamp: new Date(), transcription: null };
                const request = store.add(recording);
                request.onsuccess = (event) => resolve(event.target.result); request.onerror = (event) => reject(event.target.error);
            });
        }
        function getRecordingsFromDB() {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly'); const store = transaction.objectStore(STORE_NAME);
                const request = store.getAll();
                request.onsuccess = (event) => resolve(event.target.result.sort((a, b) => b.timestamp - a.timestamp)); request.onerror = (event) => reject(event.target.error);
            });
        }
         function getRecordingByIdFromDB(id) {
             return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly'); const store = transaction.objectStore(STORE_NAME);
                const request = store.get(id);
                request.onsuccess = (event) => resolve(event.target.result); request.onerror = (event) => reject(event.target.error);
            });
        }
        function updateTranscriptionInDB(id, transcription) {
             return new Promise(async (resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                try {
                    const recording = await getRecordingByIdFromDB(id); if (!recording) return reject(`Recording ${id} not found.`);
                    recording.transcription = transcription;
                    const transaction = db.transaction([STORE_NAME], 'readwrite'); const store = transaction.objectStore(STORE_NAME);
                    const request = store.put(recording); request.onsuccess = () => resolve(); request.onerror = (event) => reject(event.target.error);
                } catch (error) { reject(error); }
            });
        }
        function deleteRecordingFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite'); const store = transaction.objectStore(STORE_NAME);
                const request = store.delete(id); request.onsuccess = () => resolve(); request.onerror = (event) => reject(event.target.error);
            });
        }

        // --- UI Update Functions (Unchanged) ---
        function setStatus(message, isError = false) { statusMessage.textContent = message; statusMessage.className = `mt-3 h-5 ${isError ? 'text-red-600' : 'text-gray-600'}`; }
        function updateRecordButtonState() {
            const micIconElement = recordButton.querySelector('[data-lucide="mic"]');
            if (isRecording) {
                recordButton.classList.remove('bg-red-600', 'hover:bg-red-700');
                recordButton.classList.add('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                if (micIconElement) micIconElement.classList.add('animate-pulse');
                setStatus('Recording...');
                recordButton.disabled = false; // Ensure button is enabled during recording
            } else {
                if (!statusMessage.textContent.includes('FFmpeg') && !statusMessage.textContent.includes('Converting')) {
                    setStatus('Click the mic to record');
                }
                recordButton.classList.remove('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                recordButton.classList.add('bg-red-600', 'hover:bg-red-700');
                if (micIconElement) micIconElement.classList.remove('animate-pulse');
                recordButton.disabled = !ffmpegLoaded; // Only disable if FFmpeg is not loaded
            }
        }
        function displayTranscription(text) {
            transcriptionOutput.value = text || "No transcription available.";
            transcriptionSection.classList.remove('hidden');
            
            if (text && text !== "API Key needed." && !text.startsWith("Error:")) {
                copyButton.disabled = false;
                copyButton.classList.remove('opacity-50', 'cursor-not-allowed');
                copyButton.classList.add('opacity-100', 'cursor-pointer');
                
                // Automatically copy to clipboard
                navigator.clipboard.writeText(text).then(() => {
                    setStatus('Transcription copied to clipboard!');
                    const copyIcon = copyButton.querySelector('[data-lucide="copy"]');
                    const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`;
                    const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`;
                    copyButton.innerHTML = checkIconHTML;
                    lucide.createIcons();
                    setTimeout(() => {
                        copyButton.innerHTML = originalIconHTML;
                        lucide.createIcons();
                    }, 1500);
                }).catch(err => {
                    console.error('Auto-copy failed: ', err);
                    setStatus('Auto-copy failed.', true);
                });
            } else {
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }
        async function renderHistory() {
             try {
                const recordings = await getRecordingsFromDB(); 
                historyList.innerHTML = '';
                
                if (recordings.length === 0) { 
                    noHistoryMessage.classList.remove('hidden'); 
                    historyList.appendChild(noHistoryMessage); 
                } else {
                    noHistoryMessage.classList.add('hidden');
                    
                    recordings.forEach(rec => {
                        const div = document.createElement('div'); 
                        div.className = 'p-3 bg-gray-50 border border-gray-200 rounded-md flex items-center justify-between space-x-3';
                        
                        const infoDiv = document.createElement('div'); 
                        infoDiv.className = 'flex-grow min-w-0';
                        
                        const time = document.createElement('p'); 
                        time.className = 'text-sm font-medium text-gray-800 truncate'; 
                        time.textContent = `Recorded MP3: ${rec.timestamp.toLocaleString()}`; 
                        time.title = `MP3 Recorded: ${rec.timestamp.toLocaleString()}`;
                        
                        // Add file size and duration info
                        const fileInfo = document.createElement('p');
                        fileInfo.className = 'text-xs text-gray-500';
                        
                        // Calculate file size
                        const fileSizeMB = (rec.audioBlob.size / (1024 * 1024)).toFixed(2);
                        
                        // Create audio element to get duration
                        const audio = new Audio(URL.createObjectURL(rec.audioBlob));
                        audio.onloadedmetadata = () => {
                            const duration = audio.duration;
                            const minutes = Math.floor(duration / 60);
                            const seconds = Math.floor(duration % 60);
                            const durationStr = `${minutes}:${seconds.toString().padStart(2, '0')}`;
                            fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: ${durationStr}`;
                            URL.revokeObjectURL(audio.src);
                        };
                        
                        const transcriptionPreview = document.createElement('p'); 
                        transcriptionPreview.className = 'text-xs text-gray-500 italic truncate'; 
                        transcriptionPreview.textContent = rec.transcription ? `"${rec.transcription.substring(0, 60)}..."` : 'Not transcribed yet'; 
                        if(rec.transcription) transcriptionPreview.title = rec.transcription;
                        
                        // Append elements in the correct order
                        infoDiv.appendChild(time);
                        infoDiv.appendChild(fileInfo);
                        infoDiv.appendChild(transcriptionPreview);
                        
                        const controlsDiv = document.createElement('div'); 
                        controlsDiv.className = 'flex-shrink-0 flex items-center space-x-2';
                        
                        const playButton = document.createElement('button');
                        playButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        playButton.className = 'p-1.5 bg-green-100 text-green-700 rounded hover:bg-green-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-green-500';
                        playButton.title = 'Play MP3 Audio';
                        playButton.onclick = () => playAudio(rec.audioBlob, playButton);

                        const downloadButton = document.createElement('button');
                        downloadButton.innerHTML = `<i data-lucide="download" style="width: 18px; height: 18px;"></i>`;
                        downloadButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        downloadButton.title = 'Download MP3';
                        downloadButton.onclick = () => {
                            const url = URL.createObjectURL(rec.audioBlob);
                            const a = document.createElement('a');
                            a.href = url;
                            a.download = `recording_${rec.id}_${rec.timestamp.toISOString().slice(0,19).replace(/[:]/g, '-')}.mp3`;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        };

                        const transcribeButton = document.createElement('button');
                        transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                        transcribeButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        transcribeButton.title = 'Transcribe Audio';
                        transcribeButton.onclick = (e) => {
                            if (rec.transcription) {
                                displayTranscription(rec.transcription);
                                return;
                            }
                            transcribeButton.disabled = true;
                            transcribeButton.innerHTML = '...';
                            transcribeAudio(rec.id, rec.audioBlob, rec.mimeType).finally(() => {
                                transcribeButton.disabled = false;
                                transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                                lucide.createIcons();
                            });
                        };
                        transcribeButton.disabled = !currentApiKey || !ffmpegLoaded;
                        if (!currentApiKey) transcribeButton.title = 'API Key required';
                        else if (!ffmpegLoaded) transcribeButton.title = 'FFmpeg not loaded';
                        else if (rec.transcription) transcribeButton.title = 'View Transcription';

                        const deleteButton = document.createElement('button');
                        deleteButton.innerHTML = `<i data-lucide="trash-2" style="width: 18px; height: 18px;"></i>`;
                        deleteButton.className = 'p-1.5 bg-red-100 text-red-700 rounded hover:bg-red-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-red-500';
                        deleteButton.title = 'Delete Recording';
                        deleteButton.onclick = () => deleteRecording(rec.id);

                        controlsDiv.appendChild(playButton);
                        controlsDiv.appendChild(downloadButton);
                        controlsDiv.appendChild(transcribeButton);
                        controlsDiv.appendChild(deleteButton);
                        
                        div.appendChild(infoDiv);
                        div.appendChild(controlsDiv);
                        historyList.appendChild(div);
                    });
                    
                    lucide.createIcons();
                }
            } catch (error) { 
                console.error("Error rendering history:", error); 
                setStatus('Could not load history.', true); 
                noHistoryMessage.classList.remove('hidden'); 
                historyList.appendChild(noHistoryMessage); 
            }
        }

        // --- Audio Handling ---
        async function startRecording() { // Unchanged
             if (!ffmpegLoaded) { setStatus('FFmpeg not loaded. Cannot record.', true); return; }
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true }); console.log("Mic access granted.");
                const options = { mimeType: 'audio/webm;codecs=opus' };
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/ogg;codecs=opus';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/webm';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = '';
                console.log("Recording with MIME type:", options.mimeType || "Browser Default");
                mediaRecorder = new MediaRecorder(stream, options); audioChunks = [];
                mediaRecorder.ondataavailable = event => { if (event.data.size > 0) audioChunks.push(event.data); };
                mediaRecorder.onstop = async () => {
                    const originalBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });
                    const originalMimeType = mediaRecorder.mimeType || 'audio/webm';
                    console.log("Recording stopped. Original Blob:", originalBlob); console.log("Original MIME type:", originalMimeType);
                    stream.getTracks().forEach(track => track.stop());
                    await convertAudioAndSave(originalBlob, originalMimeType); // Convert and save
                    updateRecordButtonState(); // Update button state after conversion attempt
                };
                mediaRecorder.onerror = (event) => { console.error("MediaRecorder error:", event.error); setStatus(`Recording error: ${event.error?.name || 'Unknown'}`, true); isRecording = false; updateRecordButtonState(); stream.getTracks().forEach(track => track.stop()); };
                mediaRecorder.start(); isRecording = true; updateRecordButtonState();
            } catch (err) { /* Error handling for getUserMedia (unchanged) */
                console.error("Mic error:", err); console.error("Details:", JSON.stringify(err)); console.error("Name:", err?.name); console.error("Message:", err?.message); let msg = 'Error starting recording.'; if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') msg = 'Mic access denied.'; else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') msg = 'No mic found.'; else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') msg = 'Mic in use.'; else if (err.message) msg = `Error: ${err.message}`; else msg = 'Unknown mic error.'; setStatus(msg, true); isRecording = false; updateRecordButtonState();
            }
        }
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                try {
                    mediaRecorder.stop();
                    isRecording = false;
                    setStatus('Processing recording...');
                    updateRecordButtonState();
                } catch (error) {
                    console.error("Error stopping recorder:", error);
                    setStatus('Error stopping recording.', true);
                    isRecording = false;
                    updateRecordButtonState();
                    if (mediaRecorder?.stream) {
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    }
                }
            }
        }

        // --- FFmpeg Conversion Function ---
        async function convertAudioAndSave(originalBlob, originalMimeType) {
            if (!ffmpegLoaded || !ffmpeg) {
                setStatus('FFmpeg not ready. Cannot convert/save.', true);
                updateRecordButtonState();
                return;
            }
            setStatus('Converting audio to MP3...');
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = `Starting conversion of ${originalMimeType}...\n`;
            // Don't disable the button here, let updateRecordButtonState handle it
            updateRecordButtonState();

            try {
                const arrayBuffer = await originalBlob.arrayBuffer();
                const inputData = new Uint8Array(arrayBuffer);
                const inputFilename = `input.${originalMimeType.split('/')[1]?.split(';')[0] || 'bin'}`;
                const outputFilename = `output.${TARGET_FORMAT}`;

                ffmpegLog.textContent += `Writing input file (${inputFilename})...\n`;
                await ffmpeg.FS('writeFile', inputFilename, inputData);
                ffmpegLog.textContent += `Input file written.\n`;

                const ffmpegCommand = [
                    '-i', inputFilename,
                    '-ac', `${TARGET_CHANNELS}`,
                    '-q:a', TARGET_QUALITY,
                    outputFilename
                ];

                ffmpegLog.textContent += `Running FFmpeg: ffmpeg ${ffmpegCommand.join(' ')}\n`;
                await ffmpeg.run(...ffmpegCommand);
                ffmpegLog.textContent += `FFmpeg execution finished.\n`;

                ffmpegLog.textContent += `Reading output file (${outputFilename})...\n`;
                const outputData = ffmpeg.FS('readFile', outputFilename);
                ffmpegLog.textContent += `Output file read (${outputData.length} bytes).\n`;

                const mp3Blob = new Blob([outputData.buffer], { type: TARGET_MIME_TYPE });
                console.log("Conversion successful. MP3 Blob created:", mp3Blob);

                try {
                    await ffmpeg.FS('unlink', inputFilename);
                    await ffmpeg.FS('unlink', outputFilename);
                    ffmpegLog.textContent += `Cleaned up virtual files.\n`;
                } catch (cleanupError) {
                    console.warn("FFmpeg cleanup warning:", cleanupError);
                    ffmpegLog.textContent += `Cleanup warning: ${cleanupError.message}\n`;
                }

                setStatus('Saving converted MP3...');
                const newId = await addRecordingToDB(mp3Blob, TARGET_MIME_TYPE);
                setStatus(`MP3 recording saved (ID: ${newId}).`);
                await renderHistory();

                // Attempt automatic transcription if API key is available
                if (currentApiKey) {
                    setStatus(`Starting automatic transcription for recording ${newId}...`);
                    await transcribeAudio(newId, mp3Blob, TARGET_MIME_TYPE);
                } else {
                    setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                    displayTranscription("API Key needed for transcription.");
                }

            } catch (error) {
                console.error("FFmpeg conversion failed:", error);
                setStatus(`Error during MP3 conversion: ${error.message || error}`, true);
                ffmpegLog.textContent += `ERROR: ${error.message || error}\n`;
            } finally {
                updateRecordButtonState();
            }
        }

        function playAudio(blob, button) {
            try {
                // If there's already an audio playing, stop it
                if (currentlyPlayingAudio) {
                    currentlyPlayingAudio.pause();
                    currentlyPlayingAudio.currentTime = 0;
                    if (currentlyPlayingButton) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                    }
                }

                // If clicking the same button that's currently playing, just stop
                if (currentlyPlayingButton === button) {
                    currentlyPlayingAudio = null;
                    currentlyPlayingButton = null;
                    return;
                }

                // Create and play new audio
                const audioUrl = URL.createObjectURL(blob);
                const audio = new Audio(audioUrl);
                
                audio.onerror = (e) => {
                    console.error("Audio play error:", e);
                    setStatus('Error playing audio.', true);
                    URL.revokeObjectURL(audioUrl);
                };
                
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    if (currentlyPlayingButton === button) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                        currentlyPlayingAudio = null;
                        currentlyPlayingButton = null;
                    }
                };

                audio.play();
                currentlyPlayingAudio = audio;
                currentlyPlayingButton = button;
                button.innerHTML = `<i data-lucide="pause" style="width: 18px; height: 18px;"></i>`;
                lucide.createIcons();
            } catch (error) {
                console.error("Audio object error:", error);
                setStatus('Could not play audio.', true);
            }
        }

        // --- Transcription (Unchanged logic, sends MP3) ---
        async function transcribeAudio(id, audioBlob, mimeType) {
            if (!currentApiKey) { setStatus('API Key needed.', true); displayTranscription("API Key needed."); return; }
            if (!audioBlob) { setStatus('Invalid audio.', true); return; }
            if (!ffmpegLoaded) { setStatus('FFmpeg not loaded.', true); return;}
            setStatus(`Transcribing recording ${id}...`); displayTranscription("Transcribing..."); transcriptionSection.classList.remove('hidden'); copyButton.disabled = true; copyButton.classList.add('opacity-50', 'cursor-not-allowed'); copyButton.classList.remove('opacity-100', 'cursor-pointer');

            try {
                const base64Audio = await blobToBase64(audioBlob);
                const requestBody = { contents: [{ parts: [ { text: "Please transcribe the following audio recording:" }, { inline_data: { mime_type: mimeType, data: base64Audio } } ]}] };
                const response = await fetch(GEMINI_API_URL + currentApiKey, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(requestBody) });
                const data = await response.json();
                if (!response.ok) { console.error("API Error:", data); throw new Error(data?.error?.message || `HTTP ${response.status}`); }
                
                // Update token usage
                if (data.usage) {
                    tokenUsage.input += data.usage.promptTokenCount || 0;
                    tokenUsage.output += data.usage.candidatesTokenCount || 0;
                    localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                }
                
                let transcriptionText = "Transcription not found.";
                if (data.candidates?.[0]?.content?.parts?.[0]?.text) { transcriptionText = data.candidates[0].content.parts[0].text; }
                else if (data.candidates?.[0]?.finishReason === "SAFETY") { transcriptionText = "Blocked: safety."; }
                else { console.warn("Unexpected API response:", data); const textPart = data.candidates?.[0]?.content?.parts?.find(p => p.text); if (textPart) transcriptionText = textPart.text; }
                
                console.log("Transcription OK:", transcriptionText);
                setStatus(`Transcription complete (ID: ${id}).`);
                displayTranscription(transcriptionText);
                await updateTranscriptionInDB(id, transcriptionText);
                await renderHistory();
            } catch (error) { console.error("Transcription failed:", error); setStatus(`Transcription error: ${error.message}`, true); displayTranscription(`Error: ${error.message}`); transcriptionSection.classList.remove('hidden'); copyButton.disabled = true; copyButton.classList.add('opacity-50', 'cursor-not-allowed'); copyButton.classList.remove('opacity-100', 'cursor-pointer'); }
        }

        // Helper Blob to Base64 (Unchanged)
        function blobToBase64(blob) { return new Promise((resolve, reject) => { const reader = new FileReader(); reader.onloadend = () => { const base64String = reader.result.split(',')[1]; resolve(base64String); }; reader.onerror = reject; reader.readAsDataURL(blob); }); }

        // History Actions (Unchanged)
        async function deleteRecording(id) { if (confirm(`Delete recording ${id}?`)) { try { await deleteRecordingFromDB(id); setStatus(`Recording ${id} deleted.`); await renderHistory(); } catch (error) { setStatus('Error deleting.', true); console.error("Delete error:", error); } } }

        // Event Listeners
        recordButton.addEventListener('click', () => { if (isRecording) { stopRecording(); } else { transcriptionOutput.value = ''; transcriptionSection.classList.add('hidden'); copyButton.disabled = true; copyButton.classList.add('opacity-50', 'cursor-not-allowed'); copyButton.classList.remove('opacity-100', 'cursor-pointer'); startRecording(); } });
        saveApiKeyButton.addEventListener('click', () => { currentApiKey = apiKeyInput.value.trim(); if (currentApiKey) { localStorage.setItem('geminiApiKey', currentApiKey); setStatus('API Key saved.'); } else { localStorage.removeItem('geminiApiKey'); setStatus('API Key removed.', true); } renderHistory(); });
        copyButton.addEventListener('click', () => { if (transcriptionOutput.value && !copyButton.disabled) { navigator.clipboard.writeText(transcriptionOutput.value).then(() => { setStatus('Copied!'); const copyIcon = copyButton.querySelector('[data-lucide="copy"]'); const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`; const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`; copyButton.innerHTML = checkIconHTML; lucide.createIcons(); setTimeout(() => { copyButton.innerHTML = originalIconHTML; lucide.createIcons(); }, 1500); }).catch(err => { console.error('Copy failed: ', err); setStatus('Copy failed.', true); }); } });
        
        // Settings panel controls
        settingsButton.addEventListener('click', () => {
            settingsSection.classList.remove('hidden');
            lucide.createIcons();
        });
        
        closeSettings.addEventListener('click', () => {
            settingsSection.classList.add('hidden');
            lucide.createIcons();
        });

        // Initialization
        async function initializeApp() {
            lucide.createIcons();
            apiKeyInput.value = currentApiKey;
            updateTokenDisplay();
            
            // Show settings if no API key or if FFmpeg needs attention
            if (!currentApiKey) {
                settingsSection.classList.remove('hidden');
            }
            
            await loadFFmpeg(); // Load FFmpeg first
            try { await initDB(); await renderHistory(); } catch (error) { setStatus('DB init failed.', true); }
            updateRecordButtonState(); // Set initial button state
            
            // Mic support checks (unchanged)
            if (!navigator.mediaDevices?.getUserMedia) { setStatus('getUserMedia not supported.', true); recordButton.disabled = true; recordButton.title = 'Not supported'; } else if (!window.MediaRecorder) { setStatus('MediaRecorder not supported.', true); recordButton.disabled = true; recordButton.title = 'Not supported'; } else { try { const ps = await navigator.permissions.query({ name: 'microphone' }); console.log('Mic perm state:', ps.state); if (ps.state === 'denied') setStatus('Mic denied.', true); ps.onchange = () => { console.log('Mic perm changed:', ps.state); if (ps.state === 'denied') setStatus('Mic denied.', true); else if (statusMessage.textContent.includes('denied')) setStatus('Mic granted.', false); }; } catch (e) { console.warn("Perm query failed:", e); } }
        }
        document.addEventListener('DOMContentLoaded', initializeApp);

        // Update token display
        function updateTokenDisplay() {
            const savedUsage = localStorage.getItem('tokenUsage');
            if (savedUsage) {
                tokenUsage = JSON.parse(savedUsage);
            }
            document.getElementById('inputTokens').textContent = tokenUsage.input.toLocaleString();
            document.getElementById('outputTokens').textContent = tokenUsage.output.toLocaleString();
        }

    </script>
</body>
</html>
