<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="favicon.svg" type="image/svg+xml">
    <title data-i18n="app_title">Voice Recorder & Transcriber (MP3)</title>
    <script src="https://cdn.tailwindcss.com?plugins=forms"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://unpkg.com/@ffmpeg/ffmpeg@0.11.0/dist/ffmpeg.min.js"></script>
    
    <!-- Import language files - note: using type="module" as fallback for browsers with strict CORS -->
    <script src="i18n/i18n.js"></script>
    <script type="text/javascript" src="i18n/en.js"></script>
    <script type="text/javascript" src="i18n/de.js"></script>

    <style>
        /* Styles (pulse, scrollbar, layout, disabled, lucide, ffmpegLog) remain the same */
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
        .recording-pulse { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        .history-list::-webkit-scrollbar { width: 8px; }
        .history-list::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb { background: #888; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb:hover { background: #555; }
        html, body { height: 100%; margin: 0; font-family: sans-serif; }
        .main-container { display: flex; flex-direction: column; min-height: 100vh; }
        .content-grow { flex-grow: 1; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        [data-lucide] { width: 1em; height: 1em; display: inline-block; vertical-align: middle; }
        #ffmpegLog { font-family: monospace; font-size: 0.75rem; max-height: 100px; overflow-y: auto; background-color: #f5f5f5; border: 1px solid #e0e0e0; padding: 5px; margin-top: 10px; white-space: pre-wrap; word-break: break-all; }
        
        /* Dark mode styles */
        :root {
            color-scheme: light dark;
        }
        
        body.dark-mode {
            background-color: #1a1a1a;
            color: #e0e0e0;
        }
        
        body.dark-mode .bg-white {
            background-color: #2d2d2d;
        }
        
        body.dark-mode .text-gray-800 {
            color: #e0e0e0;
        }
        
        body.dark-mode .text-gray-600 {
            color: #b0b0b0;
        }
        
        body.dark-mode .text-gray-500 {
            color: #a0a0a0;
        }
        
        body.dark-mode .bg-gray-50 {
            background-color: #333333;
        }
        
        body.dark-mode .border-gray-200 {
            border-color: #444444;
        }
        
        body.dark-mode #ffmpegLog {
            background-color: #222222;
            border-color: #444444;
            color: #e0e0e0;
        }
        
        body.dark-mode .bg-gray-100 {
            background-color: #1a1a1a;
        }
        
        /* Toggle switch styles */
        .toggle-switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 24px;
        }
        
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .toggle-slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 24px;
        }
        
        .toggle-slider:before {
            position: absolute;
            content: "";
            height: 16px;
            width: 16px;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        
        input:checked + .toggle-slider {
            background-color: #2196F3;
        }
        
        input:checked + .toggle-slider:before {
            transform: translateX(26px);
        }
    </style>
</head>
<body class="bg-gray-100">
    <div class="main-container container mx-auto p-4 md:p-8 max-w-4xl">

        <header class="mb-8 text-center relative">
            <h1 class="text-3xl font-bold text-gray-800" data-i18n="app_title">Voice Recorder & Transcriber</h1>
            <p class="text-gray-600" data-i18n="app_description">Record audio, save locally, and transcribe using Cloud APIs.</p>
            <div class="absolute top-0 right-0 flex space-x-2">
                <button id="helpButton" class="p-2 text-gray-600 hover:text-gray-800 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full" data-i18n-title="help_button">
                    <i data-lucide="help-circle" style="width: 24px; height: 24px;"></i>
                </button>
                <button id="settingsButton" class="p-2 text-gray-600 hover:text-gray-800 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full" data-i18n-title="settings_button">
                    <i data-lucide="settings" style="width: 24px; height: 24px;"></i>
                </button>
            </div>
        </header>

        <!-- Help Modal -->
        <div id="helpModal" class="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50 hidden">
            <div class="bg-white dark:bg-gray-800 p-6 rounded-lg shadow-lg max-w-2xl w-full max-h-[90vh] overflow-y-auto">
                <div class="flex justify-between items-center mb-4">
                    <h2 class="text-xl font-semibold text-gray-700 dark:text-gray-300" data-i18n="help_title">How to Use This App</h2>
                    <button id="closeHelp" class="p-1 text-gray-600 dark:text-gray-400 hover:text-gray-800 dark:hover:text-gray-200 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                        <i data-lucide="x" style="width: 20px; height: 20px;"></i>
                    </button>
                </div>
                
                <div class="prose dark:prose-invert max-w-none">
                    <p data-i18n="help_intro">This voice recorder allows you to record audio from your microphone, save it locally, and transcribe it using various AI services.</p>
                    
                    <p class="mt-4 font-medium" data-i18n="help_step1">1. Set up an API key in Settings (click the gear icon ⚙️)</p>
                    <p class="mt-2 font-medium" data-i18n="help_step2">2. Click the microphone button to start recording</p>
                    <p class="mt-2 font-medium" data-i18n="help_step3">3. Click again to stop recording</p>
                    <p class="mt-2 font-medium" data-i18n="help_step4">4. Your recording will be saved in the history section</p>
                    <p class="mt-2 font-medium" data-i18n="help_step5">5. Click the transcribe button to convert speech to text</p>
                    
                    <p class="mt-4 font-medium" data-i18n="help_apis">Supported transcription services:</p>
                    <ul class="list-disc pl-6 mt-2">
                        <li data-i18n="help_api_gemini">Google Gemini - Free tier available</li>
                        <li data-i18n="help_api_openai">OpenAI Whisper - Paid API</li>
                        <li data-i18n="help_api_groq">Groq - Paid API</li>
                        <li data-i18n="help_api_assembly">Assembly AI - Paid API with free tier</li>
                    </ul>
                    
                    <p class="mt-4 text-sm text-gray-600 dark:text-gray-400 italic" data-i18n="help_privacy">
                        Privacy note: Your recordings stay on your device. API keys are stored in your browser's local storage only.
                    </p>
                </div>
                
                <div class="mt-6 flex justify-end">
                    <button id="dontShowAgainButton" class="px-4 py-2 text-sm bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300 rounded hover:bg-gray-300 dark:hover:bg-gray-600 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-gray-400" data-i18n="dont_show_startup">
                        Don't show on startup
                    </button>
                </div>
            </div>
        </div>

        <section id="settingsSection" class="mb-6 p-4 bg-white dark:bg-gray-800 rounded-lg shadow hidden">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-xl font-semibold text-gray-700 dark:text-gray-300" data-i18n="settings_title">Settings</h2>
                <button id="closeSettings" class="p-1 text-gray-600 dark:text-gray-400 hover:text-gray-800 dark:hover:text-gray-200 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                    <i data-lucide="x" style="width: 20px; height: 20px;"></i>
                </button>
            </div>
            
            <!-- Add Interface Language Section -->
            <div id="languageSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2" data-i18n="language">Interface Language:</h3>
                <select id="interfaceLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                    <option value="en" data-i18n="lang_en">English</option>
                    <option value="de" data-i18n="lang_de">Deutsch (German)</option>
                </select>
            </div>
            
            <div id="transcriptionApiSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2" data-i18n="transcription_api">Transcription API:</h3>
                
                <!-- Gemini API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Google Gemini</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="geminiToggle" checked>
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="geminiSettings" class="mt-2">
                        <label for="apiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1" data-i18n="api_key">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="apiKey" name="apiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" data-i18n-placeholder="api_key_placeholder">
                            <a href="https://aistudio.google.com/app/apikey" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        <p class="text-xs text-gray-500 dark:text-gray-400 mt-2" data-i18n="api_key_note">Your API key is stored only in your browser's local storage.</p>
                    </div>
                </div>
                
                <!-- OpenAI API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">OpenAI</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="openaiToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="openaiSettings" class="mt-2 hidden">
                        <label for="openaiApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1" data-i18n="api_key">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="openaiApiKey" name="openaiApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" data-i18n-placeholder="api_key_placeholder">
                            <a href="https://platform.openai.com/api-keys" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        
                        <div class="mt-3">
                            <label for="openaiLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1" data-i18n="language_selection">Language:</label>
                            <select id="openaiLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto" data-i18n="auto_detect">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
                
                <!-- Groq API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Groq</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="groqToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="groqSettings" class="mt-2 hidden">
                        <label for="groqApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="groqApiKey" name="groqApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your Groq API key">
                            <a href="https://console.groq.com/keys" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        
                        <div class="mt-3">
                            <label for="groqModel" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Model:</label>
                            <select id="groqModel" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="whisper-large-v3-turbo">Whisper Large V3 Turbo</option>
                                <option value="distil-whisper-large-v3-en">Distil Whisper Large V3 (English)</option>
                                <option value="whisper-large-v3">Whisper Large V3</option>
                            </select>
                        </div>
                        
                        <div class="mt-3">
                            <label for="groqLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="groqLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
                
                <!-- Assembly AI API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Assembly AI</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="assemblyToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="assemblySettings" class="mt-2 hidden">
                        <label for="assemblyApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="assemblyApiKey" name="assemblyApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your Assembly AI API key">
                            <a href="https://www.assemblyai.com/dashboard/api-keys" target="_blank" class="text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300" title="Get API Key">
                                <i data-lucide="external-link" style="width: 18px; height: 18px;"></i>
                            </a>
                        </div>
                        
                        <div class="mt-3">
                            <div class="flex items-center space-x-2">
                                <label class="text-sm font-medium text-gray-700 dark:text-gray-300">EU Server:</label>
                                <label class="toggle-switch">
                                    <input type="checkbox" id="assemblyEuToggle">
                                    <span class="toggle-slider"></span>
                                </label>
                            </div>
                            <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Toggle to use EU server for transcription</p>
                        </div>
                        
                        <div class="mt-3">
                            <label for="assemblyLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="assemblyLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
            </div>

            <div id="ffmpegSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2" data-i18n="ffmpeg_status">FFmpeg Status:</h3>
                <div class="flex items-center justify-between mb-2">
                    <p id="ffmpegStatus" class="text-sm text-gray-600 dark:text-gray-400" data-i18n="ffmpeg_disabled">FFmpeg disabled. Audio will not be converted to MP3.</p>
                    <div class="flex items-center space-x-2">
                        <label class="text-xs text-gray-500 dark:text-gray-400" data-i18n="ffmpeg_enable">Enable FFmpeg</label>
                        <label class="toggle-switch">
                            <input type="checkbox" id="ffmpegToggle" checked>
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                </div>
                <div id="ffmpegLog" class="hidden text-left mt-2"></div>
            </div>
            
            <div id="recordingSettingsSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Recording Settings:</h3>
                <div class="mt-3">
                    <label for="recordingLimit" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Recording Length Limit (seconds):</label>
                    <input type="number" id="recordingLimit" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Auto (based on API)">
                    <p class="text-xs text-gray-500 dark:text-gray-400 mt-1">Leave empty for automatic limits (FFmpeg: 600s, Gemini: 570s, OpenAI: 140s)</p>
                </div>
            </div>
            
            <div id="themeSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Theme:</h3>
                <div class="flex items-center space-x-2">
                    <label class="text-sm text-gray-600 dark:text-gray-400">Dark Mode:</label>
                    <div class="flex items-center space-x-2">
                        <label class="text-xs text-gray-500 dark:text-gray-400">System</label>
                        <label class="toggle-switch">
                            <input type="checkbox" id="darkModeToggle">
                            <span class="toggle-slider"></span>
                        </label>
                        <label class="text-xs text-gray-500 dark:text-gray-400">Dark</label>
                    </div>
                </div>
            </div>
        </section>

        <section class="mb-6 p-6 bg-white dark:bg-gray-800 rounded-lg shadow text-center">
            <h2 class="text-xl font-semibold mb-4 text-gray-700 dark:text-gray-300">Record Audio</h2>
            <div class="relative" id="recordButtonContainer">
                <button id="recordButton" class="p-4 bg-red-600 text-white rounded-full hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-red-500 transition duration-150 ease-in-out disabled:bg-gray-400" disabled> 
                    <i id="micIconPlaceholder" data-lucide="mic" style="width: 32px; height: 32px;"></i>
                </button>
                <div id="dropZoneOverlay" class="absolute inset-0 flex items-center justify-center rounded-full bg-blue-500 bg-opacity-80 text-white hidden">
                    <i data-lucide="upload" style="width: 32px; height: 32px;"></i>
                </div>
            </div>
            <p id="statusMessage" class="mt-3 text-gray-600 h-5" data-i18n="ready_to_record">Ready to record</p>
            <p id="uploadMessage" class="mt-1 text-sm text-gray-500" data-i18n="drag_drop">Drag & drop m4a, wav, or mp3 files here to upload</p>
            <div id="ffmpegLog" class="hidden text-left"></div>
        </section>

        <section id="transcriptionSection" class="mb-6 p-4 bg-white rounded-lg shadow hidden">
             <h2 class="text-xl font-semibold mb-2 text-gray-700">Transcription</h2>
             <div class="relative">
                <textarea id="transcriptionOutput" rows="4" class="w-full p-2 border border-gray-300 rounded-md bg-gray-50 resize-none" readonly placeholder="Transcription will appear here..."></textarea>
                <button id="copyButton" title="Copy to Clipboard" class="absolute top-2 right-2 p-1 bg-gray-200 text-gray-600 rounded hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500 opacity-50 cursor-not-allowed" disabled>
                    <i data-lucide="copy" style="width: 18px; height: 18px;"></i>
                </button>
             </div>
        </section>

        <section class="content-grow p-4 bg-white dark:bg-gray-800 rounded-lg shadow flex flex-col">
            <h2 class="text-xl font-semibold mb-4 text-gray-700 dark:text-gray-300 flex-shrink-0">Recording History</h2>
            <div id="historyList" class="history-list flex-grow overflow-y-auto space-y-3 pr-2">
                <p id="noHistoryMessage" class="text-gray-500">No recordings yet.</p>
            </div>
        </section>

        <footer class="mt-8 text-center text-sm text-gray-500">
            <p data-i18n="footer_text">App made with ♥️ and ✨ in Vienna. Uses browser (local ) storage. API Key is not saved in the Cloud.</p>
        </footer>

    </div> <script>
        // --- DOM Elements (Unchanged) ---
        const apiKeyInput = document.getElementById('apiKey');
        const saveApiKeyButton = document.getElementById('saveApiKey');
        const recordButton = document.getElementById('recordButton');
        const recordButtonContainer = document.getElementById('recordButtonContainer');
        const dropZoneOverlay = document.getElementById('dropZoneOverlay');
        const uploadMessage = document.getElementById('uploadMessage');
        const statusMessage = document.getElementById('statusMessage');
        const transcriptionSection = document.getElementById('transcriptionSection');
        const transcriptionOutput = document.getElementById('transcriptionOutput');
        const copyButton = document.getElementById('copyButton');
        const historyList = document.getElementById('historyList');
        const noHistoryMessage = document.getElementById('noHistoryMessage');
        const ffmpegLog = document.getElementById('ffmpegLog');
        const settingsButton = document.getElementById('settingsButton');
        const settingsSection = document.getElementById('settingsSection');
        const closeSettings = document.getElementById('closeSettings');
        const ffmpegStatus = document.getElementById('ffmpegStatus');
        const geminiToggle = document.getElementById('geminiToggle');
        const geminiSettings = document.getElementById('geminiSettings');
        const openaiToggle = document.getElementById('openaiToggle');
        const openaiSettings = document.getElementById('openaiSettings');
        const openaiApiKeyInput = document.getElementById('openaiApiKey');
        const saveOpenaiApiKeyButton = document.getElementById('saveOpenaiApiKey');
        const openaiLanguageSelect = document.getElementById('openaiLanguage');
        const groqToggle = document.getElementById('groqToggle');
        const groqSettings = document.getElementById('groqSettings');
        const groqApiKeyInput = document.getElementById('groqApiKey');
        const saveGroqApiKeyButton = document.getElementById('saveGroqApiKey');
        const groqModelSelect = document.getElementById('groqModel');
        const groqLanguageSelect = document.getElementById('groqLanguage');
        const assemblyToggle = document.getElementById('assemblyToggle');
        const assemblySettings = document.getElementById('assemblySettings');
        const assemblyApiKeyInput = document.getElementById('assemblyApiKey');
        const assemblyEuToggle = document.getElementById('assemblyEuToggle');
        const assemblyLanguageSelect = document.getElementById('assemblyLanguage');
        const recordingLimitInput = document.getElementById('recordingLimit');
        const helpButton = document.getElementById('helpButton');
        const helpModal = document.getElementById('helpModal');
        const closeHelp = document.getElementById('closeHelp');
        const dontShowAgainButton = document.getElementById('dontShowAgainButton');
        const interfaceLanguage = document.getElementById('interfaceLanguage');

        // --- State Variables (Unchanged) ---
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let currentApiKey = localStorage.getItem('geminiApiKey') || '';
        let currentOpenaiApiKey = localStorage.getItem('openaiApiKey') || '';
        let currentGroqApiKey = localStorage.getItem('groqApiKey') || '';
        let currentAssemblyApiKey = localStorage.getItem('assemblyApiKey') || '';
        let openaiLanguage = localStorage.getItem('openaiLanguage') || 'auto';
        let groqModel = localStorage.getItem('groqModel') || 'whisper-large-v3-turbo';
        let groqLanguage = localStorage.getItem('groqLanguage') || 'auto';
        let assemblyLanguage = localStorage.getItem('assemblyLanguage') || 'auto';
        let assemblyEuServer = localStorage.getItem('assemblyEuServer') === 'true';
        let db;
        let ffmpeg;
        let ffmpegLoaded = false;
        let currentlyPlayingAudio = null;
        let currentlyPlayingButton = null;
        let tokenUsage = { input: 0, output: 0 }; // Track token usage
        let darkMode = localStorage.getItem('darkMode') || 'system'; // Dark mode preference
        let settingsVisible = false; // Track settings visibility
        let helpVisible = false; // Track help visibility
        let ffmpegEnabled = localStorage.getItem('ffmpegEnabled') !== 'false'; // FFmpeg enabled by default
        let geminiEnabled = localStorage.getItem('geminiEnabled') !== 'false'; // Gemini enabled by default
        let openaiEnabled = localStorage.getItem('openaiEnabled') === 'true'; // OpenAI disabled by default
        let groqEnabled = localStorage.getItem('groqEnabled') === 'true'; // Groq disabled by default
        let assemblyEnabled = localStorage.getItem('assemblyEnabled') === 'true'; // Assembly disabled by default
        let recordingLimit = localStorage.getItem('recordingLimit') || ''; // Recording length limit
        let recordingTimer = null; // Timer for recording length limit
        let isDraggingFile = false; // Track if file is being dragged over
        let showHelpOnStartup = localStorage.getItem('showHelpOnStartup') !== 'false'; // Show help on startup by default
        let currentLanguage = localStorage.getItem('uiLanguage') || 'en'; // Default to English

        // --- Constants ---
        const DB_NAME = 'VoiceRecorderDB_MP3';
        const DB_VERSION = 1;
        const STORE_NAME = 'recordings_mp3';
        const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=';
        const OPENAI_API_URL = 'https://api.openai.com';
        const OPENAI_CHAT_API_URL = 'https://api.openai.com/v1/chat/completions';
        const GROQ_API_URL = 'https://api.groq.com/openai/v1/audio/transcriptions';
        const ASSEMBLY_API_URL_US = 'https://api.assemblyai.com/v2';
        const ASSEMBLY_API_URL_EU = 'https://api.eu.assemblyai.com/v2';
        const TARGET_MIME_TYPE = 'audio/mpeg';
        const TARGET_FORMAT = 'mp3';
        const TARGET_QUALITY = '1';
        const TARGET_CHANNELS = 1;
        
        // File size limits for different APIs
        const FILE_SIZE_LIMITS = {
            gemini: 50 * 1024 * 1024, // 50MB
            openai: 25 * 1024 * 1024, // 25MB
            groq: 25 * 1024 * 1024,   // 25MB
            assembly: 200 * 1024 * 1024 // 200MB
        };

        // --- FFmpeg Initialization ---
        async function loadFFmpeg() {
            if (!ffmpegEnabled) {
                ffmpegStatus.textContent = i18n.t('ffmpeg_disabled');
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = i18n.t('ready_to_record');
                setStatus(i18n.t('ready_to_record'));
                updateRecordButtonState();
                return;
            }
            
            ffmpegStatus.textContent = i18n.t('ffmpeg_loading');
            recordButton.disabled = true;
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = 'Initializing FFmpeg library...\n';

            try {
                if (typeof FFmpeg === 'undefined' || typeof FFmpeg.createFFmpeg === 'undefined') {
                     throw new Error("FFmpeg library script not loaded correctly.");
                }
                const { createFFmpeg } = FFmpeg;

                const corePath = 'https://unpkg.com/@ffmpeg/core@0.11.0/dist/ffmpeg-core.js';
                ffmpegLog.textContent += `Attempting to load core from: ${corePath}\n (This avoids SharedArrayBuffer issues but is slower)\n`;

                ffmpeg = createFFmpeg({
                    log: true,
                    logger: ({ type, message }) => {
                        console.log(`FFmpeg log [${type}]: ${message}`);
                        if(ffmpegLog.textContent.length > 5000) ffmpegLog.textContent = '';
                        ffmpegLog.textContent += message + '\n';
                        ffmpegLog.scrollTop = ffmpegLog.scrollHeight;
                    },
                    progress: ({ ratio }) => {
                         console.log(`FFmpeg progress: ${(ratio * 100).toFixed(2)}%`);
                         if (ratio > 0 && ratio < 1) {
                            ffmpegStatus.textContent = `Loading FFmpeg... ${(ratio * 100).toFixed(0)}%`;
                         }
                    },
                    corePath: corePath,
                });

                ffmpegLog.textContent += 'Loading FFmpeg core...\n';
                await ffmpeg.load();
                ffmpegLog.textContent += 'FFmpeg core loaded successfully.\n';
                ffmpegLoaded = true;
                ffmpegStatus.textContent = 'FFmpeg loaded successfully';
                setStatus('Ready to record.');
                recordButton.disabled = false;

            } catch (error) {
                console.error("Error loading FFmpeg:", error);
                if (error instanceof ReferenceError && error.message.includes("SharedArrayBuffer")) {
                     ffmpegStatus.textContent = 'FFmpeg failed: SharedArrayBuffer missing. Need server COOP/COEP headers.';
                     ffmpegLog.textContent += `ERROR: SharedArrayBuffer not defined. This usually means the server is not sending the required COOP and COEP headers. See console and explanation above the code.\n`;
                } else {
                    ffmpegStatus.textContent = 'Failed to load FFmpeg. Conversion unavailable.';
                    ffmpegLog.textContent += `Error loading FFmpeg: ${error}\n`;
                }
                ffmpegLoaded = false;
                recordButton.disabled = true;
                recordButton.title = 'FFmpeg failed to load, recording disabled.';
            }
        }


        // --- IndexedDB Initialization (Unchanged) ---
        function initDB() {
            return new Promise((resolve, reject) => {
                const request = indexedDB.open(DB_NAME, DB_VERSION);
                request.onerror = (event) => { console.error("IndexedDB error:", event.target.error); setStatus('Error initializing local database.', true); reject(event.target.error); };
                request.onsuccess = (event) => { db = event.target.result; console.log("Database initialized successfully:", DB_NAME); resolve(db); };
                request.onupgradeneeded = (event) => {
                    db = event.target.result;
                    if (!db.objectStoreNames.contains(STORE_NAME)) {
                        const objectStore = db.createObjectStore(STORE_NAME, { keyPath: 'id', autoIncrement: true });
                        objectStore.createIndex('timestamp', 'timestamp', { unique: false });
                        console.log("Object store created:", STORE_NAME);
                    }
                };
            });
        }

        // --- IndexedDB Operations ---
        function addRecordingToDB(blob, mimeType) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite');
                const store = transaction.objectStore(STORE_NAME);
                const recording = { audioBlob: blob, mimeType: mimeType, timestamp: new Date(), transcription: null };
                const request = store.add(recording);
                request.onsuccess = (event) => resolve(event.target.result);
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function getRecordingsFromDB() {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.getAll();
                request.onsuccess = (event) => resolve(event.target.result.sort((a, b) => b.timestamp - a.timestamp));
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function getRecordingByIdFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.get(id);
                request.onsuccess = (event) => resolve(event.target.result);
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function updateTranscriptionInDB(id, transcription) {
            return new Promise(async (resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                try {
                    const recording = await getRecordingByIdFromDB(id);
                    if (!recording) return reject(`Recording ${id} not found.`);
                    recording.transcription = transcription;
                    const transaction = db.transaction([STORE_NAME], 'readwrite');
                    const store = transaction.objectStore(STORE_NAME);
                    const request = store.put(recording);
                    request.onsuccess = () => resolve();
                    request.onerror = (event) => reject(event.target.error);
                } catch (error) {
                    reject(error);
                }
            });
        }

        function deleteRecordingFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.delete(id);
                request.onsuccess = () => resolve();
                request.onerror = (event) => reject(event.target.error);
            });
        }

        // --- UI Update Functions (Unchanged) ---
        function setStatus(message, isError = false) { 
            // Use translation if the message is a key in our translations
            const translatedMessage = i18n.t(message);
            statusMessage.textContent = translatedMessage; 
            statusMessage.className = `mt-3 h-5 ${isError ? 'text-red-600' : 'text-gray-600'}`; 
        }
        function updateRecordButtonState() {
            const micIconElement = recordButton.querySelector('[data-lucide="mic"]');
            if (isRecording) {
                recordButton.classList.remove('bg-red-600', 'hover:bg-red-700');
                recordButton.classList.add('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                if (micIconElement) micIconElement.classList.add('animate-pulse');
                setStatus(i18n.t('recording'));
                recordButton.disabled = false; // Ensure button is enabled during recording
            } else {
                if (!statusMessage.textContent.includes('FFmpeg') && !statusMessage.textContent.includes('Converting')) {
                    setStatus(i18n.t('ready_to_record'));
                }
                recordButton.classList.remove('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                recordButton.classList.add('bg-red-600', 'hover:bg-red-700');
                if (micIconElement) micIconElement.classList.remove('animate-pulse');
                
                // Only disable the button if both conditions are true:
                // 1. FFmpeg is enabled in settings
                // 2. FFmpeg is not loaded yet
                if (ffmpegEnabled && !ffmpegLoaded) {
                    recordButton.disabled = true;
                    recordButton.title = i18n.t('loading_ffmpeg');
                } else {
                    recordButton.disabled = false;
                    if (!ffmpegEnabled) {
                        recordButton.title = i18n.t('ready_to_record');
                    } else {
                        recordButton.title = i18n.t('ready_to_record');
                    }
                }
            }
        }
        function displayTranscription(text) {
            transcriptionOutput.value = text || "No transcription available.";
            transcriptionSection.classList.remove('hidden');
            
            if (text && text !== "API Key needed." && !text.startsWith("Error:")) {
                copyButton.disabled = false;
                copyButton.classList.remove('opacity-50', 'cursor-not-allowed');
                copyButton.classList.add('opacity-100', 'cursor-pointer');
                
                // Automatically copy to clipboard
                navigator.clipboard.writeText(text).then(() => {
                    setStatus('Transcription copied to clipboard!');
                    const copyIcon = copyButton.querySelector('[data-lucide="copy"]');
                    const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`;
                    const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`;
                    copyButton.innerHTML = checkIconHTML;
                    lucide.createIcons();
                    setTimeout(() => {
                        copyButton.innerHTML = originalIconHTML;
                        lucide.createIcons();
                    }, 1500);
                }).catch(err => {
                    console.error('Auto-copy failed: ', err);
                    setStatus('Auto-copy failed.', true);
                });
            } else {
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }
        async function renderHistory() {
             try {
                const recordings = await getRecordingsFromDB(); 
                historyList.innerHTML = '';
                
                if (recordings.length === 0) { 
                    noHistoryMessage.classList.remove('hidden'); 
                    historyList.appendChild(noHistoryMessage); 
                } else {
                    noHistoryMessage.classList.add('hidden');
                    
                    // Sort recordings by timestamp (newest first)
                    recordings.sort((a, b) => b.timestamp - a.timestamp);
                    
                    // Limit to 10 entries
                    const limitedRecordings = recordings.slice(0, 10);
                    
                    // If we have more than 10 recordings, delete the oldest ones
                    if (recordings.length > 10) {
                        const recordingsToDelete = recordings.slice(10);
                        for (const rec of recordingsToDelete) {
                            try {
                                await deleteRecordingFromDB(rec.id);
                                console.log(`Auto-deleted old recording ${rec.id}`);
                            } catch (error) {
                                console.error(`Error auto-deleting recording ${rec.id}:`, error);
                            }
                        }
                    }
                    
                    limitedRecordings.forEach(rec => {
                        const div = document.createElement('div'); 
                        div.className = 'p-3 bg-gray-50 border border-gray-200 rounded-md flex items-center justify-between space-x-3';
                        
                        const infoDiv = document.createElement('div'); 
                        infoDiv.className = 'flex-grow min-w-0';
                        
                        const time = document.createElement('p'); 
                        time.className = 'text-sm font-medium text-gray-800 dark:text-gray-300 truncate'; 
                        // Get the actual format from the MIME type
                        let format = 'MP3';
                        if (rec.mimeType) {
                            if (rec.mimeType.includes('webm')) {
                                format = 'WEBM';
                            } else if (rec.mimeType.includes('ogg')) {
                                format = 'OGG';
                            } else if (rec.mimeType.includes('wav')) {
                                format = 'WAV';
                            }
                        }
                        time.textContent = `Recorded ${format}: ${rec.timestamp.toLocaleString()}`; 
                        time.title = `${format} Recorded: ${rec.timestamp.toLocaleString()}`;
                        
                        // Add file size and duration info
                        const fileInfo = document.createElement('p');
                        fileInfo.className = 'text-xs text-gray-500';
                        
                        // Calculate file size
                        const fileSizeMB = (rec.audioBlob.size / (1024 * 1024)).toFixed(2);
                        
                        // Create audio element to get duration
                        const audio = new Audio(URL.createObjectURL(rec.audioBlob));
                        
                        // Function to format duration properly
                        const formatDuration = (duration) => {
                            if (isNaN(duration) || duration === Infinity || duration <= 0) {
                                return "Unknown";
                            }
                            const minutes = Math.floor(duration / 60);
                            const seconds = Math.floor(duration % 60);
                            return `${minutes}:${seconds.toString().padStart(2, '0')}`;
                        };
                        
                        // Set initial duration text
                        fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: Loading...`;
                        
                        // Try to get duration using MediaSource API
                        const getDurationWithMediaSource = async () => {
                            try {
                                // Create a MediaSource
                                const mediaSource = new MediaSource();
                                const video = document.createElement('video');
                                video.src = URL.createObjectURL(mediaSource);
                                
                                return new Promise((resolve) => {
                                    mediaSource.addEventListener('sourceopen', async () => {
                                        try {
                                            // Create a source buffer
                                            const sourceBuffer = mediaSource.addSourceBuffer('audio/webm; codecs="opus"');
                                            
                                            // Get the audio data
                                            const arrayBuffer = await rec.audioBlob.arrayBuffer();
                                            
                                            // Append the data to the source buffer
                                            sourceBuffer.addEventListener('updateend', () => {
                                                if (!sourceBuffer.updating && mediaSource.readyState === 'open') {
                                                    // Get the duration
                                                    const duration = mediaSource.duration;
                                                    // Clean up
                                                    URL.revokeObjectURL(video.src);
                                                    resolve(duration);
                                                }
                                            });
                                            
                                            sourceBuffer.appendBuffer(arrayBuffer);
                                            sourceBuffer.addEventListener('error', () => {
                                                URL.revokeObjectURL(video.src);
                                                resolve(null);
                                            });
                                        } catch (error) {
                                            console.error("MediaSource error:", error);
                                            URL.revokeObjectURL(video.src);
                                            resolve(null);
                                        }
                                    });
                                    
                                    // Set a timeout in case the MediaSource doesn't open
                                    setTimeout(() => {
                                        URL.revokeObjectURL(video.src);
                                        resolve(null);
                                    }, 3000);
                                });
                            } catch (error) {
                                console.error("MediaSource setup error:", error);
                                return null;
                            }
                        };
                        
                        // Handle metadata loaded event
                        audio.onloadedmetadata = () => {
                            const duration = audio.duration;
                            const durationStr = formatDuration(duration);
                            
                            // Add token usage if available
                            const tokenInfo = rec.tokenUsage ? 
                                ` | Tokens: ${rec.tokenUsage.input || 0} in, ${rec.tokenUsage.output || 0} out` : 
                                '';
                                
                            fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: ${durationStr}${tokenInfo}`;
                            URL.revokeObjectURL(audio.src);
                        };
                        
                        // Add error handling for audio loading
                        audio.onerror = () => {
                            console.error("Error loading audio for duration calculation");
                            // Try MediaSource as a fallback
                            getDurationWithMediaSource().then(duration => {
                                const durationStr = formatDuration(duration);
                                
                                // Add token usage if available
                                const tokenInfo = rec.tokenUsage ? 
                                    ` | Tokens: ${rec.tokenUsage.input || 0} in, ${rec.tokenUsage.output || 0} out` : 
                                    '';
                                    
                                fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: ${durationStr}${tokenInfo}`;
                            }).catch(() => {
                                fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: Unknown`;
                            });
                            URL.revokeObjectURL(audio.src);
                        };
                        
                        // Set a timeout to handle cases where metadata doesn't load
                        setTimeout(() => {
                            if (fileInfo.textContent.includes("Loading...")) {
                                // Try to get duration directly from the audio element
                                const duration = audio.duration;
                                const durationStr = formatDuration(duration);
                                
                                // Add token usage if available
                                const tokenInfo = rec.tokenUsage ? 
                                    ` | Tokens: ${rec.tokenUsage.input || 0} in, ${rec.tokenUsage.output || 0} out` : 
                                    '';
                                    
                                fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: ${durationStr}${tokenInfo}`;
                                URL.revokeObjectURL(audio.src);
                            }
                        }, 2000);
                        
                        const transcriptionPreview = document.createElement('p'); 
                        transcriptionPreview.className = 'text-xs text-gray-500 italic truncate'; 
                        transcriptionPreview.textContent = rec.transcription ? `"${rec.transcription.substring(0, 60)}..."` : 'Not transcribed yet'; 
                        if(rec.transcription) transcriptionPreview.title = rec.transcription;
                        
                        // Append elements in the correct order
                        infoDiv.appendChild(time);
                        infoDiv.appendChild(fileInfo);
                        infoDiv.appendChild(transcriptionPreview);
                        
                        const controlsDiv = document.createElement('div'); 
                        controlsDiv.className = 'flex-shrink-0 flex items-center space-x-2';
                        
                        const playButton = document.createElement('button');
                        playButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        playButton.className = 'p-1.5 bg-green-100 text-green-700 rounded hover:bg-green-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-green-500';
                        playButton.title = 'Play MP3 Audio';
                        playButton.onclick = () => playAudio(rec.audioBlob, playButton);

                        const downloadButton = document.createElement('button');
                        downloadButton.innerHTML = `<i data-lucide="download" style="width: 18px; height: 18px;"></i>`;
                        downloadButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        downloadButton.title = 'Download MP3';
                        downloadButton.onclick = () => {
                            const url = URL.createObjectURL(rec.audioBlob);
                            const a = document.createElement('a');
                            a.href = url;
                            // Get the correct file extension based on MIME type
                            let extension = 'mp3';
                            if (rec.mimeType) {
                                if (rec.mimeType.includes('webm')) {
                                    extension = 'webm';
                                } else if (rec.mimeType.includes('ogg')) {
                                    extension = 'ogg';
                                } else if (rec.mimeType.includes('wav')) {
                                    extension = 'wav';
                                }
                            }
                            a.download = `recording_${rec.id}_${rec.timestamp.toISOString().slice(0,19).replace(/[:]/g, '-')}.${extension}`;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        };

                        const transcribeButton = document.createElement('button');
                        transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                        transcribeButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        transcribeButton.title = 'Transcribe Audio';
                        transcribeButton.onclick = (e) => {
                            if (rec.transcription) {
                                displayTranscription(rec.transcription);
                                return;
                            }
                            transcribeButton.disabled = true;
                            transcribeButton.innerHTML = '...';
                            transcribeAudio(rec.id, rec.audioBlob, rec.mimeType).finally(() => {
                                transcribeButton.disabled = false;
                                transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                                lucide.createIcons();
                            });
                        };
                        
                        // Update disabled state logic
                        if (rec.transcription) {
                            // If there's a transcription, button is always enabled
                            transcribeButton.disabled = false;
                            transcribeButton.title = 'View Transcription';
                        } else {
                            // Check if any API is enabled with a valid key
                            const hasValidApiKey = (geminiEnabled && currentApiKey) || 
                                                 (openaiEnabled && currentOpenaiApiKey) || 
                                                 (groqEnabled && currentGroqApiKey) || 
                                                 (assemblyEnabled && currentAssemblyApiKey);
                            
                            if (hasValidApiKey) {
                                // If any API is enabled with a valid key, enable the button
                                transcribeButton.disabled = false;
                                transcribeButton.title = 'Transcribe Audio';
                            } else {
                                // If no API is enabled with a key, disable the button
                                transcribeButton.disabled = true;
                                transcribeButton.title = 'No API enabled or API Key required';
                            }
                        }

                        const deleteButton = document.createElement('button');
                        deleteButton.innerHTML = `<i data-lucide="trash-2" style="width: 18px; height: 18px;"></i>`;
                        deleteButton.className = 'p-1.5 bg-red-100 text-red-700 rounded hover:bg-red-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-red-500';
                        deleteButton.title = 'Delete Recording';
                        deleteButton.onclick = () => deleteRecording(rec.id);

                        controlsDiv.appendChild(playButton);
                        controlsDiv.appendChild(downloadButton);
                        controlsDiv.appendChild(transcribeButton);
                        controlsDiv.appendChild(deleteButton);
                        
                        div.appendChild(infoDiv);
                        div.appendChild(controlsDiv);
                        historyList.appendChild(div);
                    });
                    
                    lucide.createIcons();
                }
            } catch (error) { 
                console.error("Error rendering history:", error); 
                setStatus('Could not load history.', true); 
                noHistoryMessage.classList.remove('hidden'); 
                historyList.appendChild(noHistoryMessage); 
            }
        }

        // --- Audio Handling ---
        async function startRecording() {
            if (!ffmpegEnabled && !ffmpegLoaded) {
                setStatus('FFmpeg disabled. Recording without MP3 conversion.');
            }
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log("Mic access granted.");
                const options = { mimeType: 'audio/webm;codecs=opus' };
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/ogg;codecs=opus';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/webm';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = '';
                console.log("Recording with MIME type:", options.mimeType || "Browser Default");
                mediaRecorder = new MediaRecorder(stream, options);
                audioChunks = [];
                mediaRecorder.ondataavailable = event => { if (event.data.size > 0) audioChunks.push(event.data); };
                mediaRecorder.onstop = async () => {
                    const originalBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });
                    const originalMimeType = mediaRecorder.mimeType || 'audio/webm';
                    console.log("Recording stopped. Original Blob:", originalBlob);
                    console.log("Original MIME type:", originalMimeType);
                    stream.getTracks().forEach(track => track.stop());
                    
                    if (ffmpegEnabled && ffmpegLoaded) {
                        await convertAudioAndSave(originalBlob, originalMimeType); // Convert and save
                    } else {
                        // Save without conversion
                        setStatus('Saving recording...');
                        const newId = await addRecordingToDB(originalBlob, originalMimeType);
                        setStatus(`Recording saved (ID: ${newId}).`);
                        await renderHistory();
                        
                        // Attempt automatic transcription if API key is available
                        if ((geminiEnabled && currentApiKey) || (openaiEnabled && currentOpenaiApiKey) || (groqEnabled && currentGroqApiKey)) {
                            setStatus(`Starting automatic transcription for recording ${newId}...`);
                            await transcribeAudio(newId, originalBlob, originalMimeType);
                        } else {
                            setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                            displayTranscription("API Key needed for transcription.");
                        }
                    }
                    
                    updateRecordButtonState(); // Update button state after saving
                };
                mediaRecorder.onerror = (event) => {
                    console.error("MediaRecorder error:", event.error);
                    setStatus(`Recording error: ${event.error?.name || 'Unknown'}`, true);
                    isRecording = false;
                    updateRecordButtonState();
                    stream.getTracks().forEach(track => track.stop());
                };
                mediaRecorder.start();
                isRecording = true;
                updateRecordButtonState();
                
                // Set up recording length limit timer
                if (recordingLimit) {
                    const limitSeconds = parseInt(recordingLimit);
                    if (!isNaN(limitSeconds) && limitSeconds > 0) {
                        recordingTimer = setTimeout(() => {
                            if (isRecording) {
                                stopRecording();
                            }
                        }, limitSeconds * 1000);
                    }
                } else {
                    // Default to 600 seconds (10 minutes) for all recording types
                    recordingTimer = setTimeout(() => {
                        if (isRecording) {
                            stopRecording();
                        }
                    }, 600 * 1000);
                }
            } catch (err) {
                console.error("Mic error:", err);
                console.error("Details:", JSON.stringify(err));
                console.error("Name:", err?.name);
                console.error("Message:", err?.message);
                let msg = 'Error starting recording.';
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') msg = 'Mic access denied.';
                else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') msg = 'No mic found.';
                else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') msg = 'Mic in use.';
                else if (err.message) msg = `Error: ${err.message}`;
                else msg = 'Unknown mic error.';
                setStatus(msg, true);
                isRecording = false;
                updateRecordButtonState();
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                try {
                    // Clear the recording timer
                    if (recordingTimer) {
                        clearTimeout(recordingTimer);
                        recordingTimer = null;
                    }
                    
                    mediaRecorder.stop();
                    isRecording = false;
                    setStatus('Processing recording...');
                    updateRecordButtonState();
                } catch (error) {
                    console.error("Error stopping recorder:", error);
                    setStatus('Error stopping recording.', true);
                    isRecording = false;
                    updateRecordButtonState();
                    if (mediaRecorder?.stream) {
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    }
                }
            }
        }

        // --- FFmpeg Conversion Function ---
        async function convertAudioAndSave(originalBlob, originalMimeType) {
            if (!ffmpegLoaded || !ffmpeg) {
                setStatus('FFmpeg not ready. Cannot convert/save.', true);
                updateRecordButtonState();
                return;
            }
            setStatus('Converting audio to MP3...');
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = `Starting conversion of ${originalMimeType}...\n`;
            // Don't disable the button here, let updateRecordButtonState handle it
            updateRecordButtonState();

            try {
                const arrayBuffer = await originalBlob.arrayBuffer();
                const inputData = new Uint8Array(arrayBuffer);
                const inputFilename = `input.${originalMimeType.split('/')[1]?.split(';')[0] || 'bin'}`;
                const outputFilename = `output.${TARGET_FORMAT}`;

                ffmpegLog.textContent += `Writing input file (${inputFilename})...\n`;
                await ffmpeg.FS('writeFile', inputFilename, inputData);
                ffmpegLog.textContent += `Input file written.\n`;

                const ffmpegCommand = [
                    '-i', inputFilename,
                    '-ac', `${TARGET_CHANNELS}`,
                    '-q:a', TARGET_QUALITY,
                    outputFilename
                ];

                ffmpegLog.textContent += `Running FFmpeg: ffmpeg ${ffmpegCommand.join(' ')}\n`;
                await ffmpeg.run(...ffmpegCommand);
                ffmpegLog.textContent += `FFmpeg execution finished.\n`;

                ffmpegLog.textContent += `Reading output file (${outputFilename})...\n`;
                const outputData = ffmpeg.FS('readFile', outputFilename);
                ffmpegLog.textContent += `Output file read (${outputData.length} bytes).\n`;

                const mp3Blob = new Blob([outputData.buffer], { type: TARGET_MIME_TYPE });
                console.log("Conversion successful. MP3 Blob created:", mp3Blob);

                try {
                    await ffmpeg.FS('unlink', inputFilename);
                    await ffmpeg.FS('unlink', outputFilename);
                    ffmpegLog.textContent += `Cleaned up virtual files.\n`;
                } catch (cleanupError) {
                    console.warn("FFmpeg cleanup warning:", cleanupError);
                    ffmpegLog.textContent += `Cleanup warning: ${cleanupError.message}\n`;
                }

                setStatus('Saving converted MP3...');
                const newId = await addRecordingToDB(mp3Blob, TARGET_MIME_TYPE);
                setStatus(`MP3 recording saved (ID: ${newId}).`);
                await renderHistory();

                // Attempt automatic transcription if API key is available
                if (currentApiKey) {
                    setStatus(`Starting automatic transcription for recording ${newId}...`);
                    await transcribeAudio(newId, mp3Blob, TARGET_MIME_TYPE);
                } else {
                    setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                    displayTranscription("API Key needed for transcription.");
                }

            } catch (error) {
                console.error("FFmpeg conversion failed:", error);
                setStatus(`Error during MP3 conversion: ${error.message || error}`, true);
                ffmpegLog.textContent += `ERROR: ${error.message || error}\n`;
            } finally {
                updateRecordButtonState();
            }
        }

        function playAudio(blob, button) {
            try {
                // If there's already an audio playing, stop it
                if (currentlyPlayingAudio) {
                    currentlyPlayingAudio.pause();
                    currentlyPlayingAudio.currentTime = 0;
                    if (currentlyPlayingButton) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                    }
                }

                // If clicking the same button that's currently playing, just stop
                if (currentlyPlayingButton === button) {
                    currentlyPlayingAudio = null;
                    currentlyPlayingButton = null;
                    return;
                }

                // Create and play new audio
                const audioUrl = URL.createObjectURL(blob);
                const audio = new Audio(audioUrl);
                
                audio.onerror = (e) => {
                    console.error("Audio play error:", e);
                    setStatus('Error playing audio.', true);
                    URL.revokeObjectURL(audioUrl);
                };
                
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    if (currentlyPlayingButton === button) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                        currentlyPlayingAudio = null;
                        currentlyPlayingButton = null;
                    }
                };

                audio.play();
                currentlyPlayingAudio = audio;
                currentlyPlayingButton = button;
                button.innerHTML = `<i data-lucide="pause" style="width: 18px; height: 18px;"></i>`;
                lucide.createIcons();
            } catch (error) {
                console.error("Audio object error:", error);
                setStatus('Could not play audio.', true);
            }
        }

        // --- Transcription (Updated to support multiple APIs) ---
        async function transcribeAudio(id, audioBlob, mimeType) {
            // Check if any API is enabled and has a key
            if (!geminiEnabled && !openaiEnabled && !groqEnabled && !assemblyEnabled) {
                setStatus('No transcription API enabled.', true);
                displayTranscription("No transcription API enabled. Please enable an API in settings.");
                return;
            }
            
            if (geminiEnabled && !currentApiKey) {
                setStatus('Gemini API Key needed.', true);
                displayTranscription("Gemini API Key needed for transcription.");
                return;
            }
            
            if (openaiEnabled && !currentOpenaiApiKey) {
                setStatus('OpenAI API Key needed.', true);
                displayTranscription("OpenAI API Key needed for transcription.");
                return;
            }
            
            if (groqEnabled && !currentGroqApiKey) {
                setStatus('Groq API Key needed.', true);
                displayTranscription("Groq API Key needed for transcription.");
                return;
            }
            
            if (assemblyEnabled && !currentAssemblyApiKey) {
                setStatus('Assembly AI API Key needed.', true);
                displayTranscription("Assembly AI API Key needed for transcription.");
                return;
            }
            
            if (!audioBlob) {
                setStatus('Invalid audio.', true);
                return;
            }
            
            setStatus(`Transcribing recording ${id}...`);
            displayTranscription("Transcribing...");
            transcriptionSection.classList.remove('hidden');
            copyButton.disabled = true;
            copyButton.classList.add('opacity-50', 'cursor-not-allowed');
            copyButton.classList.remove('opacity-100', 'cursor-pointer');

            try {
                let transcriptionText = "Transcription not found.";
                let recordingTokenUsage = { input: 0, output: 0 };
                
                // Try Gemini first if enabled
                if (geminiEnabled && currentApiKey) {
                    try {
                        const base64Audio = await blobToBase64(audioBlob);
                        const requestBody = { contents: [{ parts: [ { text: "Please transcribe the following audio recording:" }, { inline_data: { mime_type: mimeType, data: base64Audio } } ]}] };
                        const response = await fetch(GEMINI_API_URL + currentApiKey, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(requestBody) });
                        const data = await response.json();
                        
                        if (!response.ok) {
                            console.error("Gemini API Error:", data);
                            throw new Error(data?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        // Update token usage
                        if (data.usage) {
                            recordingTokenUsage.input = data.usage.promptTokenCount || 0;
                            recordingTokenUsage.output = data.usage.candidatesTokenCount || 0;
                            
                            // Update global token usage
                            tokenUsage.input += recordingTokenUsage.input;
                            tokenUsage.output += recordingTokenUsage.output;
                            localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                        }
                        
                        if (data.candidates?.[0]?.content?.parts?.[0]?.text) {
                            transcriptionText = data.candidates[0].content.parts[0].text;
                        } else if (data.candidates?.[0]?.finishReason === "SAFETY") {
                            transcriptionText = "Blocked: safety.";
                        } else {
                            console.warn("Unexpected Gemini API response:", data);
                            const textPart = data.candidates?.[0]?.content?.parts?.find(p => p.text);
                            if (textPart) transcriptionText = textPart.text;
                        }
                        
                        console.log("Gemini transcription OK:", transcriptionText);
                    } catch (error) {
                        console.error("Gemini transcription failed:", error);
                        // If Gemini fails and other APIs are enabled, try them
                        if ((openaiEnabled && currentOpenaiApiKey) || (groqEnabled && currentGroqApiKey)) {
                            throw new Error("Gemini failed, trying other APIs...");
                        } else {
                            throw error;
                        }
                    }
                }
                
                // Try OpenAI if Gemini is not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && openaiEnabled && currentOpenaiApiKey) {
                    try {
                        // Use transcription API for Whisper models
                        const formData = new FormData();
                        formData.append('file', audioBlob, 'audio.mp3');
                        formData.append('model', 'whisper-1');
                        
                        // Only add language if not auto
                        if (openaiLanguage !== 'auto') {
                            formData.append('language', openaiLanguage);
                        }
                        
                        const response = await fetch(`${OPENAI_API_URL}/v1/audio/transcriptions`, {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${currentOpenaiApiKey}`
                            },
                            body: formData
                        });
                        
                        if (!response.ok) {
                            const errorData = await response.json();
                            console.error("OpenAI API Error:", errorData);
                            throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        const data = await response.json();
                        transcriptionText = data.text || "Transcription not found.";
                        console.log("OpenAI Whisper transcription OK:", transcriptionText);
                        
                        // OpenAI doesn't provide token usage in the same way, so we'll estimate
                        // Rough estimate: 1 token per 4 characters
                        const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                        recordingTokenUsage.input = 0; // We don't know the input tokens
                        recordingTokenUsage.output = estimatedTokens;
                        
                        // Update global token usage
                        tokenUsage.output += estimatedTokens;
                        localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                    } catch (error) {
                        console.error("OpenAI transcription failed:", error);
                        // If OpenAI fails and Groq is enabled, try Groq
                        if (groqEnabled && currentGroqApiKey) {
                            throw new Error("OpenAI failed, trying Groq...");
                        } else {
                            throw error;
                        }
                    }
                }
                
                // Try Groq if other APIs are not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && (!openaiEnabled || !currentOpenaiApiKey) && groqEnabled && currentGroqApiKey) {
                    try {
                        const formData = new FormData();
                        formData.append('file', audioBlob, 'audio.mp3');
                        formData.append('model', groqModel);
                        formData.append('temperature', '0');
                        formData.append('response_format', 'text');
                        
                        // Only add language if not auto
                        if (groqLanguage !== 'auto') {
                            formData.append('language', groqLanguage);
                        }
                        
                        const response = await fetch(GROQ_API_URL, {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${currentGroqApiKey}`
                            },
                            body: formData
                        });
                        
                        if (!response.ok) {
                            const errorData = await response.json();
                            console.error("Groq API Error:", errorData);
                            throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        // Groq returns plain text, not JSON
                        transcriptionText = await response.text();
                        console.log("Groq transcription OK:", transcriptionText);
                        
                        // Groq doesn't provide token usage in the same way, so we'll estimate
                        // Rough estimate: 1 token per 4 characters
                        const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                        recordingTokenUsage.input = 0; // We don't know the input tokens
                        recordingTokenUsage.output = estimatedTokens;
                        
                        // Update global token usage
                        tokenUsage.output += estimatedTokens;
                        localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                    } catch (error) {
                        console.error("Groq transcription failed:", error);
                        throw error;
                    }
                }
                
                // Try Assembly AI if other APIs are not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && 
                    (!openaiEnabled || !currentOpenaiApiKey) && 
                    (!groqEnabled || !currentGroqApiKey) && 
                    assemblyEnabled && currentAssemblyApiKey) {
                    try {
                        // Determine which API URL to use based on the EU/US setting
                        const apiUrl = assemblyEuServer ? ASSEMBLY_API_URL_EU : ASSEMBLY_API_URL_US;
                        
                        setStatus('Uploading audio to Assembly AI...');
                        
                        // Step 1: Upload the audio file directly
                        const formData = new FormData();
                        
                        // Determine the correct file extension and MIME type
                        let fileExtension = 'webm';
                        let mimeTypeToUse = 'audio/webm';
                        
                        // Check if the blob already has a type
                        if (audioBlob.type && audioBlob.type !== 'application/octet-stream') {
                            mimeTypeToUse = audioBlob.type;
                            // Extract extension from MIME type
                            const mimeParts = audioBlob.type.split('/');
                            if (mimeParts.length > 1) {
                                fileExtension = mimeParts[1].split(';')[0];
                            }
                        }
                        
                        // Create a new Blob with the correct MIME type
                        const audioBlobWithType = new Blob([audioBlob], { type: mimeTypeToUse });
                        
                        // Log the file details for debugging
                        console.log("Original blob type:", audioBlob.type);
                        console.log("Using MIME type:", mimeTypeToUse);
                        console.log("File extension:", fileExtension);
                        console.log("File size:", audioBlob.size);
                        
                        // Append the file with the correct name and type
                        formData.append('audio_file', audioBlobWithType, `audio.${fileExtension}`);
                        
                        const uploadResponse = await fetch(`${apiUrl}/upload`, {
                            method: 'POST',
                            headers: {
                                'Authorization': currentAssemblyApiKey
                            },
                            body: formData
                        });
                        
                        if (!uploadResponse.ok) {
                            const errorText = await uploadResponse.text();
                            console.error("Assembly AI Upload Error:", errorText);
                            throw new Error(`Upload failed: ${errorText}`);
                        }
                        
                        const uploadData = await uploadResponse.json();
                        const audioUrl = uploadData.upload_url;
                        
                        if (!audioUrl) {
                            throw new Error("Failed to get upload URL from Assembly AI");
                        }
                        
                        setStatus('Starting transcription with Assembly AI...');
                        
                        // Step 3: Create the transcription request
                        const transcriptionRequest = {
                            audio_url: audioUrl
                        };
                        
                        // Only add language if not auto and not empty
                        if (assemblyLanguage && assemblyLanguage !== 'auto') {
                            transcriptionRequest.language_code = assemblyLanguage;
                        }
                        
                        // Step 4: Submit the transcription request
                        const transcriptionResponse = await fetch(`${apiUrl}/transcript`, {
                            method: 'POST',
                            headers: {
                                'Authorization': currentAssemblyApiKey,
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify(transcriptionRequest)
                        });
                        
                        if (!transcriptionResponse.ok) {
                            const errorText = await transcriptionResponse.text();
                            console.error("Assembly AI Transcription Error:", errorText);
                            throw new Error(`Transcription request failed: ${errorText}`);
                        }
                        
                        const transcriptionData = await transcriptionResponse.json();
                        const transcriptionId = transcriptionData.id;
                        
                        if (!transcriptionId) {
                            throw new Error("Failed to get transcription ID from Assembly AI");
                        }
                        
                        setStatus('Waiting for Assembly AI transcription to complete...');
                        
                        // Step 5: Poll for transcription completion
                        let completed = false;
                        let attempts = 0;
                        const maxAttempts = 60; // 5 minutes max (5s intervals)
                        
                        while (!completed && attempts < maxAttempts) {
                            await new Promise(resolve => setTimeout(resolve, 5000)); // Wait 5 seconds
                            
                            const pollResponse = await fetch(`${apiUrl}/transcript/${transcriptionId}`, {
                                method: 'GET',
                                headers: {
                                    'Authorization': currentAssemblyApiKey
                                }
                            });
                            
                            if (!pollResponse.ok) {
                                const errorText = await pollResponse.text();
                                console.error("Assembly AI Poll Error:", errorText);
                                throw new Error(`Polling failed: ${errorText}`);
                            }
                            
                            const pollData = await pollResponse.json();
                            
                            if (pollData.status === 'completed') {
                                completed = true;
                                transcriptionText = pollData.text || "Transcription not found.";
                                console.log("Assembly AI transcription completed:", transcriptionText);
                            } else if (pollData.status === 'error') {
                                throw new Error(`Assembly AI error: ${pollData.error || 'Unknown error'}`);
                            }
                            
                            attempts++;
                            setStatus(`Waiting for transcription... (${attempts * 5}s)`);
                        }
                        
                        if (!completed) {
                            throw new Error("Transcription timed out after 5 minutes");
                        }
                        
                        // Update token usage (not provided directly by Assembly AI)
                        // Use a rough estimate based on audio duration
                        const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                        recordingTokenUsage.input = 0; // We don't know the input tokens
                        recordingTokenUsage.output = estimatedTokens;
                        
                        // Update global token usage
                        tokenUsage.output += estimatedTokens;
                        localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                        
                    } catch (error) {
                        console.error("Assembly AI transcription failed:", error);
                        throw error;
                    }
                }
                
                setStatus(`Transcription complete (ID: ${id}).`);
                displayTranscription(transcriptionText);
                
                // Update recording with transcription and token usage
                const recording = await getRecordingByIdFromDB(id);
                if (recording) {
                    recording.transcription = transcriptionText;
                    recording.tokenUsage = recordingTokenUsage;
                    
                    // Update in database
                    const transaction = db.transaction([STORE_NAME], 'readwrite');
                    const store = transaction.objectStore(STORE_NAME);
                    await new Promise((resolve, reject) => {
                        const request = store.put(recording);
                        request.onsuccess = () => resolve();
                        request.onerror = (event) => reject(event.target.error);
                    });
                }
                
                await renderHistory();
            } catch (error) {
                console.error("Transcription failed:", error);
                setStatus(`Transcription error: ${error.message}`, true);
                displayTranscription(`Error: ${error.message}`);
                transcriptionSection.classList.remove('hidden');
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }

        // --- Utility Functions ---
        function formatDuration(seconds) {
            const min = Math.floor(seconds / 60);
            const sec = Math.floor(seconds % 60);
            return `${min}:${sec.toString().padStart(2, '0')}`;
        }
        
        async function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    // Remove the "data:audio/mpeg;base64," prefix from the data URL
                    const base64data = reader.result.split(',')[1];
                    resolve(base64data);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        // History Actions (Unchanged)
        async function deleteRecording(id) { if (confirm(`Delete recording ${id}?`)) { try { await deleteRecordingFromDB(id); setStatus(`Recording ${id} deleted.`); await renderHistory(); } catch (error) { setStatus('Error deleting.', true); console.error("Delete error:", error); } } }

        // Event Listeners
        recordButton.addEventListener('click', () => {
            if (isRecording) {
                stopRecording();
            } else {
                transcriptionOutput.value = '';
                transcriptionSection.classList.add('hidden');
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
                startRecording();
            }
        });
        
        // Auto-save API keys on input change
        apiKeyInput.addEventListener('input', () => {
            currentApiKey = apiKeyInput.value.trim();
            if (currentApiKey) {
                localStorage.setItem('geminiApiKey', currentApiKey);
                setStatus('Gemini API Key saved.');
            } else {
                localStorage.removeItem('geminiApiKey');
                setStatus('Gemini API Key removed.', true);
            }
        });
        
        openaiApiKeyInput.addEventListener('input', () => {
            currentOpenaiApiKey = openaiApiKeyInput.value.trim();
            if (currentOpenaiApiKey) {
                localStorage.setItem('openaiApiKey', currentOpenaiApiKey);
                setStatus('OpenAI API Key saved.');
            } else {
                localStorage.removeItem('openaiApiKey');
                setStatus('OpenAI API Key removed.', true);
            }
        });
        
        groqApiKeyInput.addEventListener('input', () => {
            currentGroqApiKey = groqApiKeyInput.value.trim();
            if (currentGroqApiKey) {
                localStorage.setItem('groqApiKey', currentGroqApiKey);
                setStatus('Groq API Key saved.');
            } else {
                localStorage.removeItem('groqApiKey');
                setStatus('Groq API Key removed.', true);
            }
        });
        
        // Recording limit input
        recordingLimitInput.addEventListener('input', () => {
            recordingLimit = recordingLimitInput.value.trim();
            if (recordingLimit) {
                localStorage.setItem('recordingLimit', recordingLimit);
                setStatus('Recording limit updated.');
            } else {
                localStorage.removeItem('recordingLimit');
                setStatus('Recording limit reset to auto.');
            }
        });
        
        copyButton.addEventListener('click', () => {
            if (transcriptionOutput.value && !copyButton.disabled) {
                navigator.clipboard.writeText(transcriptionOutput.value).then(() => {
                    setStatus('Copied!');
                    const copyIcon = copyButton.querySelector('[data-lucide="copy"]');
                    const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`;
                    const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`;
                    copyButton.innerHTML = checkIconHTML;
                    lucide.createIcons();
                    setTimeout(() => {
                        copyButton.innerHTML = originalIconHTML;
                        lucide.createIcons();
                    }, 1500);
                }).catch(err => {
                    console.error('Copy failed: ', err);
                    setStatus('Copy failed.', true);
                });
            }
        });
        
        // Settings panel controls
        settingsButton.addEventListener('click', () => {
            settingsVisible = !settingsVisible;
            if (settingsVisible) {
                settingsSection.classList.remove('hidden');
            } else {
                settingsSection.classList.add('hidden');
            }
            lucide.createIcons();
        });
        
        closeSettings.addEventListener('click', () => {
            settingsVisible = false;
            settingsSection.classList.add('hidden');
            lucide.createIcons();
        });
        
        // Dark mode toggle
        const darkModeToggle = document.getElementById('darkModeToggle');
        darkModeToggle.addEventListener('change', () => {
            darkMode = darkModeToggle.checked ? 'dark' : 'system';
            localStorage.setItem('darkMode', darkMode);
            applyTheme();
        });
        
        // FFmpeg toggle
        const ffmpegToggle = document.getElementById('ffmpegToggle');
        ffmpegToggle.addEventListener('change', async () => {
            ffmpegEnabled = ffmpegToggle.checked;
            localStorage.setItem('ffmpegEnabled', ffmpegEnabled);
            
            if (ffmpegEnabled) {
                await loadFFmpeg();
            } else {
                ffmpegStatus.textContent = i18n.t('ffmpeg_disabled');
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = i18n.t('ready_to_record');
                setStatus(i18n.t('ready_to_record'));
                updateRecordButtonState();
            }
        });
        
        // API toggles - only one can be active at a time
        geminiToggle.addEventListener('change', () => {
            if (geminiToggle.checked) {
                // Disable other APIs
                openaiToggle.checked = false;
                groqToggle.checked = false;
                assemblyToggle.checked = false;
                openaiEnabled = false;
                groqEnabled = false;
                assemblyEnabled = false;
                openaiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
                assemblySettings.classList.add('hidden');
            }
            
            geminiEnabled = geminiToggle.checked;
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            
            if (geminiEnabled) {
                geminiSettings.classList.remove('hidden');
            } else {
                geminiSettings.classList.add('hidden');
            }
            
            // Update upload message with new API limits
            updateUploadMessage();
        });
        
        openaiToggle.addEventListener('change', () => {
            if (openaiToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                groqToggle.checked = false;
                assemblyToggle.checked = false;
                geminiEnabled = false;
                groqEnabled = false;
                assemblyEnabled = false;
                geminiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
                assemblySettings.classList.add('hidden');
            }
            
            openaiEnabled = openaiToggle.checked;
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            
            if (openaiEnabled) {
                openaiSettings.classList.remove('hidden');
            } else {
                openaiSettings.classList.add('hidden');
            }
            
            // Update upload message with new API limits
            updateUploadMessage();
        });
        
        groqToggle.addEventListener('change', () => {
            if (groqToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                openaiToggle.checked = false;
                assemblyToggle.checked = false;
                geminiEnabled = false;
                openaiEnabled = false;
                assemblyEnabled = false;
                geminiSettings.classList.add('hidden');
                openaiSettings.classList.add('hidden');
                assemblySettings.classList.add('hidden');
            }
            
            groqEnabled = groqToggle.checked;
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            
            if (groqEnabled) {
                groqSettings.classList.remove('hidden');
            } else {
                groqSettings.classList.add('hidden');
            }
            
            // Update upload message with new API limits
            updateUploadMessage();
        });
        
        // OpenAI language change
        openaiLanguageSelect.addEventListener('change', () => {
            openaiLanguage = openaiLanguageSelect.value;
            localStorage.setItem('openaiLanguage', openaiLanguage);
        });
        
        // Groq model change
        groqModelSelect.addEventListener('change', () => {
            groqModel = groqModelSelect.value;
            localStorage.setItem('groqModel', groqModel);
        });
        
        // Groq language change
        groqLanguageSelect.addEventListener('change', () => {
            groqLanguage = groqLanguageSelect.value;
            localStorage.setItem('groqLanguage', groqLanguage);
        });

        // Assembly AI toggle
        assemblyToggle.addEventListener('change', () => {
            if (assemblyToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                openaiToggle.checked = false;
                groqToggle.checked = false;
                geminiEnabled = false;
                openaiEnabled = false;
                groqEnabled = false;
                geminiSettings.classList.add('hidden');
                openaiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
            }
            
            assemblyEnabled = assemblyToggle.checked;
            localStorage.setItem('assemblyEnabled', assemblyEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            
            if (assemblyEnabled) {
                assemblySettings.classList.remove('hidden');
                // Check if API key is available
                if (!currentAssemblyApiKey) {
                    setStatus('Assembly AI API Key needed.', true);
                    displayTranscription("Assembly AI API Key needed for transcription.");
                } else {
                    setStatus('Assembly AI ready for transcription.');
                }
            } else {
                assemblySettings.classList.add('hidden');
            }
            
            // Update transcription button states
            renderHistory();
            
            // Update upload message with new API limits
            updateUploadMessage();
        });
        
        // Assembly API key input
        assemblyApiKeyInput.addEventListener('input', () => {
            currentAssemblyApiKey = assemblyApiKeyInput.value.trim();
            if (currentAssemblyApiKey) {
                localStorage.setItem('assemblyApiKey', currentAssemblyApiKey);
                setStatus('Assembly AI API Key saved.');
            } else {
                localStorage.removeItem('assemblyApiKey');
                setStatus('Assembly AI API Key removed.', true);
            }
        });
        
        // Assembly EU server toggle
        assemblyEuToggle.addEventListener('change', () => {
            assemblyEuServer = assemblyEuToggle.checked;
            localStorage.setItem('assemblyEuServer', assemblyEuServer);
            setStatus(`Assembly AI server set to ${assemblyEuServer ? 'EU' : 'US'}.`);
        });
        
        // Assembly language change
        assemblyLanguageSelect.addEventListener('change', () => {
            assemblyLanguage = assemblyLanguageSelect.value;
            localStorage.setItem('assemblyLanguage', assemblyLanguage);
        });

        // --- Initialization ---
        async function initializeApp() {
            lucide.createIcons();
            apiKeyInput.value = currentApiKey;
            openaiApiKeyInput.value = currentOpenaiApiKey;
            groqApiKeyInput.value = currentGroqApiKey;
            assemblyApiKeyInput.value = currentAssemblyApiKey;
            openaiLanguageSelect.value = openaiLanguage;
            groqModelSelect.value = groqModel;
            groqLanguageSelect.value = groqLanguage;
            assemblyLanguageSelect.value = assemblyLanguage;
            assemblyEuToggle.checked = assemblyEuServer;
            geminiToggle.checked = geminiEnabled;
            openaiToggle.checked = openaiEnabled;
            groqToggle.checked = groqEnabled;
            assemblyToggle.checked = assemblyEnabled;
            recordingLimitInput.value = recordingLimit;
            darkModeToggle.checked = darkMode === 'dark';
            ffmpegToggle.checked = ffmpegEnabled;
            interfaceLanguage.value = currentLanguage;

            // Initialize i18n system
            await i18n.init().loadTranslations();
            i18n.translatePage();
            
            // Update theme based on preference
            applyTheme();
            
            // Show help modal on first visit
            if (showHelpOnStartup) {
                showHelpModal();
            }

            // Initialize database and load recordings
            await initDB();
            await renderHistory();
            
            // Set initial status based on FFmpeg state
            if (ffmpegEnabled) {
                // If FFmpeg is enabled, load it
                await loadFFmpeg();
            } else {
                // If FFmpeg is disabled, set appropriate status
                ffmpegStatus.textContent = i18n.t('ffmpeg_disabled');
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = i18n.t('ready_to_record');
                setStatus(i18n.t('ready_to_record'));
                updateRecordButtonState(); // Ensure button state is updated
            }
            
            // Update the upload message with the current API limits
            updateUploadMessage();
        }
        
        // --- Language switching ---
        interfaceLanguage.addEventListener('change', async () => {
            const newLanguage = interfaceLanguage.value;
            await i18n.setLocale(newLanguage);
            i18n.translatePage();
            
            // Update any dynamically generated content
            updateUploadMessage();
            setStatus(ffmpegEnabled ? 
                (ffmpegLoaded ? i18n.t('ready_to_record') : i18n.t('loading_ffmpeg')) : 
                i18n.t('ready_to_record'));
        });
        
        // Listen for language changes
        window.addEventListener('languageChanged', (event) => {
            // Update the language selector
            interfaceLanguage.value = event.detail.locale;
            // Translate the page
            i18n.translatePage();
        });
        
        // --- Help Modal Functions ---
        function showHelpModal() {
            helpModal.classList.remove('hidden');
            helpVisible = true;
        }
        
        function hideHelpModal() {
            helpModal.classList.add('hidden');
            helpVisible = false;
        }
        
        // Add event listeners for help modal
        helpButton.addEventListener('click', showHelpModal);
        
        closeHelp.addEventListener('click', hideHelpModal);
        
        dontShowAgainButton.addEventListener('click', () => {
            localStorage.setItem('showHelpOnStartup', 'false');
            showHelpOnStartup = false;
            hideHelpModal();
        });
        
        // Close modals when clicking outside
        window.addEventListener('click', (event) => {
            if (event.target === helpModal) {
                hideHelpModal();
            }
        });

        // Apply theme based on system preference or user choice
        function applyTheme() {
            if (darkMode === 'dark') {
                document.body.classList.add('dark-mode');
            } else if (darkMode === 'system') {
                if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                    document.body.classList.add('dark-mode');
                } else {
                    document.body.classList.remove('dark-mode');
                }
            } else {
                document.body.classList.remove('dark-mode');
            }
        }
        
        // Listen for system theme changes
        if (window.matchMedia) {
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {
                if (darkMode === 'system') {
                    if (e.matches) {
                        document.body.classList.add('dark-mode');
                    } else {
                        document.body.classList.remove('dark-mode');
                    }
                }
            });
        }

        // --- File Upload with Drag and Drop ---
        function setupDragAndDrop() {
            const dropZone = recordButtonContainer;
            
            // Prevent default drag behaviors
            ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
                dropZone.addEventListener(eventName, preventDefaults, false);
                document.body.addEventListener(eventName, preventDefaults, false);
            });
            
            // Highlight drop zone when item is dragged over it
            ['dragenter', 'dragover'].forEach(eventName => {
                dropZone.addEventListener(eventName, highlight, false);
            });
            
            ['dragleave', 'drop'].forEach(eventName => {
                dropZone.addEventListener(eventName, unhighlight, false);
            });
            
            // Handle dropped files
            dropZone.addEventListener('drop', handleDrop, false);
            
            function preventDefaults(e) {
                e.preventDefault();
                e.stopPropagation();
            }
            
            function highlight() {
                isDraggingFile = true;
                dropZoneOverlay.classList.remove('hidden');
            }
            
            function unhighlight() {
                isDraggingFile = false;
                dropZoneOverlay.classList.add('hidden');
            }
            
            async function handleDrop(e) {
                const dt = e.dataTransfer;
                const files = dt.files;
                
                if (files.length === 0) {
                    setStatus(i18n.t('no_file_detected'), true);
                    return;
                }
                
                if (files.length > 1) {
                    setStatus(i18n.t('drop_single_file'), true);
                    return;
                }
                
                const file = files[0];
                
                // Check if it's an audio file with allowed extensions
                const allowedExtensions = ['m4a', 'wav', 'mp3'];
                const fileExtension = file.name.split('.').pop().toLowerCase();
                
                if (!file.type.startsWith('audio/') || !allowedExtensions.includes(fileExtension)) {
                    setStatus(i18n.t('file_type_error'), true);
                    return;
                }
                
                // Check file size based on selected API
                const selectedAPI = getSelectedAPI();
                const maxSize = FILE_SIZE_LIMITS[selectedAPI];
                
                if (file.size > maxSize) {
                    const maxSizeMB = maxSize / (1024 * 1024);
                    setStatus(`${i18n.t('file_too_large')} ${selectedAPI}. ${i18n.t('max')}: ${maxSizeMB}MB.`, true);
                    return;
                }
                
                setStatus(i18n.t('processing'));
                
                try {
                    // Add the file directly to the database without conversion
                    const newId = await addRecordingToDB(file, file.type);
                    setStatus(`${i18n.t('file_uploaded')} (ID: ${newId}).`);
                    await renderHistory();
                    
                    // Attempt automatic transcription if API key is available
                    if ((geminiEnabled && currentApiKey) || 
                        (openaiEnabled && currentOpenaiApiKey) || 
                        (groqEnabled && currentGroqApiKey) || 
                        (assemblyEnabled && currentAssemblyApiKey)) {
                        setStatus(`${i18n.t('starting_transcription')} ${newId}...`);
                        await transcribeAudio(newId, file, file.type);
                    } else {
                        setStatus(i18n.t('file_uploaded_no_api'), true);
                        displayTranscription(i18n.t('api_key_needed'));
                    }
                } catch (error) {
                    console.error("Error processing uploaded file:", error);
                    setStatus(`${i18n.t('error_processing_file')}: ${error.message}`, true);
                }
            }
        }
        
        function getSelectedAPI() {
            if (geminiEnabled) return 'gemini';
            if (openaiEnabled) return 'openai';
            if (groqEnabled) return 'groq';
            if (assemblyEnabled) return 'assembly';
            return 'gemini'; // Default
        }
        
        function updateUploadMessage() {
            const selectedAPI = getSelectedAPI();
            const maxSizeMB = FILE_SIZE_LIMITS[selectedAPI] / (1024 * 1024);
            uploadMessage.textContent = `${i18n.t('drag_drop')} (${i18n.t('max')} ${maxSizeMB}MB)`;
        }
        
        function formatFileSize(bytes) {
            if (bytes < 1024) return bytes + ' B';
            if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
            return (bytes / (1024 * 1024)).toFixed(1) + ' MB';
        }

        // Initialize the app when the DOM is loaded
        document.addEventListener('DOMContentLoaded', initializeApp);
    </script>
</body>
</html>
