<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Recorder & Transcriber (MP3)</title>
    <script src="https://cdn.tailwindcss.com?plugins=forms"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://unpkg.com/@ffmpeg/ffmpeg@0.11.0/dist/ffmpeg.min.js"></script>

    <style>
        /* Styles (pulse, scrollbar, layout, disabled, lucide, ffmpegLog) remain the same */
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
        .recording-pulse { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        .history-list::-webkit-scrollbar { width: 8px; }
        .history-list::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb { background: #888; border-radius: 10px; }
        .history-list::-webkit-scrollbar-thumb:hover { background: #555; }
        html, body { height: 100%; margin: 0; font-family: sans-serif; }
        .main-container { display: flex; flex-direction: column; min-height: 100vh; }
        .content-grow { flex-grow: 1; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        [data-lucide] { width: 1em; height: 1em; display: inline-block; vertical-align: middle; }
        #ffmpegLog { font-family: monospace; font-size: 0.75rem; max-height: 100px; overflow-y: auto; background-color: #f5f5f5; border: 1px solid #e0e0e0; padding: 5px; margin-top: 10px; white-space: pre-wrap; word-break: break-all; }
        
        /* Dark mode styles */
        :root {
            color-scheme: light dark;
        }
        
        body.dark-mode {
            background-color: #1a1a1a;
            color: #e0e0e0;
        }
        
        body.dark-mode .bg-white {
            background-color: #2d2d2d;
        }
        
        body.dark-mode .text-gray-800 {
            color: #e0e0e0;
        }
        
        body.dark-mode .text-gray-600 {
            color: #b0b0b0;
        }
        
        body.dark-mode .text-gray-500 {
            color: #a0a0a0;
        }
        
        body.dark-mode .bg-gray-50 {
            background-color: #333333;
        }
        
        body.dark-mode .border-gray-200 {
            border-color: #444444;
        }
        
        body.dark-mode #ffmpegLog {
            background-color: #222222;
            border-color: #444444;
            color: #e0e0e0;
        }
        
        body.dark-mode .bg-gray-100 {
            background-color: #1a1a1a;
        }
        
        /* Toggle switch styles */
        .toggle-switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 24px;
        }
        
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .toggle-slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 24px;
        }
        
        .toggle-slider:before {
            position: absolute;
            content: "";
            height: 16px;
            width: 16px;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        
        input:checked + .toggle-slider {
            background-color: #2196F3;
        }
        
        input:checked + .toggle-slider:before {
            transform: translateX(26px);
        }
    </style>
</head>
<body class="bg-gray-100">
    <div class="main-container container mx-auto p-4 md:p-8 max-w-4xl">

        <header class="mb-8 text-center relative">
            <h1 class="text-3xl font-bold text-gray-800">Voice Recorder & Transcriber (MP3)</h1>
            <p class="text-gray-600">Record audio, convert to MP3 (VBR ~q1), save locally, and transcribe using Gemini.</p>
            <button id="settingsButton" class="absolute top-0 right-0 p-2 text-gray-600 hover:text-gray-800 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                <i data-lucide="settings" style="width: 24px; height: 24px;"></i>
            </button>
        </header>

        <section id="settingsSection" class="mb-6 p-4 bg-white dark:bg-gray-800 rounded-lg shadow hidden">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-xl font-semibold text-gray-700 dark:text-gray-300">Settings</h2>
                <button id="closeSettings" class="p-1 text-gray-600 dark:text-gray-400 hover:text-gray-800 dark:hover:text-gray-200 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 rounded-full">
                    <i data-lucide="x" style="width: 20px; height: 20px;"></i>
                </button>
            </div>
            
            <div id="transcriptionApiSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Transcription API:</h3>
                
                <!-- Gemini API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Google Gemini</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="geminiToggle" checked>
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="geminiSettings" class="mt-2">
                        <label for="apiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="apiKey" name="apiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your API key">
                            <button id="saveApiKey" class="px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">Save</button>
                        </div>
                        <p class="text-xs text-gray-500 dark:text-gray-400 mt-2">Your API key is stored only in your browser's local storage.</p>
                    </div>
                </div>
                
                <!-- OpenAI API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">OpenAI</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="openaiToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="openaiSettings" class="mt-2 hidden">
                        <label for="openaiApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="openaiApiKey" name="openaiApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your OpenAI API key">
                            <button id="saveOpenaiApiKey" class="px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">Save</button>
                        </div>
                        
                        <div class="mt-3">
                            <label for="openaiModel" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Model:</label>
                            <select id="openaiModel" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="whisper-1">Whisper</option>
                                <option value="gpt-4o-audio-preview">GPT-4o Audio Preview</option>
                                <option value="gpt-4o-mini-audio-preview">GPT-4o Mini Audio Preview</option>
                            </select>
                        </div>
                        
                        <div class="mt-3">
                            <label for="openaiLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="openaiLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
                
                <!-- Groq API -->
                <div class="mb-3 p-3 border border-gray-200 dark:border-gray-700 rounded-md">
                    <div class="flex items-center justify-between mb-2">
                        <h4 class="text-sm font-medium text-gray-700 dark:text-gray-300">Groq</h4>
                        <label class="toggle-switch">
                            <input type="checkbox" id="groqToggle">
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                    <div id="groqSettings" class="mt-2 hidden">
                        <label for="groqApiKey" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">API Key:</label>
                        <div class="flex items-center space-x-2">
                            <input type="password" id="groqApiKey" name="groqApiKey" class="flex-grow mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your Groq API key">
                            <button id="saveGroqApiKey" class="px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">Save</button>
                        </div>
                        
                        <div class="mt-3">
                            <label for="groqModel" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Model:</label>
                            <select id="groqModel" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="whisper-large-v3-turbo">Whisper Large V3 Turbo</option>
                                <option value="distil-whisper-large-v3-en">Distil Whisper Large V3 (English)</option>
                                <option value="whisper-large-v3">Whisper Large V3</option>
                            </select>
                        </div>
                        
                        <div class="mt-3">
                            <label for="groqLanguage" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">Language:</label>
                            <select id="groqLanguage" class="mt-1 block w-full rounded-md border-gray-300 dark:border-gray-600 dark:bg-gray-700 dark:text-gray-300 shadow-sm focus:border-indigo-300 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                                <option value="auto">Auto-detect</option>
                                <option value="en">English</option>
                                <option value="es">Spanish</option>
                                <option value="fr">French</option>
                                <option value="de">German</option>
                                <option value="it">Italian</option>
                                <option value="pt">Portuguese</option>
                                <option value="nl">Dutch</option>
                                <option value="pl">Polish</option>
                                <option value="ru">Russian</option>
                                <option value="ja">Japanese</option>
                                <option value="ko">Korean</option>
                                <option value="zh">Chinese</option>
                            </select>
                        </div>
                    </div>
                </div>
            </div>

            <div id="ffmpegSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">FFmpeg Status:</h3>
                <div class="flex items-center justify-between mb-2">
                    <p id="ffmpegStatus" class="text-sm text-gray-600 dark:text-gray-400">Loading FFmpeg...</p>
                    <div class="flex items-center space-x-2">
                        <label class="text-xs text-gray-500 dark:text-gray-400">Enable FFmpeg</label>
                        <label class="toggle-switch">
                            <input type="checkbox" id="ffmpegToggle" checked>
                            <span class="toggle-slider"></span>
                        </label>
                    </div>
                </div>
                <div id="ffmpegLog" class="hidden text-left mt-2"></div>
            </div>
            
            <div id="themeSection" class="mb-4">
                <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Theme:</h3>
                <div class="flex items-center space-x-2">
                    <label class="text-sm text-gray-600 dark:text-gray-400">Dark Mode:</label>
                    <div class="flex items-center space-x-2">
                        <label class="text-xs text-gray-500 dark:text-gray-400">System</label>
                        <label class="toggle-switch">
                            <input type="checkbox" id="darkModeToggle">
                            <span class="toggle-slider"></span>
                        </label>
                        <label class="text-xs text-gray-500 dark:text-gray-400">Dark</label>
                    </div>
                </div>
            </div>
        </section>

        <section class="mb-6 p-6 bg-white rounded-lg shadow text-center">
            <h2 class="text-xl font-semibold mb-4 text-gray-700">Record Audio</h2>
            <button id="recordButton" class="p-4 bg-red-600 text-white rounded-full hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-red-500 transition duration-150 ease-in-out disabled:bg-gray-400" disabled> <i id="micIconPlaceholder" data-lucide="mic" style="width: 32px; height: 32px;"></i>
            </button>
            <p id="statusMessage" class="mt-3 text-gray-600 h-5">Loading FFmpeg...</p> <div id="ffmpegLog" class="hidden text-left"></div>
        </section>

        <section id="transcriptionSection" class="mb-6 p-4 bg-white rounded-lg shadow hidden">
             <h2 class="text-xl font-semibold mb-2 text-gray-700">Transcription</h2>
             <div class="relative">
                <textarea id="transcriptionOutput" rows="4" class="w-full p-2 border border-gray-300 rounded-md bg-gray-50 resize-none" readonly placeholder="Transcription will appear here..."></textarea>
                <button id="copyButton" title="Copy to Clipboard" class="absolute top-2 right-2 p-1 bg-gray-200 text-gray-600 rounded hover:bg-gray-300 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500 opacity-50 cursor-not-allowed" disabled>
                    <i data-lucide="copy" style="width: 18px; height: 18px;"></i>
                </button>
             </div>
        </section>

        <section class="content-grow p-4 bg-white rounded-lg shadow flex flex-col">
            <h2 class="text-xl font-semibold mb-4 text-gray-700 flex-shrink-0">Recording History (MP3)</h2>
            <div id="historyList" class="history-list flex-grow overflow-y-auto space-y-3 pr-2">
                <p id="noHistoryMessage" class="text-gray-500">No recordings yet.</p>
            </div>
        </section>

        <footer class="mt-8 text-center text-sm text-gray-500">
            <p>App by Gemini. Uses browser storage and requires Gemini API Key for transcription.</p>
        </footer>

    </div> <script>
        // --- DOM Elements (Unchanged) ---
        const apiKeyInput = document.getElementById('apiKey');
        const saveApiKeyButton = document.getElementById('saveApiKey');
        const recordButton = document.getElementById('recordButton');
        const statusMessage = document.getElementById('statusMessage');
        const transcriptionSection = document.getElementById('transcriptionSection');
        const transcriptionOutput = document.getElementById('transcriptionOutput');
        const copyButton = document.getElementById('copyButton');
        const historyList = document.getElementById('historyList');
        const noHistoryMessage = document.getElementById('noHistoryMessage');
        const ffmpegLog = document.getElementById('ffmpegLog');
        const settingsButton = document.getElementById('settingsButton');
        const settingsSection = document.getElementById('settingsSection');
        const closeSettings = document.getElementById('closeSettings');
        const ffmpegStatus = document.getElementById('ffmpegStatus');
        const geminiToggle = document.getElementById('geminiToggle');
        const geminiSettings = document.getElementById('geminiSettings');
        const openaiToggle = document.getElementById('openaiToggle');
        const openaiSettings = document.getElementById('openaiSettings');
        const openaiApiKeyInput = document.getElementById('openaiApiKey');
        const saveOpenaiApiKeyButton = document.getElementById('saveOpenaiApiKey');
        const openaiModelSelect = document.getElementById('openaiModel');
        const openaiLanguageSelect = document.getElementById('openaiLanguage');
        const groqToggle = document.getElementById('groqToggle');
        const groqSettings = document.getElementById('groqSettings');
        const groqApiKeyInput = document.getElementById('groqApiKey');
        const saveGroqApiKeyButton = document.getElementById('saveGroqApiKey');
        const groqModelSelect = document.getElementById('groqModel');
        const groqLanguageSelect = document.getElementById('groqLanguage');

        // --- State Variables (Unchanged) ---
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let currentApiKey = localStorage.getItem('geminiApiKey') || '';
        let currentOpenaiApiKey = localStorage.getItem('openaiApiKey') || '';
        let currentGroqApiKey = localStorage.getItem('groqApiKey') || '';
        let openaiModel = localStorage.getItem('openaiModel') || 'whisper-1';
        let openaiLanguage = localStorage.getItem('openaiLanguage') || 'auto';
        let groqModel = localStorage.getItem('groqModel') || 'whisper-large-v3-turbo';
        let groqLanguage = localStorage.getItem('groqLanguage') || 'auto';
        let db;
        let ffmpeg;
        let ffmpegLoaded = false;
        let currentlyPlayingAudio = null;
        let currentlyPlayingButton = null;
        let tokenUsage = { input: 0, output: 0 }; // Track token usage
        let darkMode = localStorage.getItem('darkMode') || 'system'; // Dark mode preference
        let settingsVisible = false; // Track settings visibility
        let ffmpegEnabled = localStorage.getItem('ffmpegEnabled') !== 'false'; // FFmpeg enabled by default
        let geminiEnabled = localStorage.getItem('geminiEnabled') !== 'false'; // Gemini enabled by default
        let openaiEnabled = localStorage.getItem('openaiEnabled') === 'true'; // OpenAI disabled by default
        let groqEnabled = localStorage.getItem('groqEnabled') === 'true'; // Groq disabled by default

        // --- Constants ---
        const DB_NAME = 'VoiceRecorderDB_MP3';
        const DB_VERSION = 1;
        const STORE_NAME = 'recordings_mp3';
        const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=';
        const OPENAI_API_URL = 'https://api.openai.com/v1/audio/transcriptions';
        const GROQ_API_URL = 'https://api.groq.com/openai/v1/audio/transcriptions';
        const TARGET_MIME_TYPE = 'audio/mpeg';
        const TARGET_FORMAT = 'mp3';
        // const TARGET_BITRATE = '256k'; // Replaced by quality setting
        const TARGET_QUALITY = '1'; // VBR quality setting (-q:a 1)
        const TARGET_CHANNELS = 1;

        // --- FFmpeg Initialization ---
        async function loadFFmpeg() {
            if (!ffmpegEnabled) {
                ffmpegStatus.textContent = 'FFmpeg disabled. Audio will not be converted to MP3.';
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = 'Recording enabled (no MP3 conversion)';
                return;
            }
            
            ffmpegStatus.textContent = 'Loading FFmpeg (approx. 30MB)...';
            recordButton.disabled = true;
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = 'Initializing FFmpeg library...\n';

            try {
                if (typeof FFmpeg === 'undefined' || typeof FFmpeg.createFFmpeg === 'undefined') {
                     throw new Error("FFmpeg library script not loaded correctly.");
                }
                const { createFFmpeg } = FFmpeg;

                const corePath = 'https://unpkg.com/@ffmpeg/core@0.11.0/dist/ffmpeg-core.js';
                ffmpegLog.textContent += `Attempting to load core from: ${corePath}\n (This avoids SharedArrayBuffer issues but is slower)\n`;

                ffmpeg = createFFmpeg({
                    log: true,
                    logger: ({ type, message }) => {
                        console.log(`FFmpeg log [${type}]: ${message}`);
                        if(ffmpegLog.textContent.length > 5000) ffmpegLog.textContent = '';
                        ffmpegLog.textContent += message + '\n';
                        ffmpegLog.scrollTop = ffmpegLog.scrollHeight;
                    },
                    progress: ({ ratio }) => {
                         console.log(`FFmpeg progress: ${(ratio * 100).toFixed(2)}%`);
                         if (ratio > 0 && ratio < 1) {
                            ffmpegStatus.textContent = `Loading FFmpeg... ${(ratio * 100).toFixed(0)}%`;
                         }
                    },
                    corePath: corePath,
                });

                ffmpegLog.textContent += 'Loading FFmpeg core...\n';
                await ffmpeg.load();
                ffmpegLog.textContent += 'FFmpeg core loaded successfully.\n';
                ffmpegLoaded = true;
                ffmpegStatus.textContent = 'FFmpeg loaded successfully';
                setStatus('Ready to record.');
                recordButton.disabled = false;

            } catch (error) {
                console.error("Error loading FFmpeg:", error);
                if (error instanceof ReferenceError && error.message.includes("SharedArrayBuffer")) {
                     ffmpegStatus.textContent = 'FFmpeg failed: SharedArrayBuffer missing. Need server COOP/COEP headers.';
                     ffmpegLog.textContent += `ERROR: SharedArrayBuffer not defined. This usually means the server is not sending the required COOP and COEP headers. See console and explanation above the code.\n`;
                } else {
                    ffmpegStatus.textContent = 'Failed to load FFmpeg. Conversion unavailable.';
                    ffmpegLog.textContent += `Error loading FFmpeg: ${error}\n`;
                }
                ffmpegLoaded = false;
                recordButton.disabled = true;
                recordButton.title = 'FFmpeg failed to load, recording disabled.';
            }
        }


        // --- IndexedDB Initialization (Unchanged) ---
        function initDB() {
            return new Promise((resolve, reject) => {
                const request = indexedDB.open(DB_NAME, DB_VERSION);
                request.onerror = (event) => { console.error("IndexedDB error:", event.target.error); setStatus('Error initializing local database.', true); reject(event.target.error); };
                request.onsuccess = (event) => { db = event.target.result; console.log("Database initialized successfully:", DB_NAME); resolve(db); };
                request.onupgradeneeded = (event) => {
                    db = event.target.result;
                    if (!db.objectStoreNames.contains(STORE_NAME)) {
                        const objectStore = db.createObjectStore(STORE_NAME, { keyPath: 'id', autoIncrement: true });
                        objectStore.createIndex('timestamp', 'timestamp', { unique: false });
                        console.log("Object store created:", STORE_NAME);
                    }
                };
            });
        }

        // --- IndexedDB Operations ---
        function addRecordingToDB(blob, mimeType) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite');
                const store = transaction.objectStore(STORE_NAME);
                const recording = { audioBlob: blob, mimeType: mimeType, timestamp: new Date(), transcription: null };
                const request = store.add(recording);
                request.onsuccess = (event) => resolve(event.target.result);
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function getRecordingsFromDB() {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.getAll();
                request.onsuccess = (event) => resolve(event.target.result.sort((a, b) => b.timestamp - a.timestamp));
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function getRecordingByIdFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readonly');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.get(id);
                request.onsuccess = (event) => resolve(event.target.result);
                request.onerror = (event) => reject(event.target.error);
            });
        }

        function updateTranscriptionInDB(id, transcription) {
            return new Promise(async (resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                try {
                    const recording = await getRecordingByIdFromDB(id);
                    if (!recording) return reject(`Recording ${id} not found.`);
                    recording.transcription = transcription;
                    const transaction = db.transaction([STORE_NAME], 'readwrite');
                    const store = transaction.objectStore(STORE_NAME);
                    const request = store.put(recording);
                    request.onsuccess = () => resolve();
                    request.onerror = (event) => reject(event.target.error);
                } catch (error) {
                    reject(error);
                }
            });
        }

        function deleteRecordingFromDB(id) {
            return new Promise((resolve, reject) => {
                if (!db) return reject("Database not initialized.");
                const transaction = db.transaction([STORE_NAME], 'readwrite');
                const store = transaction.objectStore(STORE_NAME);
                const request = store.delete(id);
                request.onsuccess = () => resolve();
                request.onerror = (event) => reject(event.target.error);
            });
        }

        // --- UI Update Functions (Unchanged) ---
        function setStatus(message, isError = false) { statusMessage.textContent = message; statusMessage.className = `mt-3 h-5 ${isError ? 'text-red-600' : 'text-gray-600'}`; }
        function updateRecordButtonState() {
            const micIconElement = recordButton.querySelector('[data-lucide="mic"]');
            if (isRecording) {
                recordButton.classList.remove('bg-red-600', 'hover:bg-red-700');
                recordButton.classList.add('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                if (micIconElement) micIconElement.classList.add('animate-pulse');
                setStatus('Recording...');
                recordButton.disabled = false; // Ensure button is enabled during recording
            } else {
                if (!statusMessage.textContent.includes('FFmpeg') && !statusMessage.textContent.includes('Converting')) {
                    setStatus('Click the mic to record');
                }
                recordButton.classList.remove('bg-blue-600', 'hover:bg-blue-700', 'recording-pulse');
                recordButton.classList.add('bg-red-600', 'hover:bg-red-700');
                if (micIconElement) micIconElement.classList.remove('animate-pulse');
                recordButton.disabled = !ffmpegLoaded; // Only disable if FFmpeg is not loaded
            }
        }
        function displayTranscription(text) {
            transcriptionOutput.value = text || "No transcription available.";
            transcriptionSection.classList.remove('hidden');
            
            if (text && text !== "API Key needed." && !text.startsWith("Error:")) {
                copyButton.disabled = false;
                copyButton.classList.remove('opacity-50', 'cursor-not-allowed');
                copyButton.classList.add('opacity-100', 'cursor-pointer');
                
                // Automatically copy to clipboard
                navigator.clipboard.writeText(text).then(() => {
                    setStatus('Transcription copied to clipboard!');
                    const copyIcon = copyButton.querySelector('[data-lucide="copy"]');
                    const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`;
                    const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`;
                    copyButton.innerHTML = checkIconHTML;
                    lucide.createIcons();
                    setTimeout(() => {
                        copyButton.innerHTML = originalIconHTML;
                        lucide.createIcons();
                    }, 1500);
                }).catch(err => {
                    console.error('Auto-copy failed: ', err);
                    setStatus('Auto-copy failed.', true);
                });
            } else {
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }
        async function renderHistory() {
             try {
                const recordings = await getRecordingsFromDB(); 
                historyList.innerHTML = '';
                
                if (recordings.length === 0) { 
                    noHistoryMessage.classList.remove('hidden'); 
                    historyList.appendChild(noHistoryMessage); 
                } else {
                    noHistoryMessage.classList.add('hidden');
                    
                    // Sort recordings by timestamp (newest first)
                    recordings.sort((a, b) => b.timestamp - a.timestamp);
                    
                    // Limit to 10 entries
                    const limitedRecordings = recordings.slice(0, 10);
                    
                    // If we have more than 10 recordings, delete the oldest ones
                    if (recordings.length > 10) {
                        const recordingsToDelete = recordings.slice(10);
                        for (const rec of recordingsToDelete) {
                            try {
                                await deleteRecordingFromDB(rec.id);
                                console.log(`Auto-deleted old recording ${rec.id}`);
                            } catch (error) {
                                console.error(`Error auto-deleting recording ${rec.id}:`, error);
                            }
                        }
                    }
                    
                    limitedRecordings.forEach(rec => {
                        const div = document.createElement('div'); 
                        div.className = 'p-3 bg-gray-50 border border-gray-200 rounded-md flex items-center justify-between space-x-3';
                        
                        const infoDiv = document.createElement('div'); 
                        infoDiv.className = 'flex-grow min-w-0';
                        
                        const time = document.createElement('p'); 
                        time.className = 'text-sm font-medium text-gray-800 truncate'; 
                        time.textContent = `Recorded MP3: ${rec.timestamp.toLocaleString()}`; 
                        time.title = `MP3 Recorded: ${rec.timestamp.toLocaleString()}`;
                        
                        // Add file size and duration info
                        const fileInfo = document.createElement('p');
                        fileInfo.className = 'text-xs text-gray-500';
                        
                        // Calculate file size
                        const fileSizeMB = (rec.audioBlob.size / (1024 * 1024)).toFixed(2);
                        
                        // Create audio element to get duration
                        const audio = new Audio(URL.createObjectURL(rec.audioBlob));
                        audio.onloadedmetadata = () => {
                            const duration = audio.duration;
                            const minutes = Math.floor(duration / 60);
                            const seconds = Math.floor(duration % 60);
                            const durationStr = `${minutes}:${seconds.toString().padStart(2, '0')}`;
                            
                            // Add token usage if available
                            const tokenInfo = rec.tokenUsage ? 
                                ` | Tokens: ${rec.tokenUsage.input || 0} in, ${rec.tokenUsage.output || 0} out` : 
                                '';
                                
                            fileInfo.textContent = `Size: ${fileSizeMB} MB | Duration: ${durationStr}${tokenInfo}`;
                            URL.revokeObjectURL(audio.src);
                        };
                        
                        const transcriptionPreview = document.createElement('p'); 
                        transcriptionPreview.className = 'text-xs text-gray-500 italic truncate'; 
                        transcriptionPreview.textContent = rec.transcription ? `"${rec.transcription.substring(0, 60)}..."` : 'Not transcribed yet'; 
                        if(rec.transcription) transcriptionPreview.title = rec.transcription;
                        
                        // Append elements in the correct order
                        infoDiv.appendChild(time);
                        infoDiv.appendChild(fileInfo);
                        infoDiv.appendChild(transcriptionPreview);
                        
                        const controlsDiv = document.createElement('div'); 
                        controlsDiv.className = 'flex-shrink-0 flex items-center space-x-2';
                        
                        const playButton = document.createElement('button');
                        playButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        playButton.className = 'p-1.5 bg-green-100 text-green-700 rounded hover:bg-green-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-green-500';
                        playButton.title = 'Play MP3 Audio';
                        playButton.onclick = () => playAudio(rec.audioBlob, playButton);

                        const downloadButton = document.createElement('button');
                        downloadButton.innerHTML = `<i data-lucide="download" style="width: 18px; height: 18px;"></i>`;
                        downloadButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        downloadButton.title = 'Download MP3';
                        downloadButton.onclick = () => {
                            const url = URL.createObjectURL(rec.audioBlob);
                            const a = document.createElement('a');
                            a.href = url;
                            a.download = `recording_${rec.id}_${rec.timestamp.toISOString().slice(0,19).replace(/[:]/g, '-')}.mp3`;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        };

                        const transcribeButton = document.createElement('button');
                        transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                        transcribeButton.className = 'p-1.5 bg-blue-100 text-blue-700 rounded hover:bg-blue-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-blue-500';
                        transcribeButton.title = 'Transcribe Audio';
                        transcribeButton.onclick = (e) => {
                            if (rec.transcription) {
                                displayTranscription(rec.transcription);
                                return;
                            }
                            transcribeButton.disabled = true;
                            transcribeButton.innerHTML = '...';
                            transcribeAudio(rec.id, rec.audioBlob, rec.mimeType).finally(() => {
                                transcribeButton.disabled = false;
                                transcribeButton.innerHTML = `<i data-lucide="captions" style="width: 18px; height: 18px;"></i>`;
                                lucide.createIcons();
                            });
                        };
                        transcribeButton.disabled = !currentApiKey || !ffmpegLoaded;
                        if (!currentApiKey) transcribeButton.title = 'API Key required';
                        else if (!ffmpegLoaded) transcribeButton.title = 'FFmpeg not loaded';
                        else if (rec.transcription) transcribeButton.title = 'View Transcription';

                        const deleteButton = document.createElement('button');
                        deleteButton.innerHTML = `<i data-lucide="trash-2" style="width: 18px; height: 18px;"></i>`;
                        deleteButton.className = 'p-1.5 bg-red-100 text-red-700 rounded hover:bg-red-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-red-500';
                        deleteButton.title = 'Delete Recording';
                        deleteButton.onclick = () => deleteRecording(rec.id);

                        controlsDiv.appendChild(playButton);
                        controlsDiv.appendChild(downloadButton);
                        controlsDiv.appendChild(transcribeButton);
                        controlsDiv.appendChild(deleteButton);
                        
                        div.appendChild(infoDiv);
                        div.appendChild(controlsDiv);
                        historyList.appendChild(div);
                    });
                    
                    lucide.createIcons();
                }
            } catch (error) { 
                console.error("Error rendering history:", error); 
                setStatus('Could not load history.', true); 
                noHistoryMessage.classList.remove('hidden'); 
                historyList.appendChild(noHistoryMessage); 
            }
        }

        // --- Audio Handling ---
        async function startRecording() { // Unchanged
             if (!ffmpegEnabled && !ffmpegLoaded) { setStatus('FFmpeg disabled and not loaded. Cannot record.', true); return; }
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true }); console.log("Mic access granted.");
                const options = { mimeType: 'audio/webm;codecs=opus' };
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/ogg;codecs=opus';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = 'audio/webm';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = '';
                console.log("Recording with MIME type:", options.mimeType || "Browser Default");
                mediaRecorder = new MediaRecorder(stream, options); audioChunks = [];
                mediaRecorder.ondataavailable = event => { if (event.data.size > 0) audioChunks.push(event.data); };
                mediaRecorder.onstop = async () => {
                    const originalBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });
                    const originalMimeType = mediaRecorder.mimeType || 'audio/webm';
                    console.log("Recording stopped. Original Blob:", originalBlob); console.log("Original MIME type:", originalMimeType);
                    stream.getTracks().forEach(track => track.stop());
                    
                    if (ffmpegEnabled && ffmpegLoaded) {
                        await convertAudioAndSave(originalBlob, originalMimeType); // Convert and save
                    } else {
                        // Save without conversion
                        setStatus('Saving recording...');
                        const newId = await addRecordingToDB(originalBlob, originalMimeType);
                        setStatus(`Recording saved (ID: ${newId}).`);
                        await renderHistory();
                        
                        // Attempt automatic transcription if API key is available
                        if (currentApiKey) {
                            setStatus(`Starting automatic transcription for recording ${newId}...`);
                            await transcribeAudio(newId, originalBlob, originalMimeType);
                        } else {
                            setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                            displayTranscription("API Key needed for transcription.");
                        }
                    }
                    
                    updateRecordButtonState(); // Update button state after saving
                };
                mediaRecorder.onerror = (event) => { console.error("MediaRecorder error:", event.error); setStatus(`Recording error: ${event.error?.name || 'Unknown'}`, true); isRecording = false; updateRecordButtonState(); stream.getTracks().forEach(track => track.stop()); };
                mediaRecorder.start(); isRecording = true; updateRecordButtonState();
            } catch (err) { /* Error handling for getUserMedia (unchanged) */
                console.error("Mic error:", err); console.error("Details:", JSON.stringify(err)); console.error("Name:", err?.name); console.error("Message:", err?.message); let msg = 'Error starting recording.'; if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') msg = 'Mic access denied.'; else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') msg = 'No mic found.'; else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') msg = 'Mic in use.'; else if (err.message) msg = `Error: ${err.message}`; else msg = 'Unknown mic error.'; setStatus(msg, true); isRecording = false; updateRecordButtonState();
            }
        }
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                try {
                    mediaRecorder.stop();
                    isRecording = false;
                    setStatus('Processing recording...');
                    updateRecordButtonState();
                } catch (error) {
                    console.error("Error stopping recorder:", error);
                    setStatus('Error stopping recording.', true);
                    isRecording = false;
                    updateRecordButtonState();
                    if (mediaRecorder?.stream) {
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    }
                }
            }
        }

        // --- FFmpeg Conversion Function ---
        async function convertAudioAndSave(originalBlob, originalMimeType) {
            if (!ffmpegLoaded || !ffmpeg) {
                setStatus('FFmpeg not ready. Cannot convert/save.', true);
                updateRecordButtonState();
                return;
            }
            setStatus('Converting audio to MP3...');
            ffmpegLog.classList.remove('hidden');
            ffmpegLog.textContent = `Starting conversion of ${originalMimeType}...\n`;
            // Don't disable the button here, let updateRecordButtonState handle it
            updateRecordButtonState();

            try {
                const arrayBuffer = await originalBlob.arrayBuffer();
                const inputData = new Uint8Array(arrayBuffer);
                const inputFilename = `input.${originalMimeType.split('/')[1]?.split(';')[0] || 'bin'}`;
                const outputFilename = `output.${TARGET_FORMAT}`;

                ffmpegLog.textContent += `Writing input file (${inputFilename})...\n`;
                await ffmpeg.FS('writeFile', inputFilename, inputData);
                ffmpegLog.textContent += `Input file written.\n`;

                const ffmpegCommand = [
                    '-i', inputFilename,
                    '-ac', `${TARGET_CHANNELS}`,
                    '-q:a', TARGET_QUALITY,
                    outputFilename
                ];

                ffmpegLog.textContent += `Running FFmpeg: ffmpeg ${ffmpegCommand.join(' ')}\n`;
                await ffmpeg.run(...ffmpegCommand);
                ffmpegLog.textContent += `FFmpeg execution finished.\n`;

                ffmpegLog.textContent += `Reading output file (${outputFilename})...\n`;
                const outputData = ffmpeg.FS('readFile', outputFilename);
                ffmpegLog.textContent += `Output file read (${outputData.length} bytes).\n`;

                const mp3Blob = new Blob([outputData.buffer], { type: TARGET_MIME_TYPE });
                console.log("Conversion successful. MP3 Blob created:", mp3Blob);

                try {
                    await ffmpeg.FS('unlink', inputFilename);
                    await ffmpeg.FS('unlink', outputFilename);
                    ffmpegLog.textContent += `Cleaned up virtual files.\n`;
                } catch (cleanupError) {
                    console.warn("FFmpeg cleanup warning:", cleanupError);
                    ffmpegLog.textContent += `Cleanup warning: ${cleanupError.message}\n`;
                }

                setStatus('Saving converted MP3...');
                const newId = await addRecordingToDB(mp3Blob, TARGET_MIME_TYPE);
                setStatus(`MP3 recording saved (ID: ${newId}).`);
                await renderHistory();

                // Attempt automatic transcription if API key is available
                if (currentApiKey) {
                    setStatus(`Starting automatic transcription for recording ${newId}...`);
                    await transcribeAudio(newId, mp3Blob, TARGET_MIME_TYPE);
                } else {
                    setStatus('Recording saved. Add an API key to enable automatic transcription.', true);
                    displayTranscription("API Key needed for transcription.");
                }

            } catch (error) {
                console.error("FFmpeg conversion failed:", error);
                setStatus(`Error during MP3 conversion: ${error.message || error}`, true);
                ffmpegLog.textContent += `ERROR: ${error.message || error}\n`;
            } finally {
                updateRecordButtonState();
            }
        }

        function playAudio(blob, button) {
            try {
                // If there's already an audio playing, stop it
                if (currentlyPlayingAudio) {
                    currentlyPlayingAudio.pause();
                    currentlyPlayingAudio.currentTime = 0;
                    if (currentlyPlayingButton) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                    }
                }

                // If clicking the same button that's currently playing, just stop
                if (currentlyPlayingButton === button) {
                    currentlyPlayingAudio = null;
                    currentlyPlayingButton = null;
                    return;
                }

                // Create and play new audio
                const audioUrl = URL.createObjectURL(blob);
                const audio = new Audio(audioUrl);
                
                audio.onerror = (e) => {
                    console.error("Audio play error:", e);
                    setStatus('Error playing audio.', true);
                    URL.revokeObjectURL(audioUrl);
                };
                
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    if (currentlyPlayingButton === button) {
                        currentlyPlayingButton.innerHTML = `<i data-lucide="play" style="width: 18px; height: 18px;"></i>`;
                        lucide.createIcons();
                        currentlyPlayingAudio = null;
                        currentlyPlayingButton = null;
                    }
                };

                audio.play();
                currentlyPlayingAudio = audio;
                currentlyPlayingButton = button;
                button.innerHTML = `<i data-lucide="pause" style="width: 18px; height: 18px;"></i>`;
                lucide.createIcons();
            } catch (error) {
                console.error("Audio object error:", error);
                setStatus('Could not play audio.', true);
            }
        }

        // --- Transcription (Updated to support multiple APIs) ---
        async function transcribeAudio(id, audioBlob, mimeType) {
            // Check if any API is enabled and has a key
            if (!geminiEnabled && !openaiEnabled && !groqEnabled) {
                setStatus('No transcription API enabled.', true);
                displayTranscription("No transcription API enabled. Please enable an API in settings.");
                return;
            }
            
            if (geminiEnabled && !currentApiKey) {
                setStatus('Gemini API Key needed.', true);
                displayTranscription("Gemini API Key needed for transcription.");
                return;
            }
            
            if (openaiEnabled && !currentOpenaiApiKey) {
                setStatus('OpenAI API Key needed.', true);
                displayTranscription("OpenAI API Key needed for transcription.");
                return;
            }
            
            if (groqEnabled && !currentGroqApiKey) {
                setStatus('Groq API Key needed.', true);
                displayTranscription("Groq API Key needed for transcription.");
                return;
            }
            
            if (!audioBlob) {
                setStatus('Invalid audio.', true);
                return;
            }
            
            if (ffmpegEnabled && !ffmpegLoaded) {
                setStatus('FFmpeg not loaded.', true);
                return;
            }
            
            setStatus(`Transcribing recording ${id}...`);
            displayTranscription("Transcribing...");
            transcriptionSection.classList.remove('hidden');
            copyButton.disabled = true;
            copyButton.classList.add('opacity-50', 'cursor-not-allowed');
            copyButton.classList.remove('opacity-100', 'cursor-pointer');

            try {
                let transcriptionText = "Transcription not found.";
                let recordingTokenUsage = { input: 0, output: 0 };
                
                // Try Gemini first if enabled
                if (geminiEnabled && currentApiKey) {
                    try {
                        const base64Audio = await blobToBase64(audioBlob);
                        const requestBody = { contents: [{ parts: [ { text: "Please transcribe the following audio recording:" }, { inline_data: { mime_type: mimeType, data: base64Audio } } ]}] };
                        const response = await fetch(GEMINI_API_URL + currentApiKey, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(requestBody) });
                        const data = await response.json();
                        
                        if (!response.ok) {
                            console.error("Gemini API Error:", data);
                            throw new Error(data?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        // Update token usage
                        if (data.usage) {
                            recordingTokenUsage.input = data.usage.promptTokenCount || 0;
                            recordingTokenUsage.output = data.usage.candidatesTokenCount || 0;
                            
                            // Update global token usage
                            tokenUsage.input += recordingTokenUsage.input;
                            tokenUsage.output += recordingTokenUsage.output;
                            localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                        }
                        
                        if (data.candidates?.[0]?.content?.parts?.[0]?.text) {
                            transcriptionText = data.candidates[0].content.parts[0].text;
                        } else if (data.candidates?.[0]?.finishReason === "SAFETY") {
                            transcriptionText = "Blocked: safety.";
                        } else {
                            console.warn("Unexpected Gemini API response:", data);
                            const textPart = data.candidates?.[0]?.content?.parts?.find(p => p.text);
                            if (textPart) transcriptionText = textPart.text;
                        }
                        
                        console.log("Gemini transcription OK:", transcriptionText);
                    } catch (error) {
                        console.error("Gemini transcription failed:", error);
                        // If Gemini fails and other APIs are enabled, try them
                        if ((openaiEnabled && currentOpenaiApiKey) || (groqEnabled && currentGroqApiKey)) {
                            throw new Error("Gemini failed, trying other APIs...");
                        } else {
                            throw error;
                        }
                    }
                }
                
                // Try OpenAI if Gemini is not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && openaiEnabled && currentOpenaiApiKey) {
                    try {
                        const formData = new FormData();
                        formData.append('file', audioBlob, 'audio.mp3');
                        formData.append('model', openaiModel);
                        
                        // Only add language if not auto
                        if (openaiLanguage !== 'auto') {
                            formData.append('language', openaiLanguage);
                        }
                        
                        const response = await fetch(OPENAI_API_URL, {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${currentOpenaiApiKey}`
                            },
                            body: formData
                        });
                        
                        if (!response.ok) {
                            const errorData = await response.json();
                            console.error("OpenAI API Error:", errorData);
                            throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        const data = await response.json();
                        transcriptionText = data.text || "Transcription not found.";
                        console.log("OpenAI transcription OK:", transcriptionText);
                        
                        // OpenAI doesn't provide token usage in the same way, so we'll estimate
                        // Rough estimate: 1 token per 4 characters
                        const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                        recordingTokenUsage.input = 0; // We don't know the input tokens
                        recordingTokenUsage.output = estimatedTokens;
                        
                        // Update global token usage
                        tokenUsage.output += estimatedTokens;
                        localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                    } catch (error) {
                        console.error("OpenAI transcription failed:", error);
                        // If OpenAI fails and Groq is enabled, try Groq
                        if (groqEnabled && currentGroqApiKey) {
                            throw new Error("OpenAI failed, trying Groq...");
                        } else {
                            throw error;
                        }
                    }
                }
                
                // Try Groq if other APIs are not enabled or failed
                if ((!geminiEnabled || !currentApiKey) && (!openaiEnabled || !currentOpenaiApiKey) && groqEnabled && currentGroqApiKey) {
                    try {
                        const formData = new FormData();
                        formData.append('file', audioBlob, 'audio.mp3');
                        formData.append('model', groqModel);
                        formData.append('temperature', '0');
                        formData.append('response_format', 'text');
                        
                        // Only add language if not auto
                        if (groqLanguage !== 'auto') {
                            formData.append('language', groqLanguage);
                        }
                        
                        const response = await fetch(GROQ_API_URL, {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${currentGroqApiKey}`
                            },
                            body: formData
                        });
                        
                        if (!response.ok) {
                            const errorData = await response.json();
                            console.error("Groq API Error:", errorData);
                            throw new Error(errorData?.error?.message || `HTTP ${response.status}`);
                        }
                        
                        // Groq returns plain text, not JSON
                        const transcriptionText = await response.text();
                        console.log("Groq transcription OK:", transcriptionText);
                        
                        // Groq doesn't provide token usage in the same way, so we'll estimate
                        // Rough estimate: 1 token per 4 characters
                        const estimatedTokens = Math.ceil(transcriptionText.length / 4);
                        recordingTokenUsage.input = 0; // We don't know the input tokens
                        recordingTokenUsage.output = estimatedTokens;
                        
                        // Update global token usage
                        tokenUsage.output += estimatedTokens;
                        localStorage.setItem('tokenUsage', JSON.stringify(tokenUsage));
                    } catch (error) {
                        console.error("Groq transcription failed:", error);
                        throw error;
                    }
                }
                
                setStatus(`Transcription complete (ID: ${id}).`);
                displayTranscription(transcriptionText);
                
                // Update recording with transcription and token usage
                const recording = await getRecordingByIdFromDB(id);
                if (recording) {
                    recording.transcription = transcriptionText;
                    recording.tokenUsage = recordingTokenUsage;
                    
                    // Update in database
                    const transaction = db.transaction([STORE_NAME], 'readwrite');
                    const store = transaction.objectStore(STORE_NAME);
                    await new Promise((resolve, reject) => {
                        const request = store.put(recording);
                        request.onsuccess = () => resolve();
                        request.onerror = (event) => reject(event.target.error);
                    });
                }
                
                await renderHistory();
            } catch (error) {
                console.error("Transcription failed:", error);
                setStatus(`Transcription error: ${error.message}`, true);
                displayTranscription(`Error: ${error.message}`);
                transcriptionSection.classList.remove('hidden');
                copyButton.disabled = true;
                copyButton.classList.add('opacity-50', 'cursor-not-allowed');
                copyButton.classList.remove('opacity-100', 'cursor-pointer');
            }
        }

        // Helper Blob to Base64 (Unchanged)
        function blobToBase64(blob) { return new Promise((resolve, reject) => { const reader = new FileReader(); reader.onloadend = () => { const base64String = reader.result.split(',')[1]; resolve(base64String); }; reader.onerror = reject; reader.readAsDataURL(blob); }); }

        // History Actions (Unchanged)
        async function deleteRecording(id) { if (confirm(`Delete recording ${id}?`)) { try { await deleteRecordingFromDB(id); setStatus(`Recording ${id} deleted.`); await renderHistory(); } catch (error) { setStatus('Error deleting.', true); console.error("Delete error:", error); } } }

        // Event Listeners
        recordButton.addEventListener('click', () => { if (isRecording) { stopRecording(); } else { transcriptionOutput.value = ''; transcriptionSection.classList.add('hidden'); copyButton.disabled = true; copyButton.classList.add('opacity-50', 'cursor-not-allowed'); copyButton.classList.remove('opacity-100', 'cursor-pointer'); startRecording(); } });
        saveApiKeyButton.addEventListener('click', () => { currentApiKey = apiKeyInput.value.trim(); if (currentApiKey) { localStorage.setItem('geminiApiKey', currentApiKey); setStatus('Gemini API Key saved.'); } else { localStorage.removeItem('geminiApiKey'); setStatus('Gemini API Key removed.', true); } renderHistory(); });
        saveOpenaiApiKeyButton.addEventListener('click', () => { currentOpenaiApiKey = openaiApiKeyInput.value.trim(); if (currentOpenaiApiKey) { localStorage.setItem('openaiApiKey', currentOpenaiApiKey); setStatus('OpenAI API Key saved.'); } else { localStorage.removeItem('openaiApiKey'); setStatus('OpenAI API Key removed.', true); } renderHistory(); });
        saveGroqApiKeyButton.addEventListener('click', () => { currentGroqApiKey = groqApiKeyInput.value.trim(); if (currentGroqApiKey) { localStorage.setItem('groqApiKey', currentGroqApiKey); setStatus('Groq API Key saved.'); } else { localStorage.removeItem('groqApiKey'); setStatus('Groq API Key removed.', true); } renderHistory(); });
        copyButton.addEventListener('click', () => { if (transcriptionOutput.value && !copyButton.disabled) { navigator.clipboard.writeText(transcriptionOutput.value).then(() => { setStatus('Copied!'); const copyIcon = copyButton.querySelector('[data-lucide="copy"]'); const checkIconHTML = `<i data-lucide="check" style="width: 18px; height: 18px; color: green;"></i>`; const originalIconHTML = copyIcon ? copyIcon.outerHTML : `<i data-lucide="copy" style="width: 18px; height: 18px;"></i>`; copyButton.innerHTML = checkIconHTML; lucide.createIcons(); setTimeout(() => { copyButton.innerHTML = originalIconHTML; lucide.createIcons(); }, 1500); }).catch(err => { console.error('Copy failed: ', err); setStatus('Copy failed.', true); }); } });
        
        // Settings panel controls
        settingsButton.addEventListener('click', () => {
            settingsVisible = !settingsVisible;
            if (settingsVisible) {
                settingsSection.classList.remove('hidden');
            } else {
                settingsSection.classList.add('hidden');
            }
            lucide.createIcons();
        });
        
        closeSettings.addEventListener('click', () => {
            settingsVisible = false;
            settingsSection.classList.add('hidden');
            lucide.createIcons();
        });
        
        // Dark mode toggle
        const darkModeToggle = document.getElementById('darkModeToggle');
        darkModeToggle.addEventListener('change', () => {
            darkMode = darkModeToggle.checked ? 'dark' : 'system';
            localStorage.setItem('darkMode', darkMode);
            applyTheme();
        });
        
        // FFmpeg toggle
        const ffmpegToggle = document.getElementById('ffmpegToggle');
        ffmpegToggle.addEventListener('change', async () => {
            ffmpegEnabled = ffmpegToggle.checked;
            localStorage.setItem('ffmpegEnabled', ffmpegEnabled);
            
            if (ffmpegEnabled) {
                await loadFFmpeg();
            } else {
                ffmpegStatus.textContent = 'FFmpeg disabled. Audio will not be converted to MP3.';
                ffmpegLoaded = false;
                recordButton.disabled = false;
                recordButton.title = 'Recording enabled (no MP3 conversion)';
                setStatus('Ready to record (no MP3 conversion).');
            }
        });
        
        // API toggles - only one can be active at a time
        geminiToggle.addEventListener('change', () => {
            if (geminiToggle.checked) {
                // Disable other APIs
                openaiToggle.checked = false;
                groqToggle.checked = false;
                openaiEnabled = false;
                groqEnabled = false;
                openaiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
            }
            
            geminiEnabled = geminiToggle.checked;
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            
            if (geminiEnabled) {
                geminiSettings.classList.remove('hidden');
            } else {
                geminiSettings.classList.add('hidden');
            }
        });
        
        openaiToggle.addEventListener('change', () => {
            if (openaiToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                groqToggle.checked = false;
                geminiEnabled = false;
                groqEnabled = false;
                geminiSettings.classList.add('hidden');
                groqSettings.classList.add('hidden');
            }
            
            openaiEnabled = openaiToggle.checked;
            localStorage.setItem('openaiEnabled', openaiEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('groqEnabled', groqEnabled);
            
            if (openaiEnabled) {
                openaiSettings.classList.remove('hidden');
            } else {
                openaiSettings.classList.add('hidden');
            }
        });
        
        groqToggle.addEventListener('change', () => {
            if (groqToggle.checked) {
                // Disable other APIs
                geminiToggle.checked = false;
                openaiToggle.checked = false;
                geminiEnabled = false;
                openaiEnabled = false;
                geminiSettings.classList.add('hidden');
                openaiSettings.classList.add('hidden');
            }
            
            groqEnabled = groqToggle.checked;
            localStorage.setItem('groqEnabled', groqEnabled);
            localStorage.setItem('geminiEnabled', geminiEnabled);
            localStorage.setItem('openaiEnabled', openaiEnabled);
            
            if (groqEnabled) {
                groqSettings.classList.remove('hidden');
            } else {
                groqSettings.classList.add('hidden');
            }
        });
        
        // OpenAI model change
        openaiModelSelect.addEventListener('change', () => {
            openaiModel = openaiModelSelect.value;
            localStorage.setItem('openaiModel', openaiModel);
        });
        
        // OpenAI language change
        openaiLanguageSelect.addEventListener('change', () => {
            openaiLanguage = openaiLanguageSelect.value;
            localStorage.setItem('openaiLanguage', openaiLanguage);
        });
        
        // Groq model change
        groqModelSelect.addEventListener('change', () => {
            groqModel = groqModelSelect.value;
            localStorage.setItem('groqModel', groqModel);
        });
        
        // Groq language change
        groqLanguageSelect.addEventListener('change', () => {
            groqLanguage = groqLanguageSelect.value;
            localStorage.setItem('groqLanguage', groqLanguage);
        });

        // Initialization
        async function initializeApp() {
            lucide.createIcons();
            apiKeyInput.value = currentApiKey;
            openaiApiKeyInput.value = currentOpenaiApiKey;
            groqApiKeyInput.value = currentGroqApiKey;
            openaiModelSelect.value = openaiModel;
            openaiLanguageSelect.value = openaiLanguage;
            groqModelSelect.value = groqModel;
            groqLanguageSelect.value = groqLanguage;
            
            // Set dark mode toggle state
            darkModeToggle.checked = darkMode === 'dark';
            applyTheme();
            
            // Set FFmpeg toggle state
            ffmpegToggle.checked = ffmpegEnabled;
            
            // Set API toggles
            geminiToggle.checked = geminiEnabled;
            openaiToggle.checked = openaiEnabled;
            groqToggle.checked = groqEnabled;
            
            // Show/hide API settings based on toggles
            if (!geminiEnabled) {
                geminiSettings.classList.add('hidden');
            }
            if (!openaiEnabled) {
                openaiSettings.classList.add('hidden');
            }
            if (!groqEnabled) {
                groqSettings.classList.add('hidden');
            }
            
            // Show settings if no API key or if FFmpeg needs attention
            if ((geminiEnabled && !currentApiKey) || (openaiEnabled && !currentOpenaiApiKey) || (groqEnabled && !currentGroqApiKey)) {
                settingsSection.classList.remove('hidden');
                settingsVisible = true;
            }
            
            if (ffmpegEnabled) {
                await loadFFmpeg(); // Load FFmpeg first
            } else {
                ffmpegStatus.textContent = 'FFmpeg disabled. Audio will not be converted to MP3.';
                recordButton.disabled = false;
                recordButton.title = 'Recording enabled (no MP3 conversion)';
                setStatus('Ready to record (no MP3 conversion).');
            }
            
            try { await initDB(); await renderHistory(); } catch (error) { setStatus('DB init failed.', true); }
            updateRecordButtonState(); // Set initial button state
            
            // Mic support checks (unchanged)
            if (!navigator.mediaDevices?.getUserMedia) { setStatus('getUserMedia not supported.', true); recordButton.disabled = true; recordButton.title = 'Not supported'; } else if (!window.MediaRecorder) { setStatus('MediaRecorder not supported.', true); recordButton.disabled = true; recordButton.title = 'Not supported'; } else { try { const ps = await navigator.permissions.query({ name: 'microphone' }); console.log('Mic perm state:', ps.state); if (ps.state === 'denied') setStatus('Mic denied.', true); ps.onchange = () => { console.log('Mic perm changed:', ps.state); if (ps.state === 'denied') setStatus('Mic denied.', true); else if (statusMessage.textContent.includes('denied')) setStatus('Mic granted.', false); }; } catch (e) { console.warn("Perm query failed:", e); } }
        }
        document.addEventListener('DOMContentLoaded', initializeApp);

        // Update token display
        function updateTokenDisplay() {
            const savedUsage = localStorage.getItem('tokenUsage');
            if (savedUsage) {
                tokenUsage = JSON.parse(savedUsage);
            }
            document.getElementById('inputTokens').textContent = tokenUsage.input.toLocaleString();
            document.getElementById('outputTokens').textContent = tokenUsage.output.toLocaleString();
        }
        
        // Apply theme based on system preference or user choice
        function applyTheme() {
            if (darkMode === 'dark') {
                document.body.classList.add('dark-mode');
            } else if (darkMode === 'system') {
                if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                    document.body.classList.add('dark-mode');
                } else {
                    document.body.classList.remove('dark-mode');
                }
            } else {
                document.body.classList.remove('dark-mode');
            }
        }
        
        // Listen for system theme changes
        if (window.matchMedia) {
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {
                if (darkMode === 'system') {
                    if (e.matches) {
                        document.body.classList.add('dark-mode');
                    } else {
                        document.body.classList.remove('dark-mode');
                    }
                }
            });
        }

    </script>
</body>
</html>
