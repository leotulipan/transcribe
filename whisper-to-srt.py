#!/usr/bin/env python3
"""
Converts a Whisper JSON output file to SRT format, filtering out potentially
hallucinated segments (e.g., segments starting at time 0 with high compression
ratios).

Usage:
    python whisper_to_srt.py input.json [output.srt] [max_chars_per_line]

Arguments:
    input.json             : The input JSON file generated by Whisper.
    output.srt (optional)  : The output SRT file.  If not provided, the output
                             filename will be based on the input filename.
    max_chars_per_line (optional): The maximum number of characters per line
                             in the SRT output (default: 80).

Example:
    python whisper_to_srt.py my_audio.json my_audio.srt 40
"""

# /// script
# dependencies = []
# ///

import json
import textwrap
import sys
from datetime import timedelta

def format_time(seconds):
    """Convert seconds to SRT timestamp format: HH:MM:SS,mmm"""
    td = timedelta(seconds=seconds)
    hours, remainder = divmod(td.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = int(td.microseconds / 1000)
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

def split_text_into_chunks(text, max_chars=80):
    """Split text into chunks of maximum length while respecting word boundaries"""
    return textwrap.wrap(text, width=max_chars, break_long_words=False)

def whisper_to_srt(json_data, output_file=None, max_chars=80):
    """Convert Whisper JSON format to SRT format, filtering out bad segments."""
    if isinstance(json_data, str):
        try:
            data = json.loads(json_data)
        except json.JSONDecodeError:
            with open(json_data, 'r', encoding='utf-8') as f:
                data = json.load(f)
    else:
        data = json_data

    # --- FILTERING STEP ---
    filtered_segments = []
    for segment in data['segments']:
        # Skip segments with:
        # 1. High no_speech_prob (likely non-speech)
        # 2. Very negative avg_logprob (low confidence)
        # 3. Unusual compression_ratio (potential issues)
        # 4. Zero start time (unless it's the only segment)
        if (segment.get('no_speech_prob', 0) < 0.5 and  # Less than 50% chance of being non-speech
            segment.get('avg_logprob', 0) > -0.5 and    # Better than -0.5 log probability
            0.8 < segment.get('compression_ratio', 1.0) < 2.0 and  # Normal speech patterns
            (segment['start'] != 0 or all(s['start'] == 0 for s in data['segments']))):
            filtered_segments.append(segment)

    # Sort segments by start time to ensure proper ordering
    filtered_segments.sort(key=lambda x: x['start'])

    # Merge overlapping segments
    merged_segments = []
    if filtered_segments:
        current_segment = filtered_segments[0].copy()
        
        for next_segment in filtered_segments[1:]:
            # If segments overlap or are very close (within 0.1s), merge them
            if next_segment['start'] <= current_segment['end'] + 0.1:
                current_segment['end'] = max(current_segment['end'], next_segment['end'])
                current_segment['text'] = current_segment['text'] + ' ' + next_segment['text']
            else:
                merged_segments.append(current_segment)
                current_segment = next_segment.copy()
        
        merged_segments.append(current_segment)

    data['segments'] = merged_segments
    # --- END FILTERING ---

    srt_lines = []
    subtitle_index = 1

    for segment in data['segments']:
        start_time = segment['start']
        end_time = segment['end']
        text = segment['text'].strip()

        if not text:  # Skip empty segments
            continue

        chunks = split_text_into_chunks(text, max_chars)
        
        if len(chunks) == 1:
            srt_lines.append(f"{subtitle_index}")
            srt_lines.append(f"{format_time(start_time)} --> {format_time(end_time)}")
            srt_lines.append(chunks[0])
            srt_lines.append("")  # Empty line
            subtitle_index += 1
        else:
            # Distribute chunks evenly across segment duration
            chunk_duration = (end_time - start_time) / len(chunks)
            for i, chunk in enumerate(chunks):
                chunk_start = start_time + i * chunk_duration
                chunk_end = chunk_start + chunk_duration
                srt_lines.append(f"{subtitle_index}")
                srt_lines.append(f"{format_time(chunk_start)} --> {format_time(chunk_end)}")
                srt_lines.append(chunk)
                srt_lines.append("")  # Empty line
                subtitle_index += 1

    srt_content = "\n".join(srt_lines)

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        return f"SRT file saved to {output_file}"
    else:
        return srt_content

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python whisper_to_srt.py input.json [output.srt] [max_chars_per_line]")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else input_file.rsplit('.', 1)[0] + '.srt'
    max_chars = int(sys.argv[3]) if len(sys.argv) > 3 else 80

    with open(input_file, 'r', encoding='utf-8') as f:
        json_data = json.load(f)

    result = whisper_to_srt(json_data, output_file, max_chars)
    print(result)